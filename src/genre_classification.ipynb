{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764251d9-7e3c-45b4-b776-2ef5af3c13ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9cda5a-afdf-4317-bb69-3c19aebf0167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:11:02.185410: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 11:11:02.324914: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-15 11:11:02.364142: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-15 11:11:03.005144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 11:11:03.005205: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-15 11:11:03.005212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvolpepe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:11:09.597628: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 11:11:10.246291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30970 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained weights into the model and freezing weights...\n",
      "Collecting dataset splits...\n",
      "Modifying labels...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import config, music_model, utils\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "### CONFIGURATION ###\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "MODEL_SAVE_PATH = os.path.join(ROOT_PATH, 'training', 'checkpoints', 'genre_classifier')\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_PATH, 'model-{val_loss:.2f}.h5')\n",
    "DATASET_NAME = 'lmd_matched_final_2048_cut'\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "USE_ONE_GPU = True\n",
    "\n",
    "WEIGHTS_PATH = os.path.join(ROOT_PATH, 'training', 'checkpoints', \n",
    "                            'model_GPT_baseline_with_mse_vellmd_matched_2048', \n",
    "                            'model_GPT_baseline_with_mse_vellmd_matched_2048')\n",
    "\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1\n",
    "\n",
    "### MODEL CREATION ###\n",
    "\n",
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf,\n",
    "                                         num_genres=len(conf.accepted_subgenres),\n",
    "                                         use_regularization=False,\n",
    "                                         use_masking_layers=False)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf,\n",
    "                                     num_genres=len(conf.accepted_subgenres),\n",
    "                                     use_regularization=False,\n",
    "                                     use_masking_layers=False)\n",
    "\n",
    "print(\"Loading pre-trained weights into the model and freezing weights...\")\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "    \n",
    "print(\"Collecting dataset splits...\")\n",
    "dataset_path = conf.dataset_paths[DATASET_NAME]\n",
    "train_dataset, val_dataset, test_dataset = utils.get_dataset_splits(dataset_path, conf)\n",
    "\n",
    "print(\"Modifying labels...\")\n",
    "train_dataset, val_dataset, test_dataset = \\\n",
    "    train_dataset.map(lambda x, y: (x, x[1])), \\\n",
    "    val_dataset.map(lambda x, y: (x, x[1])),   \\\n",
    "    test_dataset.map(lambda x, y: (x, x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5dfb4-1553-4e1e-bd20-1bc3ab9ee03c",
   "metadata": {},
   "source": [
    "We extract the transformer's embeddings for the dataset and define the genre classifier on top of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca7bd04-46e7-45dd-bcb2-94ad09c3d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "music_transformer = tf.keras.Model(\n",
    "    inputs=model.inputs, \n",
    "    outputs=model.get_layer('tfgpt2_model').output.last_hidden_state\n",
    ")\n",
    "music_transformer.trainable = False\n",
    "\n",
    "class_gen = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(conf.accepted_subgenres), activation='relu'),\n",
    "    tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "out_classes = class_gen(music_transformer.outputs[0])\n",
    "\n",
    "genre_classifier = tf.keras.Model(inputs=music_transformer.inputs, outputs=out_classes)\n",
    "genre_classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "                         loss=tf.keras.losses.KLDivergence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1733337-3741-4039-ba70-480814170e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([x[1] for x, y in train_dataset], axis=0)\n",
    "genre_labels = np.where(labels > 0)[1]\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(genre_labels), y=genre_labels)\n",
    "class_weights = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5d7fa-76c5-47b9-93c1-07cfc15d0442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvolpepe\u001b[0m (\u001b[33mmarcello-e-federico\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aborghesi/persistent/MusicGeneration/src/wandb/run-20230515_111123-2liy5qe9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation/runs/2liy5qe9\" target=\"_blank\">baseline_genre_class_full</a></strong> to <a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 11:11:37.493745: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5314/6949 [=====================>........] - ETA: 5:21 - loss: 1.5757"
     ]
    }
   ],
   "source": [
    "run = wandb.init(project=\"Music Generation\", entity=\"marcello-e-federico\",\n",
    "                         group='genre_classification', job_type='train',\n",
    "                         name='baseline_genre_class_full')\n",
    "\n",
    "genre_classifier.fit(x=train_dataset, validation_data=val_dataset, epochs=200, \n",
    "                     callbacks=[\n",
    "                        tf.keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True),\n",
    "                        tf.keras.callbacks.ModelCheckpoint(filepath=MODEL_SAVE_PATH, \n",
    "                            save_best_only=True, save_weights_only=True),\n",
    "                        tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "                        WandbCallback(save_model=False, \n",
    "                                      save_graph=False,log_weights=False)\n",
    "                        ])\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1a5e1-8acf-4cb2-8161-ccdf8544c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = genre_classifier.evaluate(x=test_dataset, batch_size=conf.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e0a9f-0d9c-49d3-a3f8-461577c6be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
