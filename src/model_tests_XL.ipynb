{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 10:39:18.458505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 10:39:18.608039: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-17 10:39:18.647707: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-17 10:39:19.247530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 10:39:19.247604: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 10:39:19.247611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from transformers import TransfoXLConfig, TFTransfoXLModel, TransfoXLTokenizer\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for very high loads on GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 10:39:22.680501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "decoder = TFTransfoXLModel(TransfoXLConfig(\n",
    "    # some of these were taken by \n",
    "    # https://github.com/slSeanWU/jazz_transformer/blob/master/transformer_xl/model_aug.py\n",
    "    vocab_size=0,\n",
    "    div_val=12,      # creates 12 blocks of 512\n",
    "    n_head=2,\n",
    "    n_layer=6,\n",
    "    d_head=256, # d_model // n_head\n",
    "    d_model=512,\n",
    "    d_embed=512,\n",
    "    d_inner=2048,\n",
    "    mem_len=512,\n",
    "    attn_type=0,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 6144, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': np.ones((8, 6144, 512))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 6143, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 3), dtype=tf.uint8, name=None)), {'tempo': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'instrument': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'position': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'measure': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'key_sign': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'duration': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'beat': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'type': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'time_sign': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'pitch': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None), 'velocity': TensorSpec(shape=(None, 6143), dtype=tf.uint8, name=None)})>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(8).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6143, 11) (8, 3) dict_keys(['tempo', 'instrument', 'position', 'measure', 'key_sign', 'duration', 'beat', 'type', 'time_sign', 'pitch', 'velocity'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 10:41:54.912560: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())\n",
    "print(X[0].shape, X[1].shape, y.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['type'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['position'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X[0].shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[0][:, : ,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(conf.SINGLE_EMB_SIZE, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(conf.GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(X[1])\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 6143, 704])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "concat_outputs = types_concat_layer(outputs)\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 6143, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(conf.TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to preprend the genre embedding token to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 6144, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "final_sequence = sequence_concat_layer([genre_embedding[:, np.newaxis, :], encoding])\n",
    "final_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Transformer-XL uses its own positional encoding (relative instead of absolute), so it's not needed to add it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([8, 6144, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_sequence})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['type'], activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['measure'], activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['beat'], activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['position'], activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['duration'], activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'], activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'], activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'], activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'], activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'], activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6144, 8)\n",
      "(8, 6144, 256)\n",
      "(8, 6144, 131)\n",
      "(8, 6144, 128)\n",
      "(8, 6144, 136)\n",
      "(8, 6144, 256)\n",
      "(8, 6144, 129)\n",
      "(8, 6144, 128)\n",
      "(8, 6144, 25)\n",
      "(8, 6144, 153)\n",
      "(8, 6144, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tempo: [   8 6143]\n",
      "instrument: [   8 6143]\n",
      "position: [   8 6143]\n",
      "measure: [   8 6143]\n",
      "key_sign: [   8 6143]\n",
      "duration: [   8 6143]\n",
      "beat: [   8 6143]\n",
      "type: [   8 6143]\n",
      "time_sign: [   8 6143]\n",
      "pitch: [   8 6143]\n",
      "velocity: [   8 6143]\n"
     ]
    }
   ],
   "source": [
    "for k in y:\n",
    "    print(f\"{k}: {tf.shape(y[k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_scores_dict = {\n",
    "    key: out_scores[i] \n",
    "    for i, key in enumerate(conf.INPUT_RANGES)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function. The two distributions we are comparing are the input sequence (so we ignore the genre embedding token representation) and the output sequence up to the last token representation (`output[:-1]`)\n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_type_7(songs):\n",
    "    idxs = []\n",
    "    for song in songs:\n",
    "        idxs.append(tf.math.reduce_min(tf.where(song[:, 0] == 7)))\n",
    "    return tf.stack(idxs)\n",
    "\n",
    "idx = tf.keras.layers.Lambda(find_type_7)(X[0])\n",
    "\n",
    "mask = tf.cast(tf.stack([\n",
    "    tf.concat([tf.ones(idx[i]), tf.zeros(conf.SEQ_LEN - 1 - idx[i])], axis=-1)\n",
    "    for i in tf.range(tf.shape(idx)[0])\n",
    "]), tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=3.90957>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.862876>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8547277>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.54609>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.2417126>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.906821>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.8794417>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.2039227>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0347724>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.5456944>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.853795>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "losses = []\n",
    "for key in y.keys():\n",
    "    gt = tf.boolean_mask(y[key], mask)\n",
    "    pred = tf.boolean_mask(out_scores_dict[key][:, :-1, :], mask)\n",
    "    losses.append(loss_function(gt, pred))\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To these loss terms we can add some regularization terms that can help the model produce a grammatically correct sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "\n",
    "    \n",
    "class InstrumentsChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(InstrumentsChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types, instrument_scores = inputs\n",
    "        reg_term_2_list = []\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            instruments_in_batch = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 1)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_batch, _ = tf.unique(instruments_in_batch)\n",
    "            instruments_in_notes = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 3)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_notes, _, count_of_instruments_in_notes = \\\n",
    "                tf.unique_with_counts(instruments_in_notes)\n",
    "            undefined_instruments_in_notes = tf.sparse.to_dense(\n",
    "                  tf.sets.difference(tf.expand_dims(unique_instruments_in_notes, axis=0), \n",
    "                                     tf.expand_dims(unique_instruments_in_batch, axis=0)))[0]\n",
    "            indices_of_undefined_instruments = tf.where(\n",
    "                tf.expand_dims(undefined_instruments_in_notes, axis=1) == unique_instruments_in_notes)[:, 1]\n",
    "            count_of_undefined_instruments = tf.gather(count_of_instruments_in_notes, indices_of_undefined_instruments)\n",
    "            # Difference between the number of selected instruments and the number of unique instruments\n",
    "            # (AKA: number of duplicates)\n",
    "            reg_term_2_1 = tf.shape(instruments_in_batch)[0] - tf.shape(unique_instruments_in_batch)[0]\n",
    "            # Sum the number of undefined instruments in notes\n",
    "            reg_term_2_2 = tf.math.reduce_sum(count_of_undefined_instruments)\n",
    "            reg_term_2_list.append(reg_term_2_1 + reg_term_2_2)\n",
    "        return tf.math.reduce_sum(reg_term_2_list)\n",
    "\n",
    "\n",
    "class MiscTypeChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(MiscTypeChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types = inputs\n",
    "        # 1) First token must have type 0 (each batch element times 4 to keep it comparable)\n",
    "        rg1 = tf.math.reduce_sum(tf.cast(max_pred_types[:, 0] != 0, tf.int32)*4)\n",
    "        # 2) Second token must have type 1 (each batch element times 4 to keep it comparable)\n",
    "        rg2 = tf.math.reduce_sum(tf.cast(max_pred_types[:, 1] != 1, tf.int32)*4)\n",
    "        rg3s = []\n",
    "        rg4s = []\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            ones = tf.cast(tf.where(max_pred_types[b] == 1), tf.int32)\n",
    "            last_1 = -1\n",
    "            if tf.size(ones)  > 0: last_1 = tf.squeeze(ones[-1])\n",
    "            # 3) There should be at least one of each type (squared to be comparable to other losses)\n",
    "            rg3s.append((conf.INPUT_RANGES['type'] - tf.size(tf.unique(max_pred_types[b])[0]))**2)\n",
    "            # 4) From the last 1 type token there should be the following types pattern:\n",
    "            #    ..., 1, 2, 4, 5, 6, 3, ...\n",
    "            if 0 < last_1 < (tf.shape(max_pred_types)[1] - 5):\n",
    "                rg4s.append(tf.cast(max_pred_types[b, last_1 + 1] != 2, tf.int32) + \\\n",
    "                            tf.cast(max_pred_types[b, last_1 + 2] != 4, tf.int32) + \\\n",
    "                            tf.cast(max_pred_types[b, last_1 + 3] != 5, tf.int32) + \\\n",
    "                            tf.cast(max_pred_types[b, last_1 + 4] != 6, tf.int32) + \\\n",
    "                            tf.cast(max_pred_types[b, last_1 + 5] != 3, tf.int32))\n",
    "            else:\n",
    "                # Something has gone wrong, so the error would be the maximum + 1\n",
    "                rg4s.append(6)\n",
    "        return rg1 + rg2 + tf.math.reduce_sum(rg3s) + tf.math.reduce_sum(rg4s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "instruments_checker = InstrumentsChecker()\n",
    "misc_type_checker = MiscTypeChecker()\n",
    "reg_scaler = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_regularizers(y_pred):\n",
    "    # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "    max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "    ####### 0: MISC CONSTRAINTS ABOUT TOKEN TYPES ORDER #######\n",
    "    reg_term_0 = misc_type_checker(max_pred_types) * 20   # *20 to keep it comparable to other losses\n",
    "    ####### 1: PUNISHMENT FOR NON-CONSECUTIVE TYPES ##########\n",
    "    consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "    # Compute difference\n",
    "    differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "    # Compute regularization terms\n",
    "    # Difference between one element's type and the next is >= 0\n",
    "    reg_term_1_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "    # Difference between one element's type and the next is < 1\n",
    "    reg_term_1_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))  \n",
    "    reg_term_1 = reg_term_1_1 + reg_term_1_2\n",
    "    ####### 2: PUNISHMENT FOR NOTES WHOSE INSTRUMENT IS NOT DEFINED AND FOR DUPLICATE INSTRUMENTS ########\n",
    "    reg_term_2 = instruments_checker([max_pred_types, y_pred[6]])\n",
    "    ####### 3: PUNISHMENT FOR CONSECUTIVE EVENTS WITH NON-INCREASING TIMINGS ########\n",
    "    # Get the predicted measures, beats and positions\n",
    "    max_pred_measures = tf.argmax(y_pred[1], axis=2, output_type=tf.int32)\n",
    "    max_pred_beats = tf.argmax(y_pred[2], axis=2, output_type=tf.int32)\n",
    "    max_pred_positions = tf.argmax(y_pred[3], axis=2, output_type=tf.int32)\n",
    "    # Use them to compute the \"times\" matrix\n",
    "    times = max_pred_measures*max_pred_beats + max_pred_positions*max_pred_beats\n",
    "    # TODO: What did he mean by \"numeratore\"?\n",
    "    # Only consider the time matrix when the type is between 3 and 6\n",
    "    times = tf.cast(tf.where(tf.logical_and(max_pred_types >= 3, max_pred_types <= 6), times, 0), tf.float32)\n",
    "    # For type 7 fill with a very large value\n",
    "    times = tf.where(max_pred_types == 7, 1e10, times)\n",
    "    # Compute time differences between consecutive time steps\n",
    "    time_sep = times[1:] - times[:-1]\n",
    "    # Count negative time seps\n",
    "    reg_term_3 = tf.math.reduce_sum(tf.cast(time_sep < 0, tf.int32))\n",
    "    print(reg_term_0, reg_term_1, reg_term_2, reg_term_3)\n",
    "    return reg_scaler * ((tf.cast(reg_term_0, tf.float32)) + (tf.cast(reg_term_1, tf.float32)) + \\\n",
    "                         (tf.cast(reg_term_2, tf.float32)) + (tf.cast(reg_term_3, tf.float32))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2460, shape=(), dtype=int32) tf.Tensor(5339, shape=(), dtype=int32) tf.Tensor(1119, shape=(), dtype=int32) tf.Tensor(2861, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.779>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_regularizers(out_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:07:24.752058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 12:07:24.892732: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-17 12:07:24.925643: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-17 12:07:25.556184: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 12:07:25.556257: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-17 12:07:25.556264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-17 12:07:26.550406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:07:27.164674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30503 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import TransfoXLConfig, TFTransfoXLModel, TransfoXLTokenizer\n",
    "\n",
    "# Workaround for very high loads on GPUs\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "from config import Config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CUSTOM LAYERS\n",
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "\n",
    "\n",
    "# Custom intermediate layer for regularization that computes the loss related to \n",
    "# miscellaneous type errors that could happen in the generated song\n",
    "class MiscTypeChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(MiscTypeChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types = inputs\n",
    "        # 1) First token must have type 0 (each batch element times 4 to keep it comparable)\n",
    "        rg1 = tf.math.reduce_sum(tf.cast(max_pred_types[:, 0] != 0, tf.int32)*4)\n",
    "        # 2) Second token must have type 1 (each batch element times 4 to keep it comparable)\n",
    "        rg2 = tf.math.reduce_sum(tf.cast(max_pred_types[:, 1] != 1, tf.int32)*4)\n",
    "        rg3s = tf.TensorArray(dtype=tf.int32, size=tf.shape(max_pred_types)[0])\n",
    "        rg4s = tf.TensorArray(dtype=tf.int32, size=tf.shape(max_pred_types)[0])\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            ones = tf.cast(tf.where(max_pred_types[b] == 1), tf.int32)\n",
    "            last_1 = -1\n",
    "            if tf.size(ones)  > 0: last_1 = tf.squeeze(ones[-1])\n",
    "            # 3) There should be at least one of each type (squared to be comparable to other losses)\n",
    "            rg3s = rg3s.write(b, (conf.INPUT_RANGES['type'] - tf.size(tf.unique(max_pred_types[b])[0]))**2)\n",
    "            # 4) From the last 1 type token there should be the following types pattern:\n",
    "            #    ..., 1, 2, 4, 5, 6, 3, ...\n",
    "            if 0 < last_1 < (tf.shape(max_pred_types)[1] - 5):\n",
    "                rg4s = rg4s.write(b, (tf.cast(max_pred_types[b, last_1 + 1] != 2, tf.int32) + \\\n",
    "                                      tf.cast(max_pred_types[b, last_1 + 2] != 4, tf.int32) + \\\n",
    "                                      tf.cast(max_pred_types[b, last_1 + 3] != 5, tf.int32) + \\\n",
    "                                      tf.cast(max_pred_types[b, last_1 + 4] != 6, tf.int32) + \\\n",
    "                                      tf.cast(max_pred_types[b, last_1 + 5] != 3, tf.int32)))\n",
    "            else:\n",
    "                # Something has gone wrong, so the error would be the maximum + 1\n",
    "                rg4s = rg4s.write(b, 6)\n",
    "        return rg1 + rg2 + tf.math.reduce_sum(rg3s.stack()) + tf.math.reduce_sum(rg4s.stack())\n",
    "\n",
    "\n",
    "# Custom intermediate layer for regularization that computes the loss related to duplicate instruments\n",
    "# definition and instruments that are used wrongly in the notes.\n",
    "class InstrumentsChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(InstrumentsChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types, instrument_scores = inputs\n",
    "        reg_term_2_list = tf.TensorArray(dtype=tf.int32, size=tf.shape(max_pred_types)[0])\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            instruments_in_batch = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 1)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_batch, _ = tf.unique(instruments_in_batch)\n",
    "            instruments_in_notes = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 3)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_notes, _, count_of_instruments_in_notes = \\\n",
    "                tf.unique_with_counts(instruments_in_notes)\n",
    "            undefined_instruments_in_notes = tf.sparse.to_dense(\n",
    "                  tf.sets.difference(tf.expand_dims(unique_instruments_in_notes, axis=0), \n",
    "                                     tf.expand_dims(unique_instruments_in_batch, axis=0)))[0]\n",
    "            indices_of_undefined_instruments = tf.where(\n",
    "                tf.expand_dims(undefined_instruments_in_notes, axis=1) == unique_instruments_in_notes)[:, 1]\n",
    "            count_of_undefined_instruments = tf.gather(count_of_instruments_in_notes, indices_of_undefined_instruments)\n",
    "            # Difference between the number of selected instruments and the number of unique instruments\n",
    "            # (AKA: number of duplicates)\n",
    "            reg_term_2_1 = tf.shape(instruments_in_batch)[0] - tf.shape(unique_instruments_in_batch)[0]\n",
    "            # Sum the number of undefined instruments in notes\n",
    "            reg_term_2_2 = tf.math.reduce_sum(count_of_undefined_instruments)\n",
    "            reg_term_2_list = reg_term_2_list.write(b, reg_term_2_1 + reg_term_2_2)\n",
    "        return tf.math.reduce_sum(reg_term_2_list.concat())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation function (to be called within a scope in case of MultiGPU training)\n",
    "def create_model(input_shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), num_genres=len(conf.accepted_subgenres), \n",
    "                 use_regularization=True, use_masking_layers=False, reg_loss_scale=conf.REG_LOSS_SCALE):\n",
    "    \n",
    "    # Get input shapes\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate transformer decoder (n_emb % n_head must be 0)\n",
    "    decoder = TFTransfoXLModel(TransfoXLConfig(\n",
    "        # some of these were taken by \n",
    "        # https://github.com/slSeanWU/jazz_transformer/blob/master/transformer_xl/model_aug.py\n",
    "        vocab_size=0,\n",
    "        div_val=12,      # creates 12 blocks of 512\n",
    "        n_head=2,\n",
    "        n_layer=6,\n",
    "        d_head=256,      # d_model // n_head\n",
    "        d_model=512,\n",
    "        d_embed=512,\n",
    "        d_inner=2048,\n",
    "        mem_len=512,\n",
    "        attn_type=0,\n",
    "    ))\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs',  dtype=tf.int32)\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres', dtype=tf.float32)\n",
    "    \n",
    "    # Define loss\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # Regularization layers\n",
    "    subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "    misc_type_checker = MiscTypeChecker()\n",
    "    instruments_checker = InstrumentsChecker()\n",
    "    reg_scaler = tf.constant(reg_loss_scale, dtype=tf.float32)\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['type'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='type_embeddings'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'],    conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='measure_embeddings'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='beat_embeddings'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['position'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='position_embeddings'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='duration_embeddings'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='pitch_embeddings'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='instrument_embeddings'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='velocity_embeddings'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='key_sign_embeddings'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'],  conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='time_sign_embeddings'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='tempo_embeddings')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(conf.GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    input_concat_layer         = tf.keras.layers.Concatenate(axis=2)\n",
    "    sequence_concat_layer      = tf.keras.layers.Concatenate(axis=1)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(conf.TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = conf.get_positional_embedding_matrix()\n",
    "    positional_encoding        = tf.repeat(positional_encoding_matrix[tf.newaxis, :, :], tf.shape(songs)[0], axis=0)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['type'],       name='type_scores'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['measure'],    name='measure_scores'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['beat'],       name='beat_scores'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['position'],   name='position_scores'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['duration'],   name='duration_scores'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'],      name='pitch_scores'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], name='instrument_scores'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'],   name='velocity_scores'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'],   name='keysign_scores'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'],  name='timesign_scores'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'],      name='tempo_scores')\n",
    "    ]\n",
    "    \n",
    "    output_probs_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Softmax(name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Softmax(name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Softmax(name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Softmax(name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Softmax(name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Softmax(name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Softmax(name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Softmax(name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Softmax(name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Softmax(name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Softmax(name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Masking layers\n",
    "    if use_masking_layers:\n",
    "        type_masking_layer = MaskTypeProbabilitiesLayer()\n",
    "        activations_masking =  MaskingActivationLayer()\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    input_embedding   = input_concat_layer(embeddings)\n",
    "    input_embedding   = encoding_processing_layer(input_embedding)\n",
    "    input_embedding   = sequence_concat_layer([genre_embedding[:, np.newaxis, :], input_embedding])\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output)[:,:-1,:] \n",
    "                         for i in range(len(output_dense_layers))]\n",
    "    \n",
    "    # TODO: Masking layers are commented out\n",
    "    # We don't care about the last scores, since they refer to a token that's out of bounds.\n",
    "    # if use_masking_layers:\n",
    "    #     type_mask           = type_masking_layer(songs, training=True)\n",
    "    #     types_probabilities = output_probs_layers[0](out_scores[0], type_mask) # BATCH_SIZE * SEQ_LEN-1 * 8\n",
    "    #     full_mask           = activations_masking([songs, out_scores, types_probabilities])\n",
    "    #     # Unpack the final masks into a list of masks\n",
    "    #     index = 0; masks = []          \n",
    "    #     for key in conf.INPUT_RANGES:\n",
    "    #         if key != 'type':\n",
    "    #             masks.append(full_mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "    #             index += conf.INPUT_RANGES[key]\n",
    "    #     # Call all the softmax layers\n",
    "    #     out_probabilities = [types_probabilities] + [\n",
    "    #         output_probs_layers[i](out_scores[i], masks[i-1]) \n",
    "    #         for i in range(1, len(output_dense_layers))]\n",
    "    # else:\n",
    "    out_probabilities = [output_probs_layers[i](out_scores[i]) \n",
    "                         for i in range(len(output_dense_layers))]\n",
    "                \n",
    "    out_probabilities_dict = {\n",
    "        key: out_probabilities[i] \n",
    "        for i, key in enumerate(conf.INPUT_RANGES)\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=[songs, genres], \n",
    "                           outputs=out_probabilities_dict, \n",
    "                           name='music_generation_model')\n",
    "    \n",
    "    # Before computing losses, mask probabilities so that nothing after the first 7\n",
    "    # in the original song counts.\n",
    "    @tf.function\n",
    "    def find_type_7(songs):\n",
    "        mask = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        for i in tf.range(tf.shape(songs)[0]):\n",
    "            end_song_idx = tf.math.reduce_min(tf.where(songs[i, :, 0] == 7))\n",
    "            mask = mask.write(i, tf.concat([\n",
    "                tf.ones(end_song_idx), \n",
    "                tf.zeros(conf.SEQ_LEN - 1 - end_song_idx)], axis=-1))\n",
    "        return mask.stack()\n",
    "\n",
    "    end_song_mask = tf.keras.layers.Lambda(find_type_7)(songs)\n",
    "    end_song_mask = tf.cast(end_song_mask, tf.bool)\n",
    "    \n",
    "    # Define loss\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        return loss_function(y_true, y_pred) * \\\n",
    "            (1. / (conf.GLOBAL_BATCH_SIZE * tf.cast(tf.shape(y_true)[0], tf.float32)))\n",
    "    \n",
    "    # Define regularizers\n",
    "    def custom_regularizers(y_pred):\n",
    "        # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "        max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "        \n",
    "        ####### 0: MISC CONSTRAINTS ABOUT TOKEN TYPES ORDER #######\n",
    "        reg_term_0 = misc_type_checker(max_pred_types) * 20   # *20 to keep it comparable to other losses\n",
    "        \n",
    "        ####### 1: PUNISHMENT FOR NON-CONSECUTIVE TYPES ##########\n",
    "        consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "        # Compute difference\n",
    "        differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "        # Compute regularization terms\n",
    "        # Difference between one element's type and the next is >= 0\n",
    "        reg_term_1_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "        # Difference between one element's type and the next is < 1\n",
    "        reg_term_1_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))  \n",
    "        reg_term_1 = reg_term_1_1 + reg_term_1_2\n",
    "        \n",
    "        ####### 2: PUNISHMENT FOR NOTES WHOSE INSTRUMENT IS NOT DEFINED AND FOR DUPLICATE INSTRUMENTS ########\n",
    "        reg_term_2 = instruments_checker([max_pred_types, y_pred[6]])\n",
    "        \n",
    "        ####### 3: PUNISHMENT FOR CONSECUTIVE EVENTS WITH NON-INCREASING TIMINGS ########\n",
    "        # Get the predicted measures, beats and positions\n",
    "        max_pred_measures = tf.argmax(y_pred[1], axis=2, output_type=tf.int32)\n",
    "        max_pred_beats = tf.argmax(y_pred[2], axis=2, output_type=tf.int32)\n",
    "        max_pred_positions = tf.argmax(y_pred[3], axis=2, output_type=tf.int32)\n",
    "        # Use them to compute the \"times\" matrix\n",
    "        times = max_pred_measures*max_pred_beats + max_pred_positions*max_pred_beats\n",
    "        # TODO: What did he mean by \"numeratore\"?\n",
    "        # Only consider the time matrix when the type is between 3 and 6\n",
    "        times = tf.cast(tf.where(tf.logical_and(max_pred_types >= 3, max_pred_types <= 6), times, 0), tf.float32)\n",
    "        # For type 7 fill with a very large value\n",
    "        times = tf.where(max_pred_types == 7, 1e10, times)\n",
    "        # Compute time differences between consecutive time steps\n",
    "        time_sep = times[1:] - times[:-1]\n",
    "        # Count negative time seps\n",
    "        reg_term_3 = tf.math.reduce_sum(tf.cast(time_sep < 0, tf.int32))\n",
    "        \n",
    "        ####### PUT TOGETHER THE REGULARIZATION TERMS #######\n",
    "        return reg_scaler * ((tf.cast(reg_term_1, tf.float32)) + (tf.cast(reg_term_2, tf.float32)) + (tf.cast(reg_term_3, tf.float32)))\n",
    "    \n",
    "    # Add losses\n",
    "    for i, k in enumerate(conf.INPUT_RANGES):\n",
    "        loss_name = f'{k}_loss'\n",
    "        gt = tf.boolean_mask(songs[:,:,i], end_song_mask)\n",
    "        pred = tf.boolean_mask(out_probabilities[i], end_song_mask)\n",
    "        loss = custom_loss(y_true = gt, y_pred = pred)\n",
    "        model.add_loss(loss)\n",
    "        model.add_metric(loss, name=loss_name)\n",
    "    \n",
    "    if use_regularization:\n",
    "        # Note: we don't mask in regularization, because we don't use a ground truth\n",
    "        # Here we just make the model learn how to produce a syntactically good output.\n",
    "        reg_loss = custom_regularizers(out_probabilities)\n",
    "        model.add_loss(reg_loss)\n",
    "        model.add_metric(reg_loss, name='regularization_loss')\n",
    "    \n",
    "    # Compile and return\n",
    "    model.compile(optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU/CPU device\n"
     ]
    }
   ],
   "source": [
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = create_model(num_genres=3)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = create_model(num_genres=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(8).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 12:07:34.705965: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([8, 6143, 8]), TensorShape([8, 6143, 256]), TensorShape([8, 6143, 131]), TensorShape([8, 6143, 128]), TensorShape([8, 6143, 136]), TensorShape([8, 6143, 256]), TensorShape([8, 6143, 129]), TensorShape([8, 6143, 128]), TensorShape([8, 6143, 25]), TensorShape([8, 6143, 153]), TensorShape([8, 6143, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model(X)\n",
    "print([v.shape for _, v in output.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([9.35345088e-05, 1.16941512e-04, 1.07550266e-04, ...,\n",
       "        7.92284191e-05, 8.22113507e-05, 7.97772154e-05], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00029678, 0.00029892, 0.00029174, ..., 0.000187  , 0.00017035,\n",
       "        0.00016405], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00024943, 0.00024625, 0.0002537 , ..., 0.00021522, 0.00022814,\n",
       "        0.00024516], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00016675, 0.00017065, 0.00019175, ..., 0.00025547, 0.00025231,\n",
       "        0.00024597], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00029705, 0.00028766, 0.00026662, ..., 0.00032816, 0.00028016,\n",
       "        0.00029753], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00018523, 0.00019269, 0.00021214, ..., 0.00040672, 0.00029344,\n",
       "        0.00030372], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00017687, 0.0003296 , 0.00034186, ..., 0.00031108, 0.00019952,\n",
       "        0.00024053], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00018798, 0.00021064, 0.0002555 , ..., 0.00028803, 0.00033663,\n",
       "        0.00034896], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00027787, 0.00025871, 0.00023527, ..., 0.00020504, 0.00022361,\n",
       "        0.00022953], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00020514, 0.00023288, 0.00027515, ..., 0.00022295, 0.00022193,\n",
       "        0.00023938], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3742,), dtype=float32, numpy=\n",
       " array([0.00020739, 0.0001982 , 0.00019451, ..., 0.00015532, 0.00016084,\n",
       "        0.00016417], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=15.692>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
