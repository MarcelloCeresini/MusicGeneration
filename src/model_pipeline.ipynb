{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Volpe\\anaconda3\\envs\\ai3i\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "  except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "import utils\n",
    "import config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.load(conf.lmda_genres_tf_data_path)   \\\n",
    "dataset = tf.data.Dataset.load(conf.tf_data_path)               \\\n",
    "    .cache()                                                    \\\n",
    "    .shuffle(conf.SHUFFLE_SIZE)                                 \\\n",
    "    .batch(conf.BATCH_SIZE)                                     \\\n",
    "    .prefetch(conf.PREFETCH_SIZE)                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song_shape: (2, 1023, 11)\n",
      "\n",
      "Decoder output shape: (2, 1024, 512)\n",
      "\n",
      "Output logit #0: (2, 1024, 8)\n",
      "Output logit #1: (2, 1024, 256)\n",
      "Output logit #2: (2, 1024, 131)\n",
      "Output logit #3: (2, 1024, 128)\n",
      "Output logit #4: (2, 1024, 136)\n",
      "Output logit #5: (2, 1024, 256)\n",
      "Output logit #6: (2, 1024, 129)\n",
      "Output logit #7: (2, 1024, 128)\n",
      "Output logit #8: (2, 1024, 25)\n",
      "Output logit #9: (2, 1024, 153)\n",
      "Output logit #10: (2, 1024, 49)\n"
     ]
    }
   ],
   "source": [
    "song_batch = next(dataset.take(1).as_numpy_iterator())[0][:, :conf.SEQ_LEN-1, :]\n",
    "print(\"Song_shape: {}\\n\".format(song_batch.shape))\n",
    "\n",
    "decoder_output = tf.random.uniform((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM), minval=-1, maxval=1)\n",
    "print(f\"Decoder output shape: {decoder_output.shape}\\n\")\n",
    "\n",
    "out_logits = [layer(decoder_output) for layer in conf.output_dense_layers]\n",
    "for i, out_logit_part in enumerate(out_logits):\n",
    "    print(f\"Output logit #{i}: {out_logit_part.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1024, 8])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskTypeProbabilitiesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def create_mask(self, inputs):\n",
    "        batch_gt_types = inputs\n",
    "        mask = tf.TensorArray(tf.bool, size=conf.SEQ_LEN)\n",
    "        mask = mask.write(0, tf.constant([True, False, False, False, False, False, False, False], dtype=tf.bool))\n",
    "        for i in tf.range(conf.SEQ_LEN-1):\n",
    "            token_type = batch_gt_types[i]\n",
    "            if token_type == 0: # only start of song token: cannot be anything else than instrument choice (1)\n",
    "                type_mask = tf.constant([False, True, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 1: # we reached instrument choice: cannot be anything else than instrument choice (1) or start of events (2)\n",
    "                type_mask = tf.constant([False, True, True, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type >= 2 and token_type < 7: # we reached start of events or notes\n",
    "                type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change ending token to type 7s -> 7000000000\n",
    "                type_mask = tf.constant([True, False, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            else:\n",
    "                # ERROR. Define a random type mask so that it's defined in all branches for tf.function\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            mask = mask.write(i+1, type_mask)\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Takes as input the ground truth song (at training time) or the logits (at testing time) \n",
    "        and computes a mask for the type probabilities.\n",
    "        '''\n",
    "        if training:\n",
    "            # Use the groundtruth song as a target\n",
    "            song        = inputs\n",
    "            gt_types    = song[:,:,0]       # Get the token types from the song (batch_size x seq_len-1)\n",
    "            # Iterate over the batch to collect the appropriate masks from the song\n",
    "            masks = tf.map_fn(fn=self.create_mask, \n",
    "                elems=gt_types, \n",
    "                fn_output_signature=tf.TensorSpec(\n",
    "                    (conf.SEQ_LEN, conf.INPUT_RANGES['type']), \n",
    "                    dtype=tf.bool)\n",
    "            )\n",
    "            return masks\n",
    "        else:\n",
    "            # Compute the types and their masks one by one based on the type chosen at the previous iteration\n",
    "            # TODO: implement this branch\n",
    "            pass\n",
    "\n",
    "mask_probabilities = MaskTypeProbabilitiesLayer()(song_batch, training=True)\n",
    "mask_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.4315946 , 0.56840533, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.0821274 , 0.91787255, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.29944634, 0.70055366, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With these masks we can compute the probabilities for the token types\n",
    "activations = [tf.keras.layers.Softmax()]*len(conf.INPUT_RANGES)\n",
    "\n",
    "types_probabilities = activations[0](out_logits[0], mask_probabilities) # (last out logit predicts a token that's out of bound in our sequence)\n",
    "types_probabilities[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the second part of the layer: given the type probabilities, compute the other constraints\n",
    "class MaskingActivationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        self.default_mask = conf.default_mask\n",
    "        self.full_mask    = conf.full_mask\n",
    "        self._numerators  = conf.numerators\n",
    "        self._tot_numerators = conf.tot_numerators\n",
    "        self.triang_mask = tf.cast(\n",
    "            tf.repeat(\n",
    "                tf.expand_dims(np.tri(conf.SEQ_LEN-1), axis=-1),     # Much more efficient to do it like this: it's a lower triangular matrix\n",
    "                repeats=len(conf.INPUT_RANGES), axis=-1), \n",
    "            dtype=tf.float32)                                        # Create a seq_len x seq_len x 10 float tensor\n",
    "\n",
    "    @tf.function\n",
    "    def get_max_beat_from_time_sign(self, time_sign):\n",
    "        idx = tf.math.floormod(time_sign, self._tot_numerators)\n",
    "        return tf.gather(self._numerators, idx) - 1\n",
    "\n",
    "    def get_mask(self, inputs):\n",
    "        chosen_type, song, scores, index_tensor = inputs\n",
    "        chosen_type  = tf.cast(chosen_type, dtype=tf.int32)               # 1\n",
    "        song         = tf.cast(song, dtype=tf.int32)                      # (SEQ_LEN-1) * 11\n",
    "        index_tensor = tf.cast(index_tensor, dtype=tf.int32)              # 1\n",
    "        default_token_parts = [True]*(len(conf.INPUT_RANGES)-1)\n",
    "        default_flag = False\n",
    "\n",
    "        # DEFAULT CREATION (tensorflow requires the variable to be present in all possible branches when if/else are present)\n",
    "        min_measure           = tf.constant(-1, dtype=tf.int32)\n",
    "        min_beat              = tf.constant(-1, dtype=tf.int32)\n",
    "        min_position          = tf.constant(-1, dtype=tf.int32)\n",
    "        allowed_instruments   = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "        allowed_key_sign      = tf.constant(-1, dtype=tf.int32)\n",
    "        allowed_time_sign     = tf.constant(-1, dtype=tf.int32)\n",
    "        allowed_tempo         = tf.constant(-1, dtype=tf.int32)\n",
    "        forbidden_instruments_flag = False\n",
    "        forbidden_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "        forbidden_key_sign    = tf.constant(-1, dtype=tf.int32)\n",
    "        forbidden_time_sign   = tf.constant(-1, dtype=tf.int32)\n",
    "        forbidden_tempo       = tf.constant(-1, dtype=tf.int32)\n",
    "        \n",
    "        # Check all different possibilities\n",
    "\n",
    "        if chosen_type == 0 or chosen_type == 2: # TODO: change 0s to 7s at the end of the song\n",
    "            # Original comments: \n",
    "            # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "            # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "            default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "\n",
    "        # Instrument selection\n",
    "        elif chosen_type == 1: # false only for type and instrument type (the ones that you can choose)\n",
    "            # TODO: this function was GREATLY changed. Is it ok?    \n",
    "            if tf.size(tf.where(song[:index_tensor, 0] == 1)[:,0]) == 0:\n",
    "                # Choice of first instrument\n",
    "                default_token_parts = [True, True, True, True, True, False, True, True, True, True]  # TODO: Element 6 should not be default = True right?\n",
    "                default_flag = True\n",
    "            else:\n",
    "                # TODO: Original is this:\n",
    "                # forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                #     song[:, 6],\n",
    "                #     tf.squeeze(tf.where(song[:, 0] == 2))           \n",
    "                # ))\n",
    "                # I don't think it does what it's supposed to. \n",
    "                # Forbidden instruments should be a 1D tensor of all previously defined instruments, right?\n",
    "                # Instruments are defined with type 1, right?\n",
    "                forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                    song[:index_tensor, 6], \n",
    "                    tf.where(song[:index_tensor, 0] == 1)[:,0]        # Cast to 1D array\n",
    "                ))\n",
    "                forbidden_instruments_flag = True\n",
    "        \n",
    "        # Notes\n",
    "        elif chosen_type == 3: # Note has same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "            min_measure = song[index_tensor, 1]   # It has to be >= than the last measure\n",
    "            # If in the MEASURE SCORES the MAX SCORE between all possible measures == min_measure, the measure is min_measure.\n",
    "            # In this case, we need to make sure that beat >= last_beat\n",
    "            # TODO: I changed this. Is it okay? We are trying to get the part of the score that's between 0 and 256 right? (there is no type in my scores)\n",
    "            if tf.math.argmax(\n",
    "                scores[:conf.INPUT_RANGES[\"measure\"]], \n",
    "                    output_type=tf.int32) == min_measure:\n",
    "                \n",
    "                min_beat = song[index_tensor,2]      # It has to be >= than the last beat when measure is the same\n",
    "                if tf.math.argmax(scores[\n",
    "                    conf.INPUT_RANGES[\"measure\"] : \n",
    "                    conf.INPUT_RANGES[\"measure\"] + conf.INPUT_RANGES[\"beat\"]], \n",
    "                    output_type=tf.int32) == min_beat:\n",
    "\n",
    "                    min_position = song[index_tensor,3]  # It has to be >= than the last position (if beat and measure are the same)\n",
    "                else:\n",
    "                    min_position = tf.constant(0, dtype=tf.int32)\n",
    "            else:\n",
    "                min_beat = tf.constant(0, dtype=tf.int32)\n",
    "                min_position = tf.constant(0, dtype=tf.int32)\n",
    "            \n",
    "            # Only some instruments, key signs, time signs and tempos are allowed for these events: \n",
    "            # - for instruments, the allowed ones are the ones that have been defined previously with type = 1\n",
    "            # - for the others, the allowed ones are the ones that are collected right before the note from event types 4, 5 and 6\n",
    "            allowed_instruments, _ = tf.unique(tf.gather(\n",
    "                song[:index_tensor, 6], \n",
    "                tf.where(song[:index_tensor, 0] == 1)[:,0]\n",
    "            ))\n",
    "            # TODO: There are cases where there is not a LAST key_sign/time_sign, ...\n",
    "            # If the model chooses 3, we cannot be certain that there is at least a 4, 5 or 6 before it\n",
    "            # In these cases we use the default masks\n",
    "            allowed_key_signs = tf.gather(\n",
    "                song[:index_tensor, 8], \n",
    "                tf.where(song[:index_tensor, 0] == 4)[:,0]) # if type == 4 --> read the LAST key_sign\n",
    "            if tf.size(allowed_key_signs) > 0:\n",
    "                allowed_key_sign = allowed_key_signs[-1]\n",
    "\n",
    "            allowed_time_signs = tf.gather(\n",
    "                song[:index_tensor, 9], \n",
    "                tf.where(song[:index_tensor, 0] == 5)[:,0]) # if type == 5 --> read the LAST time_sign\n",
    "            if tf.size(allowed_time_signs) > 0:\n",
    "                allowed_time_sign = allowed_time_signs[-1]\n",
    "            \n",
    "            allowed_tempos = tf.gather(\n",
    "                song[:index_tensor, 10], \n",
    "                tf.where(song[:index_tensor, 0] == 6)[:,0]) # if type == 6 --> read the LAST tempo\n",
    "            if tf.size(allowed_tempos) > 0:\n",
    "                allowed_tempo = allowed_tempos[-1]\n",
    "        \n",
    "        # key_sign, time_sign, tempo\n",
    "        elif chosen_type >= 4 and chosen_type <= 6:\n",
    "            # If last event is at the beginning of a measure, you can add an event at the same time\n",
    "            if song[index_tensor, 3] == 0 and song[index_tensor, 2] == 0:  # if beat and position == 0, the event can be at this measure\n",
    "                min_measure = song[index_tensor, 1]\n",
    "            else:\n",
    "                min_measure = song[index_tensor, 1] + 1                   # otherwise it goes to the next measure\n",
    "            # Fine-grain checks\n",
    "            # TODO: As before, there are cases where there is not a LAST key_sign/time_sign. \n",
    "            # In these cases we should use the default masks.\n",
    "            if chosen_type == 4:\n",
    "                # Cannot put the same key_sign again\n",
    "                forbidden_key_signs = tf.gather(\n",
    "                    song[:index_tensor, 8], \n",
    "                    tf.where(song[:index_tensor, 0] == 4)[:,0]) # if type == 4 --> read the LAST key_sign\n",
    "                if tf.size(forbidden_key_signs) > 0:\n",
    "                    forbidden_key_sign = forbidden_key_signs[-1]\n",
    "            elif chosen_type == 5:\n",
    "                # Cannot put the same time_sign again\n",
    "                forbidden_time_signs = tf.gather(\n",
    "                    song[:index_tensor, 9], \n",
    "                    tf.where(song[:index_tensor, 0] == 5)[:,0]) # if type == 5 --> read the LAST time_sign\n",
    "                if tf.size(forbidden_time_signs) > 0:\n",
    "                    forbidden_time_sign = forbidden_time_signs[-1]\n",
    "            elif chosen_type == 6:\n",
    "                # Cannot put the same tempo again\n",
    "                forbidden_tempos = tf.gather(\n",
    "                    song[:index_tensor, 10], \n",
    "                    tf.where(song[:index_tensor, 0] == 6)[:,0]) # if type == 6 --> read the LAST tempo\n",
    "                if tf.size(forbidden_tempos) > 9:\n",
    "                    forbidden_tempo = forbidden_tempos[-1]\n",
    "\n",
    "        elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "            default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "\n",
    "        else:\n",
    "            # cannot RAISE inside tf graph, because it WILL pass from every path\n",
    "            default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "            # raise ValueError(\"Impossible that chosen type isn't in [1,7] --> {}\".format(chosen_type))\n",
    "        \n",
    "        # Put together the masks\n",
    "        if default_flag: \n",
    "            # No manual masking required, either \"can freely choose this part of the token\" (True) or \n",
    "            # \"can only choose default for this part of the token\" (False)\n",
    "            return tf.concat(\n",
    "                    # Default mask only allows to predict a 0\n",
    "                    # Full mask allows to predict any value\n",
    "                    [self.default_mask[i] if default_token_parts[i] else self.full_mask[i] \n",
    "                        for i in range(len(default_token_parts))],\n",
    "                    axis=-1)\n",
    "        else: \n",
    "            # We need to do manual masking\n",
    "            measure_mask     = self.default_mask[0]\n",
    "            beat_mask        = self.default_mask[1]\n",
    "            position_mask    = self.default_mask[2]\n",
    "            duration_mask    = self.default_mask[3]\n",
    "            pitch_mask       = self.default_mask[4]\n",
    "            instruments_mask = self.default_mask[5]\n",
    "            velocity_mask    = self.default_mask[6]\n",
    "            key_sign_mask    = self.default_mask[7]\n",
    "            time_sign_mask   = self.default_mask[8]\n",
    "            tempo_mask       = self.default_mask[9]\n",
    "            \n",
    "            if not forbidden_instruments_flag:\n",
    "                # TODO: I didn't understand this comment\n",
    "                # Measure mask, beat and position go to default if type==2 and forbidden_instruments_flag == True\n",
    "                # so if forbidden_instruments_flag == False --> you can change it\n",
    "                measure_mask = tf.cast(\n",
    "                    tf.concat([\n",
    "                        tf.repeat([False], min_measure),        # Can be equal to or greater than min_measure\n",
    "                        tf.repeat([True], conf.INPUT_RANGES[\"measure\"]-min_measure)], \n",
    "                        axis=-1),\n",
    "                    dtype=tf.dtypes.bool)\n",
    "\n",
    "                if min_beat != -1:\n",
    "                    # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                    # TODO: Did not understand this function\n",
    "                    max_beat = self.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                    # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                    beat_mask = tf.cast(tf.concat([\n",
    "                        tf.repeat([False], min_beat),\n",
    "                        tf.repeat([True],  max_beat-min_beat), \n",
    "                        tf.repeat([False], conf.INPUT_RANGES[\"beat\"]-max_beat)],\n",
    "                        axis=-1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "\n",
    "                if min_position != -1:\n",
    "                    position_mask = tf.cast(tf.concat([\n",
    "                        tf.repeat([False], min_position), \n",
    "                        tf.repeat([True],  conf.INPUT_RANGES[\"position\"]-min_position)],\n",
    "                        axis=-1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "\n",
    "            else:\n",
    "                instruments_mask = tf.sparse.SparseTensor(  # Forbidden instruments\n",
    "                    indices= tf.expand_dims(tf.cast(forbidden_instruments, tf.int64), axis=-1),\n",
    "                    values = tf.zeros_like(forbidden_instruments),\n",
    "                    dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                )\n",
    "                instruments_mask = tf.cast(\n",
    "                    tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "                # FORBIDDEN INSTRUMENTS is ONLY USED WHEN type==1 --> measure_mask, beat, position are all default\n",
    "\n",
    "            if chosen_type==3:\n",
    "                # Mask that's true only for defined instruments\n",
    "                instruments_mask = tf.sparse.SparseTensor( # Allowed instruments\n",
    "                    indices=tf.expand_dims(tf.cast(allowed_instruments, tf.int64), axis=-1),\n",
    "                    values=tf.ones_like(allowed_instruments),               # TODO: this was zeros_like. Shouldn't it be inverted tho?\n",
    "                    dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                )\n",
    "                instruments_mask = tf.cast(\n",
    "                    tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=1), # TODO: the default value was 0. Shouldn't it be 1 tho?\n",
    "                    dtype=tf.dtypes.bool)\n",
    "                \n",
    "                # TODO: I think this part should be indented like this\n",
    "                # Deal with key signs and time signs\n",
    "                if allowed_key_sign != -1:\n",
    "                    key_sign_mask = tf.convert_to_tensor([\n",
    "                        i == allowed_key_sign \n",
    "                        for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                        dtype=tf.bool)\n",
    "                elif forbidden_key_sign != -1:\n",
    "                    # Inverse\n",
    "                    key_sign_mask = tf.convert_to_tensor([\n",
    "                        i != forbidden_key_sign \n",
    "                        for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                        dtype=tf.bool)\n",
    "                else: \n",
    "                    pass\n",
    "\n",
    "                if allowed_time_sign != -1:\n",
    "                    time_sign_mask = tf.convert_to_tensor([\n",
    "                        i == allowed_time_sign \n",
    "                        for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                        dtype=tf.bool)\n",
    "                elif forbidden_time_sign != -1:\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                if allowed_tempo != -1:\n",
    "                    tempo_mask = tf.convert_to_tensor([\n",
    "                        i == allowed_tempo \n",
    "                        for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                        dtype=tf.bool)\n",
    "                elif forbidden_tempo != -1:\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            return tf.concat([\n",
    "                measure_mask, beat_mask, position_mask, duration_mask,\n",
    "                pitch_mask, instruments_mask, velocity_mask, key_sign_mask,\n",
    "                time_sign_mask, tempo_mask], axis=-1)\n",
    "\n",
    "\n",
    "    def get_mask_for_all_tokens(self, inputs): \n",
    "        '''\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "        Inputs are for a SINGLE ELEMENT OF A BATCH of size SEQ_LEN*(1+11+1391) where 1391 is the summed length of logits (minus the type)\n",
    "        '''\n",
    "        # Collect inputs from longer tensor\n",
    "        chosen_types, song, scores = inputs\n",
    "        # Result = SEQ_LEN-1 matrices --> first one has only first token full (others are 0), second one has first two tokens full (others are 0) etc\n",
    "        triang_song = tf.math.multiply(\n",
    "            tf.repeat(tf.expand_dims(song, axis=0), repeats=[conf.SEQ_LEN-1], axis=0),\n",
    "            self.triang_mask\n",
    "        )\n",
    "        # Indexes\n",
    "        index_tensor = tf.range(conf.SEQ_LEN-1, dtype=tf.float32)\n",
    "        # TODO: to speedup we could change it to vectorized_map, but we need to try it out\n",
    "        final_masks = tf.map_fn(\n",
    "            fn=self.get_mask, \n",
    "            elems=(\n",
    "                chosen_types,    # (SEQ_LEN-1)*1                 --> 1\n",
    "                triang_song,     # (SEQ_LEN-1)*(SEQ_LEN-1)*11    --> (SEQ_LEN-1)*11\n",
    "                scores,          # (SEQ_LEN-1)*1391              --> 1391\n",
    "                index_tensor     # (SEQ_LEN-1)*1                 --> 1\n",
    "            ), \n",
    "            fn_output_signature=tf.TensorSpec(\n",
    "                shape=(conf.input_ranges_sum - conf.INPUT_RANGES['type']),\n",
    "                dtype=tf.bool  # TODO: change it accordingly to the output signature\n",
    "        ))\n",
    "        return final_masks\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        songs, out_logits, types_probabilities = inputs\n",
    "        chosen_types  = tf.expand_dims(tf.math.argmax(types_probabilities[:,:-1], axis=2), axis=-1)\n",
    "        concat_logits = tf.concat(out_logits[1:], axis=-1)                 # Concatenate all logits (except type) into a tensor batch_size x seq_len x 1391\n",
    "        masks = tf.map_fn(fn=self.get_mask_for_all_tokens, elems=(         # Iterate function over batch dimension \n",
    "                tf.cast(chosen_types, concat_logits.dtype),                # BATCH*(SEQ_LEN-1)*1\n",
    "                tf.cast(songs,   concat_logits.dtype),                     # BATCH*(SEQ_LEN-1)*11\n",
    "                concat_logits[:, :conf.SEQ_LEN-1, :]                       # BATCH*(SEQ_LEN-1)*1391\n",
    "            ), fn_output_signature=tf.TensorSpec(                          # Total: a BATCH * SEQ_LEN-1 * 1403 tensor\n",
    "                (conf.SEQ_LEN-1, conf.input_ranges_sum - conf.INPUT_RANGES['type']),\n",
    "                dtype=tf.bool\n",
    "            ))\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_input = tf.keras.layers.Input(shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), dtype=tf.int8)\n",
    "\n",
    "mask_type_probabilities_layer = MaskTypeProbabilitiesLayer()\n",
    "final_masking_layer = MaskingActivationLayer()\n",
    "activations = [tf.keras.layers.Softmax()]*len(conf.INPUT_RANGES)\n",
    "\n",
    "mask_for_type_probabilities = mask_type_probabilities_layer(song_input, training=True)\n",
    "type_probabilities = activations[0](out_logits[0], mask_for_type_probabilities)\n",
    "final_mask = final_masking_layer([song_input, out_logits, type_probabilities])\n",
    "\n",
    "# Unpack the final masks\n",
    "index = 0\n",
    "masks = []\n",
    "for key in conf.INPUT_RANGES:\n",
    "    if key != 'type':       # We have already checked for the type\n",
    "        masks.append(final_mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "        index += conf.INPUT_RANGES[key]\n",
    "\n",
    "model = tf.keras.Model(inputs=song_input, outputs=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([2, 1023, 256]),\n",
       " TensorShape([2, 1023, 131]),\n",
       " TensorShape([2, 1023, 128]),\n",
       " TensorShape([2, 1023, 136]),\n",
       " TensorShape([2, 1023, 256]),\n",
       " TensorShape([2, 1023, 129]),\n",
       " TensorShape([2, 1023, 128]),\n",
       " TensorShape([2, 1023, 25]),\n",
       " TensorShape([2, 1023, 153]),\n",
       " TensorShape([2, 1023, 49])]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = model(song_batch)\n",
    "[mask.shape for mask in masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check that the masks are ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MusicGenerator(tf.keras.Model):\n",
    "\n",
    "#     def __init__(self, conf: config.Config, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "\n",
    "#         self.conf = conf\n",
    "#         self.SEQ_LEN = conf.SEQ_LEN\n",
    "#         self.TOKEN_DIM = conf.TOKEN_DIM\n",
    "#         self.INPUT_RANGES = conf.INPUT_RANGES\n",
    "\n",
    "#         self.dense_genre_emb = tf.keras.layers.Dense(self.TOKEN_DIM)\n",
    "#         self.embeddings = conf.embedding_layers\n",
    "#         self.concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "\n",
    "#         self.pos_embedding_matrix = conf.get_positional_embedding_matrix()\n",
    "#         self.positional_embeddings = tf.stack([self.pos_embedding_matrix]*conf.BATCH_SIZE)\n",
    "#         self.sum_layer = tf.keras.layers.Add()\n",
    "\n",
    "#         # TODO: add dense layer from embeddings to input decoder\n",
    "\n",
    "#         self.decoder = conf.get_decoder()\n",
    "\n",
    "#         self.output_dense_layers = conf.output_dense_layers\n",
    "\n",
    "#         self.full_mask = conf.full_mask\n",
    "#         self.default_mask = conf.default_mask\n",
    "\n",
    "#         self.masked_activations = [tf.keras.layers.Softmax()]*len(self.embeddings)\n",
    "\n",
    "\n",
    "#     def softargmax(x, beta=1e10):\n",
    "#         x = tf.convert_to_tensor(x, dtype=tf.float64)\n",
    "#         x_range = tf.range(x.shape.as_list()[-1], dtype=x.dtype)\n",
    "#         return tf.reduce_sum(tf.nn.softmax(x*beta) * x_range, axis=-1)\n",
    "\n",
    "\n",
    "#     def apply_activations(self, logits, masks):\n",
    "#         return [activation(elem, mask) for elem, mask, activation in zip(logits, masks, self.masked_activations)]\n",
    "\n",
    "\n",
    "#     def get_mask(self, \n",
    "#             default = [], \n",
    "#             min_measure = None, \n",
    "#             min_beat = None, \n",
    "#             min_position = None,\n",
    "#             note = False,\n",
    "#             allowed_instruments = None,\n",
    "#             allowed_key_sign = None,\n",
    "#             allowed_time_sign = None,\n",
    "#             allowed_tempo = None,\n",
    "#             forbidden_key_sign = None,\n",
    "#             forbidden_time_sign = None,\n",
    "#             forbidden_tempo = None\n",
    "#         ): \n",
    "\n",
    "#         '''\n",
    "#         Returns a list of ndarrays of bool type used for masking\n",
    "#         '''\n",
    "#         if len(default) > 0: # no manual masking, either \"can freely choose this part of the token\" or \"can only choose default for this part of the token\"\n",
    "#             return [self.default_mask[i] if default[i] else self.full_mask[i] for i in range(len(default))]\n",
    "        \n",
    "#         else: # manual masking\n",
    "\n",
    "#             measure_mask = np.asarray([False]*min_measure + [True]*(self.INPUT_RANGES[\"measure\"]-min_measure), dtype=bool)\n",
    "#             # TODO: Implement BEAT MASK only if measure == last_measure\n",
    "#             # TODO: Implement POSITION MASK only if measure == last_measure AND beat == last_beat\n",
    "\n",
    "#             if min_beat == None:\n",
    "#                 beat_mask = self.default_mask[2]\n",
    "#             else: # oss: allowed_time_sign is always != None if min_beat != None\n",
    "#                 max_beat = conf.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "#                 # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "#                 beat_mask = np.asarray(\n",
    "#                     [False]*min_beat + \\\n",
    "#                     [True]*(max_beat-min_beat) + \\\n",
    "#                     [False]*(self.INPUT_RANGES[\"beat\"]-max_beat)\n",
    "#                 , dtype=bool)\n",
    "            \n",
    "\n",
    "#             if min_position == None:\n",
    "#                 position_mask = self.default_mask[3]\n",
    "#             else:\n",
    "#                 position_mask = np.asarray([False]*min_position + [True]*(self.INPUT_RANGES[\"position\"]-min_position), dtype=bool)\n",
    "\n",
    "#             if note:\n",
    "#                 duration_mask = self.full_mask[4]\n",
    "#                 pitch_mask = self.full_mask[5]\n",
    "#                 velocity_mask = self.full_mask[7]\n",
    "#             else:\n",
    "#                 duration_mask = self.default_mask[4]\n",
    "#                 pitch_mask = self.default_mask[5]\n",
    "#                 velocity_mask = self.default_mask[7]\n",
    "\n",
    "#             if allowed_instruments == None:\n",
    "#                 instruments_mask = self.default_mask[6]\n",
    "#             else:\n",
    "#                 instruments_mask = np.asarray([True if i in allowed_instruments else False for i in range(self.INPUT_RANGES[\"instrument\"])], dtype=bool)\n",
    "\n",
    "#             if allowed_key_sign == None:\n",
    "#                 if forbidden_key_sign == None:\n",
    "#                     raise AssertionError(\"Cannot have both allowed and forbidden key_sign not instanciated\")\n",
    "#                 else:\n",
    "#                     key_sign_mask = np.asarray([False if i == forbidden_key_sign else True for i in range(self.INPUT_RANGES[\"key_sign\"])], dtype=bool)\n",
    "#             else:\n",
    "#                 key_sign_mask = np.asarray([True if i == allowed_key_sign else False for i in range(self.INPUT_RANGES[\"key_sign\"])], dtype=bool)\n",
    "\n",
    "#             if allowed_time_sign == None:\n",
    "#                 if forbidden_time_sign == None:\n",
    "#                     raise AssertionError(\"Cannot have both allowed and forbidden time_sign not instanciated\")\n",
    "#                 else:\n",
    "#                     time_sign_mask = np.asarray([False if i == forbidden_time_sign else True for i in range(self.INPUT_RANGES[\"time_sign\"])], dtype=bool)\n",
    "#             else:\n",
    "#                 time_sign_mask = np.asarray([True if i == allowed_time_sign else False for i in range(self.INPUT_RANGES[\"time_sign\"])], dtype=bool)\n",
    "\n",
    "#             if allowed_tempo == None:\n",
    "#                 if forbidden_tempo == None:\n",
    "#                     raise AssertionError(\"Cannot have both allowed and forbidden tempo not instanciated\")\n",
    "#                 else:\n",
    "#                     tempo_mask = np.asarray([False if i == forbidden_tempo else True for i in range(self.INPUT_RANGES[\"tempo\"])], dtype=bool)\n",
    "#             else:\n",
    "#                 tempo_mask = np.asarray([True if i == allowed_tempo else False for i in range(self.INPUT_RANGES[\"tempo\"])], dtype=bool)\n",
    "\n",
    "\n",
    "#             return [\n",
    "#                 self.full_mask[0], # type is not masked\n",
    "#                 measure_mask,\n",
    "#                 beat_mask,\n",
    "#                 position_mask,\n",
    "#                 duration_mask,\n",
    "#                 pitch_mask,\n",
    "#                 instruments_mask,\n",
    "#                 velocity_mask,\n",
    "#                 key_sign_mask,\n",
    "#                 time_sign_mask,\n",
    "#                 tempo_mask\n",
    "#             ]\n",
    "\n",
    "\n",
    "#     def mask_and_activate_outputs(self, out_logits, song):\n",
    "#         '''\n",
    "#         Takes as input:\n",
    "#             - out_logits: the scores outputted by the decoder + dense layers\n",
    "#             - song: the input song, token by token\n",
    "\n",
    "#         This function, based on the chosen token \"type\" given by the first dense layer,\n",
    "#         masks all the different parts of the token accordingly, also taking into consideration\n",
    "#         the previous tokens of the song\n",
    "\n",
    "#         Output:\n",
    "#             - probabilities for each different part of the predicted token (the following one in the song)\n",
    "        \n",
    "#         '''\n",
    "\n",
    "#         max_type = tf.math.reduce_max(song[:,0])\n",
    "\n",
    "#         # do not have to be tensors because loos shouldn't flow through them\n",
    "#         if max_type == 0: # only start of song token\n",
    "#             # cannot be anything else than instrument choice (1)\n",
    "#             type_mask = np.asarray([False, True, False, False, False, False, False, False], dtype=bool)\n",
    "#         elif max_type == 1: # we reached instrument choice\n",
    "#             # cannot be anything else than instrument choice (1) or start of events (2)\n",
    "#             type_mask = np.asarray([False, True, True, False, False, False, False, False], dtype=bool)\n",
    "#         elif max_type >= 2 and max_type < 7: # we reached start of events or notes\n",
    "#             type_mask = np.asarray([False, False, False, True, True, True, True, True], dtype=bool)\n",
    "\n",
    "#         elif max_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change to zero\n",
    "#             type_mask = np.asarray([True, False, False, False, False, False, False, False], dtype=bool)\n",
    "\n",
    "#         type_scores = self.masked_activations[0](out_logits[0], type_mask) # the first masked activation is for the type\n",
    "        \n",
    "#         # needs to be differentiable (but the masks shouldn't need to be)\n",
    "#         chosen_type = self.softargmax(type_scores)\n",
    "\n",
    "#         # could change == i with x<i+eps and x>i-eps because it's softargmax and not argmax\n",
    "#         if chosen_type == 0: # TODO: change to 7 # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "#             # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "#             mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "#         # instrument selection\n",
    "#         if chosen_type == 1: # false only for type and instrument type (the ones that you can choose)\n",
    "#             mask = self.get_mask(default = [False, True, True, True, True, True, False, True, True, True, True])\n",
    "#         # start of events\n",
    "#         elif chosen_type == 2: # false only for type (cannot choose anything in \"start of events\" token)\n",
    "#             mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "#         # notes\n",
    "#         elif chosen_type == 3: # note: has same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "            \n",
    "#             mask = self.get_mask(\n",
    "#                 min_measure = song[-1,1],   # it has to be >= than the last measure\n",
    "#                 min_beat = song[-1,2],      # it has to be >= than the last beat (if measure is the same)\n",
    "#                 min_position = song[-1,3],  # it has to be >= than the last position (if beat and measure are the same)\n",
    "#                 note = True,\n",
    "#                 allowed_instruments = np.unique(song[np.where(song[:,0] == 2),6]), # if type == 2 --> read the instruments (unique = set)\n",
    "#                 allowed_key_sign =  song[np.where(song[:,0] == 4), 8][0][-1], # if type == 4 --> read the LAST key_sign\n",
    "#                 allowed_time_sign = song[np.where(song[:,0] == 5), 9][0][-1], # if type == 5 --> read the LAST time_sign\n",
    "#                 allowed_tempo =     song[np.where(song[:,0] == 6),10][0][-1]  # if type == 6 --> read the LAST tempo\n",
    "#             )\n",
    "\n",
    "#         # key_sign, time_sign, tempo\n",
    "#         elif chosen_type == 4 or chosen_type == 5 or chosen_type == 6:\n",
    "#             # if last event is at the beginning of a measure, you can add an event at the same time\n",
    "#             if song[-1,3] == 0 and song[-1,2] == 0:  # if beat and position == 0, can be this measure\n",
    "#                 min_measure = song[-1,1]\n",
    "#             # otherwise it goes to the next measure\n",
    "#             else:\n",
    "#                 min_measure = song[-1,1] + 1\n",
    "            \n",
    "#             if chosen_type == 4:\n",
    "#                 mask = self.get_mask(\n",
    "#                     min_measure = min_measure,\n",
    "#                     forbidden_key_sign = song[np.where(song[:,0] == 4), 8][0][-1] # cannot put the same key_sign again\n",
    "#                 )\n",
    "\n",
    "#             if chosen_type == 5:\n",
    "#                 mask = self.get_mask(\n",
    "#                     min_measure = min_measure,\n",
    "#                     forbidden_time_sign = song[np.where(song[:,0] == 5), 9][0][-1] # cannot put the same time_sign again\n",
    "#                 )\n",
    "            \n",
    "#             if chosen_type == 6:\n",
    "#                 mask = self.get_mask(\n",
    "#                     min_measure = min_measure,\n",
    "#                     forbidden_tempo = song[np.where(song[:,0] == 6),10][0][-1] # cannot put the same tempo again\n",
    "#                 )\n",
    "        \n",
    "#         elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "#             mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "\n",
    "#         else:\n",
    "#             raise ValueError(\"Impossible that chosen type isn't in [1,7] --> {}\".format(chosen_type))\n",
    "\n",
    "#         # TODO: check if it works for every type!\n",
    "#         return [masked_act(type_logit, type_mask) for masked_act, type_logit, type_mask in zip(self.masked_activations, out_logits, mask)]\n",
    "\n",
    "\n",
    "#     def call(self, inputs):\n",
    "\n",
    "#         # to train you need to add a \"end_song\" input --> in this way you create the attention mask\n",
    "#         # for the decoder\n",
    "\n",
    "#         if type(inputs) == dict:\n",
    "#             song = inputs[\"song\"]\n",
    "#             genre = inputs[\"genre\"]\n",
    "#             attention_mask = inputs[\"attention_mask\"] # TODO: remove if decoder outputs sequences\n",
    "\n",
    "#         elif type(inputs) == tuple:\n",
    "#             song = inputs[0]\n",
    "#             genre = inputs[1]\n",
    "#             attention_mask = inputs[2] # TODO: remove if decoder outputs sequences\n",
    "            \n",
    "#         # EMBEDDING GENERATION for decoder\n",
    "#         genre_embedding = self.dense_genre_emb(genre)\n",
    "\n",
    "#         # TODO: check how they come out (should be 11*64 numbers for each line, and 6143 lines for each song in batch)\n",
    "#         # TODO: batch?\n",
    "#         token_embeddings = [self.embeddings[i](song[:,i]) for i in range(len(self.embeddings))]\n",
    "\n",
    "#         final_embeddings = self.concat_layer([genre_embedding, token_embeddings])\n",
    "\n",
    "#         decoder_output = self.decoder(\n",
    "#             input_embeds = final_embeddings,\n",
    "#             attention_mask = attention_mask, # TODO: remove if decoder outputs sequences\n",
    "#             position_ids = self.positional_embeddings\n",
    "#         )\n",
    "\n",
    "#         out_logits = [layer(decoder_output[\"last_hidden_state\"]) for layer in self.output_dense_layers]\n",
    "        \n",
    "#         # insert for if decoder outputs sequences\n",
    "\n",
    "#         out_scores = self.mask_and_activate_outputs(out_logits, song)\n",
    "        \n",
    "#         # return genre_embedding, token_embeddings, final_embeddings, attention_mask, out_logits, out_scores\n",
    "#         return out_scores\n",
    "\n",
    "    \n",
    "#     def train_step(self, data):\n",
    "#         song, genre = data\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             # TODO: how to do it for batches?\n",
    "#             trainable_vars = self.trainable_variables\n",
    "#             # we only want to predict up to the real finish of the song\n",
    "#             # but they are padded --> for each song we stop at the token BEFORE the \"end_song\" token\n",
    "#             # we predict as last token the \"end_song\" one\n",
    "\n",
    "#             # pass through the network THE ENTIRE SONG (even the last PADDED TOKENS! so the batch flows together)\n",
    "#             # OR we could stop on the biggest last token in batch\n",
    "#             for i, y in enumerate(song[1:]):\n",
    "#                 # TODO: check and simplify if decoder output is already sequence\n",
    "\n",
    "#                 # y is the current token\n",
    "#                 y_pred = self((\n",
    "#                     song,\n",
    "#                     genre,\n",
    "#                     np.asarray([1]*(i+1) + [0]*(self.SEQ_LEN-1-(i+1))) # attention mask\n",
    "#                 ))\n",
    "\n",
    "#                 loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "#                 gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "#                 self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "#                 self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "#         return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fd096c0f68c234ce42f352405a374f9608d011e25b44ffd11646331457b1b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
