{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for i in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(i, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fpEh8pHNkB4r"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "SEQ_LEN = 6144\n",
    "TOKEN_DIM = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "# Custom configuration for using GPT2 as a standard transformer decoder\n",
    "config = GPT2Config(vocab_size = 0, n_positions = SEQ_LEN, n_embd = TOKEN_DIM, \n",
    "                    n_layer = 6, n_head = 8, activation_function='relu')\n",
    "# Instantiate decoder\n",
    "decoder = TFGPT2Model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [],
   "source": [
    "output = decoder({'inputs_embeds': tf.ones((BATCH_SIZE, SEQ_LEN, TOKEN_DIM))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2KCtXoPjbJS",
    "outputId": "97405255-686b-4047-de72-25d98f96428e"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'lmd_matched_6133_tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 6143, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 18), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(BATCH_SIZE).cache().shuffle(256).prefetch(32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [],
   "source": [
    "X, y = next(dataset.as_numpy_iterator())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xgKsIQtuxrb2"
   },
   "outputs": [],
   "source": [
    "## Ranges and dimensions for embedding layers\n",
    "TYPE_RANGE      = 8\n",
    "MEASURE_RANGE   = 256\n",
    "BEAT_RANGE      = 132\n",
    "POSITION_RANGE  = 128\n",
    "DURATION_RANGE  = 136\n",
    "PITCH_RANGE     = 256\n",
    "INSTRUMENT_RANGE= 129\n",
    "VELOCITY_RANGE  = 128\n",
    "KEY_SIGN_RANGE  = 24\n",
    "TIME_SIGN_RANGE = 153\n",
    "TEMPO_RANGE     = 49\n",
    "GENRE_RANGE     = 18\n",
    "\n",
    "OUTPUT_SIZE     = 64\n",
    "GENRE_DIM       = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(TYPE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(MEASURE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(BEAT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(POSITION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(DURATION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(PITCH_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(INSTRUMENT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(VELOCITY_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(KEY_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(TIME_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(TEMPO_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X.shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[:,:SEQ_LEN,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(y)\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6143, 704])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "concat_outputs = types_concat_layer(outputs)\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6143, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to preprend the genre embedding token to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "final_sequence = sequence_concat_layer([genre_embedding[:, np.newaxis, :], encoding])\n",
    "final_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnls1ffVrRED"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add positional encodings to encode which is the position of each token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "01PpH7qxrZPh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_positional_embedding_matrix(seq_len=SEQ_LEN, dim=TOKEN_DIM):\n",
    "    # From \"Attention is all you need\", https://arxiv.org/pdf/1706.03762.pdf\n",
    "    PE = np.zeros((seq_len, dim))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(int(dim/2)):\n",
    "            PE[pos,2*i]   = math.sin(pos/(10000**(2*i/dim)))\n",
    "            PE[pos,2*i+1] = math.cos(pos/(10000**(2*i/dim)))\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "E3J8TF6kuPL3"
   },
   "outputs": [],
   "source": [
    "positional_encoding_matrix = get_positional_embedding_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gJp6amvZNw"
   },
   "source": [
    "In transformers, it is common to add the positional embedding to the elements embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb9HQ-0BSKGq",
    "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_layer = tf.keras.layers.Add()\n",
    "positional_encoding = tf.repeat(positional_encoding_matrix[np.newaxis, :, :], tf.constant(BATCH_SIZE), axis=0)\n",
    "final_encoding = sum_layer([final_sequence, positional_encoding])\n",
    "final_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_encoding})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(TYPE_RANGE, activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(MEASURE_RANGE, activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(BEAT_RANGE, activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(POSITION_RANGE, activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(DURATION_RANGE, activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(PITCH_RANGE, activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(INSTRUMENT_RANGE, activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(VELOCITY_RANGE, activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(KEY_SIGN_RANGE, activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(TIME_SIGN_RANGE, activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(TEMPO_RANGE, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6144, 8)\n",
      "(6, 6144, 256)\n",
      "(6, 6144, 132)\n",
      "(6, 6144, 128)\n",
      "(6, 6144, 136)\n",
      "(6, 6144, 256)\n",
      "(6, 6144, 129)\n",
      "(6, 6144, 128)\n",
      "(6, 6144, 24)\n",
      "(6, 6144, 153)\n",
      "(6, 6144, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.stack([tf.stack([tf.squeeze(tf.random.categorical(tf.math.log([[0.5,0.5]]), 8))]*6144)]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.Softmax()(tf.random.uniform((6, 6144, 8)), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n"
     ]
    }
   ],
   "source": [
    "gt_vectors = [X[:,:,i] for i in range(len(out_scores))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(gt_vectors[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function. The two distributions we are comparing are the input sequence (so we ignore the genre embedding token representation) and the output sequence up to the last token representation (`output[:-1]`)\n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>,\n",
       " <tf.Tensor: shape=(), dtype=float16, numpy=inf>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "losses = []\n",
    "for i in range(len(out_scores)):\n",
    "    losses.append(loss_function(gt_vectors[i], out_scores[i][:, :-1, :]))\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To these loss terms we can add some regularization terms that can help the model produce a grammatically correct sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "types = gt_vectors[0]\n",
    "max_pred_types = tf.argmax(out_scores[0], axis=2) # 6, 6144\n",
    "# Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "keys_tensor = tf.range(TYPE_RANGE, dtype=tf.int32)\n",
    "vals_tensor = tf.constant([0,1,2,3,3,3,3,4], dtype=tf.int32)\n",
    "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), default_value=-1)\n",
    "consecutive_gt_types   = table.lookup(tf.cast(types, tf.int32))\n",
    "consecutive_pred_types = table.lookup(tf.cast(max_pred_types, tf.int32))\n",
    "# Note: we assume that after token token type 7 all following token types are 7s\n",
    "differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=1737>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=553>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some constraint to pose for regularization\n",
    "reg_term_1 = tf.reduce_sum(tf.math.maximum(0, -differences))                           # Difference between one element's type and the next is >= 0\n",
    "reg_term_2 = tf.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))    # Difference between one element's type and the next is < 1\n",
    "\n",
    "reg_term_1, reg_term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float16, numpy=inf>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REG_SCALER = 0.001\n",
    "\n",
    "total_loss = tf.reduce_sum(losses) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_1, tf.float16) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_2, tf.float16)\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "# Setting mixed float16 use for lower memory use\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "# Setting memory growth for lower memory use\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for i in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(i, True)\n",
    "# Multi-GPU training strategy\n",
    "training_strategy = tf.distribute.MirroredStrategy()\n",
    "num_devices = training_strategy.num_replicas_in_sync\n",
    "\n",
    "### CONSTANTS ###\n",
    "BATCH_SIZE   = 12\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * num_devices\n",
    "SEQ_LEN      = 6144\n",
    "TOKEN_DIM    = 512\n",
    "EVENTS_ELEMS = 11\n",
    "\n",
    "## Ranges and dimensions for embedding layers\n",
    "TYPE_RANGE      = 8\n",
    "MEASURE_RANGE   = 256\n",
    "BEAT_RANGE      = 132\n",
    "POSITION_RANGE  = 128\n",
    "DURATION_RANGE  = 136\n",
    "PITCH_RANGE     = 256\n",
    "INSTRUMENT_RANGE= 129\n",
    "VELOCITY_RANGE  = 128\n",
    "KEY_SIGN_RANGE  = 24\n",
    "TIME_SIGN_RANGE = 153\n",
    "TEMPO_RANGE     = 49\n",
    "GENRE_RANGE     = 18\n",
    "# GENRE_RANGE     = 3\n",
    "OUTPUT_SIZE     = 64\n",
    "GENRE_DIM       = TOKEN_DIM\n",
    "\n",
    "REG_LOSS_SCALE  = 0.001\n",
    "\n",
    "\n",
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(TYPE_RANGE)\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "\n",
    "\n",
    "# Custom numpy function to create positional embeddings\n",
    "def get_positional_embedding_matrix(seq_len=SEQ_LEN, dim=TOKEN_DIM):\n",
    "    # From \"Attention is all you need\", https://arxiv.org/pdf/1706.03762.pdf\n",
    "    PE = np.zeros((seq_len, dim))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(int(dim/2)):\n",
    "            PE[pos,2*i]   = math.sin(pos/(10000**(2*i/dim)))\n",
    "            PE[pos,2*i+1] = math.cos(pos/(10000**(2*i/dim)))\n",
    "    return PE\n",
    "\n",
    "\n",
    "# Model creation function (to be called within a scope in case of MultiGPU training)\n",
    "def create_model(input_shape=(SEQ_LEN-1, EVENTS_ELEMS), num_genres=GENRE_RANGE, \n",
    "                 use_regularization=True, reg_loss_scale=REG_LOSS_SCALE):\n",
    "    \n",
    "    # Get input shapes\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate transformer decoder (n_emb % n_head must be 0)\n",
    "    config = GPT2Config(vocab_size = 0, n_positions = seq_len, \n",
    "                        n_embd = TOKEN_DIM, n_layer = 6, \n",
    "                        n_head = 2, activation_function='relu',\n",
    "                        reorder_and_upcast_attn = True)\n",
    "    decoder = TFGPT2Model(config, name='decoder')\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs',  dtype=tf.int32)\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres', dtype=tf.float32)\n",
    "    \n",
    "    # Define loss\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "    reg_scaler = tf.constant(reg_loss_scale, dtype=tf.float32)\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(TYPE_RANGE, OUTPUT_SIZE, input_length=seq_len, name='type_embedding'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(MEASURE_RANGE, OUTPUT_SIZE, input_length=seq_len, name='measure_embedding'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(BEAT_RANGE, OUTPUT_SIZE, input_length=seq_len, name='beat_embedding'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(POSITION_RANGE, OUTPUT_SIZE, input_length=seq_len, name='position_embedding'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(DURATION_RANGE, OUTPUT_SIZE, input_length=seq_len, name='duration_embedding'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(PITCH_RANGE, OUTPUT_SIZE, input_length=seq_len, name='pitch_embedding'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(INSTRUMENT_RANGE, OUTPUT_SIZE, input_length=seq_len, name='instrument_embedding'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(VELOCITY_RANGE, OUTPUT_SIZE, input_length=seq_len, name='velocity_embedding'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(KEY_SIGN_RANGE, OUTPUT_SIZE, input_length=seq_len, name='keysign_embedding'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(TIME_SIGN_RANGE, OUTPUT_SIZE, input_length=seq_len, name='timesign_embedding'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(TEMPO_RANGE, OUTPUT_SIZE, input_length=seq_len, name='tempo_embedding')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    input_concat_layer         = tf.keras.layers.Concatenate(axis=2)\n",
    "    sequence_concat_layer      = tf.keras.layers.Concatenate(axis=1)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = get_positional_embedding_matrix(seq_len=seq_len+1, dim=TOKEN_DIM)\n",
    "    positional_encoding        = tf.repeat(positional_encoding_matrix[tf.newaxis, :, :], tf.shape(songs)[0], axis=0)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(TYPE_RANGE, name='type_scores'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(MEASURE_RANGE, name='measure_scores'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(BEAT_RANGE, name='beat_scores'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(POSITION_RANGE, name='position_scores'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(DURATION_RANGE, name='duration_scores'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(PITCH_RANGE, name='pitch_scores'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(INSTRUMENT_RANGE, name='instrument_scores'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(VELOCITY_RANGE, name='velocity_scores'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(KEY_SIGN_RANGE, name='keysign_scores'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(TIME_SIGN_RANGE, name='timesign_scores'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(TEMPO_RANGE, name='tempo_scores')\n",
    "    ]\n",
    "    \n",
    "    output_probs_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Softmax(name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Softmax(name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Softmax(name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Softmax(name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Softmax(name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Softmax(name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Softmax(name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Softmax(name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Softmax(name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Softmax(name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Softmax(name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    input_embedding   = input_concat_layer(embeddings)\n",
    "    input_embedding   = encoding_processing_layer(input_embedding)\n",
    "    input_embedding   = sequence_concat_layer([genre_embedding[:, np.newaxis, :], input_embedding])\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output) for i in range(len(output_dense_layers))]\n",
    "    # TODO: Here we should add the masking layer\n",
    "    out_probabilities = [output_probs_layers[i](out_scores[i]) for i in range(len(output_dense_layers))]\n",
    "    # TODO: In the line above we should add the masks computed in the masking layer\n",
    "\n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=[songs, genres], outputs=out_probabilities, name='music_generation_model')\n",
    "    \n",
    "    # Define loss\n",
    "    def custom_loss(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(EVENTS_ELEMS)]\n",
    "        # Base loss term\n",
    "        losses = []\n",
    "        for i in range(len(y_pred)):\n",
    "            losses.append(tf.reduce_sum(\n",
    "                tf.cast(loss_function(gt_vectors[i], y_pred[i][:, :-1, :]), tf.float32) * \\\n",
    "                (1. / GLOBAL_BATCH_SIZE)))\n",
    "        return tf.math.reduce_sum(losses)\n",
    "    \n",
    "    # Define regularizers\n",
    "    def custom_regularizers(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(EVENTS_ELEMS)]\n",
    "        # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "        types = gt_vectors[0]\n",
    "        max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "        consecutive_gt_types   = subsequent_type_transform_layer(types)\n",
    "        consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "        # Compute difference\n",
    "        differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "        # Compute regularization terms\n",
    "        # Difference between one element's type and the next is >= 0\n",
    "        reg_term_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "        # Difference between one element's type and the next is < 1\n",
    "        reg_term_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))\n",
    "        return reg_scaler * tf.cast(reg_term_1, tf.float32) + reg_scaler * tf.cast(reg_term_2, tf.float32)\n",
    "    \n",
    "    # Add losses\n",
    "    model.add_loss(custom_loss(songs, out_scores))\n",
    "    if use_regularization:\n",
    "        model.add_loss(custom_regularizers(songs, out_scores))\n",
    "    \n",
    "    # Compile and return\n",
    "    model.compile(optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with training_strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    global_batch_size = BATCH_SIZE\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'lmd_matched_6133_tf')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(GLOBAL_BATCH_SIZE).shuffle(256).cache().prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([24, 6144, 8]), TensorShape([24, 6144, 256]), TensorShape([24, 6144, 132]), TensorShape([24, 6144, 128]), TensorShape([24, 6144, 136]), TensorShape([24, 6144, 256]), TensorShape([24, 6144, 129]), TensorShape([24, 6144, 128]), TensorShape([24, 6144, 24]), TensorShape([24, 6144, 153]), TensorShape([24, 6144, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model([X, y])\n",
    "print([x.shape for x in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=345038.62>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=35.868004>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fd096c0f68c234ce42f352405a374f9608d011e25b44ffd11646331457b1b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
