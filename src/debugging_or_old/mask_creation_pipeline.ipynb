{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:30:41.460890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 22:30:42.235259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2022-12-01 22:30:42.235308: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2022-12-01 22:30:42.235314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-01 22:30:42.891403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:42.917291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:42.917510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/marcello/github/MusicGeneration/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "  except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "import utils\n",
    "import config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:30:43.888029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 22:30:43.889319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:43.889549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:43.889671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:44.584197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:44.584596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:44.584758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 22:30:44.585070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3217 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# dataset = tf.data.Dataset.load(conf.lmda_genres_tf_data_path)   \\\n",
    "dataset = tf.data.Dataset.load(conf.tf_data7dict_path)               \\\n",
    "    .cache()                                                    \\\n",
    "    .shuffle(conf.SHUFFLE_SIZE)                                 \\\n",
    "    .batch(conf.BATCH_SIZE)                                     \\\n",
    "    .prefetch(conf.PREFETCH_SIZE)                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 04:09:08.756860: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song_shape: (2, 1023, 11)\n",
      "\n",
      "Decoder output shape: (2, 1024, 512)\n",
      "\n",
      "Output logit #0: (2, 1024, 8)\n",
      "Output logit #1: (2, 1024, 256)\n",
      "Output logit #2: (2, 1024, 131)\n",
      "Output logit #3: (2, 1024, 128)\n",
      "Output logit #4: (2, 1024, 136)\n",
      "Output logit #5: (2, 1024, 256)\n",
      "Output logit #6: (2, 1024, 129)\n",
      "Output logit #7: (2, 1024, 128)\n",
      "Output logit #8: (2, 1024, 25)\n",
      "Output logit #9: (2, 1024, 153)\n",
      "Output logit #10: (2, 1024, 49)\n"
     ]
    }
   ],
   "source": [
    "song_batch = next(dataset.take(1).as_numpy_iterator())[0][:, :conf.SEQ_LEN-1, :]\n",
    "print(\"Song_shape: {}\\n\".format(song_batch.shape))\n",
    "\n",
    "decoder_output = tf.random.uniform((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM), minval=-1, maxval=1)\n",
    "print(f\"Decoder output shape: {decoder_output.shape}\\n\")\n",
    "\n",
    "out_logits = [layer(decoder_output) for layer in conf.output_dense_layers]\n",
    "for i, out_logit_part in enumerate(out_logits):\n",
    "    print(f\"Output logit #{i}: {out_logit_part.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 1024, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskTypeProbabilitiesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def create_mask(self, inputs):\n",
    "        batch_gt_types = inputs\n",
    "        mask = tf.TensorArray(tf.bool, size=conf.SEQ_LEN)\n",
    "        mask = mask.write(0, tf.constant([True, False, False, False, False, False, False, False], dtype=tf.bool))\n",
    "        for i in tf.range(conf.SEQ_LEN-1):\n",
    "            token_type = batch_gt_types[i]\n",
    "            if token_type == 0: # only start of song token: cannot be anything else than instrument choice (1)\n",
    "                type_mask = tf.constant([False, True, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 1: # we reached instrument choice: cannot be anything else than instrument choice (1) or start of events (2)\n",
    "                type_mask = tf.constant([False, True, True, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 2: # after a 2 there must be at least a 4\n",
    "                type_mask = tf.constant([False, False, False, False, True, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 3: # allow 3,4,5,6,7\n",
    "                type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type >= 4 and token_type <= 6:\n",
    "                # - if there are at least a 5 and a 6 (there is always a 4)   --> [3, 4, 5, 6, 7]\n",
    "                # - if a 5 is missing, we only allow 5                        --> [5]\n",
    "                # - if a 6 is missing, we only allow 6                        --> [6]\n",
    "                if tf.size(tf.where(batch_gt_types[:i] == 5)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, True, False, False], dtype=tf.bool)\n",
    "                if tf.size(tf.where(batch_gt_types[:i] == 6)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, False, True, False], dtype=tf.bool)\n",
    "                else:\n",
    "                    type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change ending token to type 7s -> 7000000000\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, True], dtype=tf.bool)\n",
    "            else:\n",
    "                # ERROR. Define a random type mask so that it's defined in all branches for tf.function\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            mask = mask.write(i+1, type_mask)\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Takes as input the ground truth song (at training time) or the logits (at testing time) \n",
    "        and computes a mask for the type probabilities.\n",
    "        '''\n",
    "        if training:\n",
    "            # Use the groundtruth song as a target\n",
    "            song        = inputs\n",
    "            gt_types    = song[:,:,0]       # Get the token types from the song (batch_size x seq_len-1)\n",
    "            # Iterate over the batch to collect the appropriate masks from the song\n",
    "            masks = tf.map_fn(fn=self.create_mask, \n",
    "                elems=gt_types, \n",
    "                fn_output_signature=tf.TensorSpec(\n",
    "                    (conf.SEQ_LEN, conf.INPUT_RANGES['type']), \n",
    "                    dtype=tf.bool)\n",
    "            )\n",
    "            return masks\n",
    "        else:\n",
    "            # Compute the types and their masks one by one based on the type chosen at the previous iteration\n",
    "            # TODO: implement this branch\n",
    "            pass\n",
    "\n",
    "mask_probabilities = MaskTypeProbabilitiesLayer()(song_batch, training=True)\n",
    "mask_probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.37524801, 0.624752  , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.6394718 , 0.3605282 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.6632023 , 0.33679768, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With these masks we can compute the probabilities for the token types\n",
    "activations = [tf.keras.layers.Softmax()]*len(conf.INPUT_RANGES)\n",
    "\n",
    "types_probabilities = activations[0](out_logits[0], mask_probabilities) # (last out logit predicts a token that's out of bound in our sequence)\n",
    "types_probabilities[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the second part of the layer: given the type probabilities, compute the other constraints\n",
    "class MaskingActivationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        self.default_mask = conf.default_mask\n",
    "        self.full_mask    = conf.full_mask\n",
    "        self._numerators  = tf.constant(conf.numerators)\n",
    "        self._tot_numerators = tf.constant(conf.tot_numerators)\n",
    "\n",
    "    @tf.function\n",
    "    def get_max_beat_from_time_sign(self, time_sign):\n",
    "        '''\n",
    "        Since the time sign is defined (in utils.time_sign_map()) as: \n",
    "            conf.numerators.index(time_sign[0]) + conf.denominators.index(time_sign[1])*conf.tot_numerators\n",
    "\n",
    "        to retrieve the NUMERATOR of the time_sign given the index you need to divide by conf.tot_numerators and take the rest of the division\n",
    "        that gives you the index of the corresponding numerator in conf.numerators\n",
    "        then you use gather or, more simply, a slice to get the actual value of the numerator\n",
    "\n",
    "        You then subtract 1 because the beat is in [0, numerator)\n",
    "        '''\n",
    "        idx = tf.math.floormod(time_sign, self._tot_numerators)\n",
    "        return self._numerators[idx] - 1\n",
    "\n",
    "    @tf.function\n",
    "    def get_mask_for_all_tokens(self, inputs): \n",
    "        '''\n",
    "        Inputs:\n",
    "        - chosen_types:         (SEQ_LEN-1)*1\n",
    "        - song_tokens:          (SEQ_LEN-1)*11\n",
    "        - seq_scores:           (SEQ_LEN-1)*1391\n",
    "\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "        Inputs are for a SINGLE ELEMENT OF A BATCH of size SEQ_LEN*(1+11+1391) where 1391 is the summed length of logits (minus the type)\n",
    "        '''\n",
    "        # Collect inputs from longer tensor\n",
    "        chosen_types, song_tokens, seq_scores = inputs\n",
    "        chosen_types = tf.cast(chosen_types, dtype=tf.int32)\n",
    "        song_tokens  = tf.cast(song_tokens , dtype=tf.int32)\n",
    "        seq_scores   = tf.cast(seq_scores  , dtype=tf.int32)\n",
    "        # Indexes\n",
    "        index_tensor = tf.range(conf.SEQ_LEN-1, dtype=tf.int32)\n",
    "        # Define mask (output) using a TensorArray\n",
    "        mask = tf.TensorArray(dtype=tf.bool, size=conf.SEQ_LEN-1)\n",
    "        # Iterate over the indexes\n",
    "        for idx in index_tensor:\n",
    "            ## SETUP ##\n",
    "            # Define the default variables and flags\n",
    "            default_token_parts   = [True]*(len(conf.INPUT_RANGES)-1)\n",
    "            default_flag          = False\n",
    "            min_measure           = tf.constant(-1, dtype=tf.int32)\n",
    "            min_beat              = tf.constant(-1, dtype=tf.int32)\n",
    "            min_position          = tf.constant(-1, dtype=tf.int32)\n",
    "            # TODO: variable length arrays: can we do it with tensorarrays?\n",
    "            allowed_instruments   = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            allowed_key_sign      = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_time_sign     = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_tempo         = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_instruments_flag = False\n",
    "            forbidden_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            forbidden_key_sign    = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_time_sign   = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_tempo       = tf.constant(-1, dtype=tf.int32)\n",
    "            # Define the inputs\n",
    "            chosen_type = chosen_types[idx]\n",
    "            scores      = seq_scores[idx]\n",
    "            song        = song_tokens * (tf.expand_dims([1]*idx + [0]*(conf.SEQ_LEN-1-idx), axis=-1)) # Mask all tokens after index idx\n",
    "            ## MAIN BODY ##\n",
    "            if chosen_type == 0 or chosen_type == 2: # TODO: change 0s to 7s at the end of the song\n",
    "                # Original comments: \n",
    "                # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "                # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "            elif chosen_type == 1: # Instrument selection, false only for type and instrument type (the ones that you can choose)\n",
    "                if tf.size(tf.where(song[:idx, 0] == 1)[:,0]) == 0:\n",
    "                    # Choice of first instrument\n",
    "                    default_token_parts = [True, True, True, True, True, False, True, True, True, True]  # TODO: Element 6 should not be default = True right?\n",
    "                    default_flag = True\n",
    "                else:\n",
    "                    forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                        song[:idx, 6], \n",
    "                        tf.where(song[:idx, 0] == 1)[:,0]        # Cast to 1D array\n",
    "                    ))\n",
    "                    forbidden_instruments_flag = True\n",
    "            elif chosen_type == 3: # Notes: They have the same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "                min_measure = song[idx, 1]   # It has to be >= than the last measure\n",
    "                # If in the MEASURE SCORES the MAX SCORE between all possible measures == min_measure, the measure is min_measure.\n",
    "                # In this case, we need to make sure that beat >= last_beat\n",
    "                if tf.math.argmax(\n",
    "                    scores[:conf.INPUT_RANGES[\"measure\"]], \n",
    "                        output_type=tf.int32) == min_measure:  \n",
    "                    min_beat = song[idx,2]      # It has to be >= than the last beat when measure is the same\n",
    "                    if tf.math.argmax(scores[\n",
    "                        conf.INPUT_RANGES[\"measure\"] : \n",
    "                        conf.INPUT_RANGES[\"measure\"] + conf.INPUT_RANGES[\"beat\"]], \n",
    "                        output_type=tf.int32) == min_beat:\n",
    "                        min_position = song[idx,3]  # It has to be >= than the last position (if beat and measure are the same)\n",
    "                    else:\n",
    "                        min_position = tf.constant(0, dtype=tf.int32)\n",
    "                else:\n",
    "                    min_beat = tf.constant(0, dtype=tf.int32)\n",
    "                    min_position = tf.constant(0, dtype=tf.int32)\n",
    "                # Only some instruments, key signs, time signs and tempos are allowed for these events: \n",
    "                # - for instruments, the allowed ones are the ones that have been defined previously with type = 1\n",
    "                # - for the others, the allowed ones are the ones that are collected right before the note from event types 4, 5 and 6\n",
    "                allowed_instruments, _ = tf.unique(tf.gather(\n",
    "                    song[:idx, 6], \n",
    "                    tf.where(song[:idx, 0] == 1)[:,0]\n",
    "                ))\n",
    "                # We have made it so that the model should output 3s only after at least a 4, 5 and 6.\n",
    "                allowed_key_sign = tf.gather(\n",
    "                    song[:idx, 8], \n",
    "                    tf.where(song[:idx, 0] == 4)[:,0]   # if type == 4 --> read the LAST key_sign\n",
    "                )[-1] \n",
    "                allowed_time_sign = tf.gather(\n",
    "                    song[:idx, 9], \n",
    "                    tf.where(song[:idx, 0] == 5)[:,0]   # if type == 5 --> read the LAST time_sign\n",
    "                )[-1] \n",
    "                allowed_tempo = tf.gather(\n",
    "                    song[:idx, 10], \n",
    "                    tf.where(song[:idx, 0] == 6)[:,0]   # if type == 6 --> read the LAST tempo\n",
    "                )[-1] \n",
    "            elif chosen_type >= 4 and chosen_type <= 6:     # key_sign, time_sign, tempo\n",
    "                # If last event is at the beginning of a measure, you can add an event at the same time\n",
    "                if song[idx, 3] == 0 and song[idx, 2] == 0:  # if beat and position == 0, the event can be at this measure\n",
    "                    min_measure = song[idx, 1]\n",
    "                else:\n",
    "                    min_measure = song[idx, 1] + 1                   # otherwise it goes to the next measure\n",
    "                # Fine-grain checks\n",
    "                # Here, there are cases where there is not a LAST key_sign/time_sign (when this is the first 4, 5 or 6). \n",
    "                # In these cases we should use the default masks.\n",
    "                if chosen_type == 4:\n",
    "                    # Cannot put the same key_sign again\n",
    "                    forbidden_key_signs = tf.gather(\n",
    "                        song[:idx, 8], \n",
    "                        tf.where(song[:idx, 0] == 4)[:,0]) # if type == 4 --> read the LAST key_sign\n",
    "                    if tf.size(forbidden_key_signs) > 0:\n",
    "                        forbidden_key_sign = forbidden_key_signs[-1]\n",
    "                elif chosen_type == 5:\n",
    "                    # Cannot put the same time_sign again\n",
    "                    forbidden_time_signs = tf.gather(\n",
    "                        song[:idx, 9], \n",
    "                        tf.where(song[:idx, 0] == 5)[:,0]) # if type == 5 --> read the LAST time_sign\n",
    "                    if tf.size(forbidden_time_signs) > 0:\n",
    "                        forbidden_time_sign = forbidden_time_signs[-1]\n",
    "                elif chosen_type == 6:\n",
    "                    # Cannot put the same tempo again\n",
    "                    forbidden_tempos = tf.gather(\n",
    "                        song[:idx, 10], \n",
    "                        tf.where(song[:idx, 0] == 6)[:,0]) # if type == 6 --> read the LAST tempo\n",
    "                    if tf.size(forbidden_tempos) > 9:\n",
    "                        forbidden_tempo = forbidden_tempos[-1]\n",
    "            elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "\n",
    "            ## ENDING PART ##\n",
    "            # Put together the masks\n",
    "            if default_flag: \n",
    "                # No manual masking required, either \"can freely choose this part of the token\" (True) or \n",
    "                # \"can only choose default for this part of the token\" (False)\n",
    "                mask.write(idx, tf.concat(\n",
    "                    # Default mask only allows to predict a 0\n",
    "                    # Full mask allows to predict any value\n",
    "                    [self.default_mask[i] if default_token_parts[i] else self.full_mask[i] \n",
    "                        for i in range(len(default_token_parts))], axis=-1)\n",
    "                )\n",
    "            elif forbidden_instruments_flag:\n",
    "                # Default flag is False and forbidden instruments contains some elmeents (which means that the chosen type is 1)\n",
    "                instruments_mask = tf.sparse.SparseTensor(  # Forbidden instruments\n",
    "                        indices= tf.expand_dims(tf.cast(forbidden_instruments, tf.int64), axis=-1),\n",
    "                        values = tf.zeros_like(forbidden_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                instruments_mask = tf.cast(\n",
    "                    tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "                # Only mask the forbidden instruments, all the rest is default\n",
    "                mask.write(idx, tf.concat(\n",
    "                    [self.default_mask[i] for i in range(5)] + \\\n",
    "                    [instruments_mask] + \\\n",
    "                    [self.default_mask[i] for i in range(6,len(default_token_parts))], \n",
    "                    axis=-1))\n",
    "            elif chosen_type >= 3 and chosen_type <= 6:\n",
    "                # General event. What we do depends on which specific event it is, but\n",
    "                # in general there is always a measure mask.\n",
    "                measure_mask = tf.cast(\n",
    "                    tf.concat([\n",
    "                        tf.repeat([False], min_measure),        # Can be equal to or greater than min_measure\n",
    "                        tf.repeat([True],  conf.INPUT_RANGES[\"measure\"]-min_measure)], \n",
    "                        axis=-1),\n",
    "                    dtype=tf.dtypes.bool)\n",
    "                # We need to do manual masking. Define all tensors\n",
    "                measure_mask     = self.default_mask[0]\n",
    "                beat_mask        = self.default_mask[1]\n",
    "                position_mask    = self.default_mask[2]\n",
    "                duration_mask    = self.default_mask[3]\n",
    "                pitch_mask       = self.default_mask[4]\n",
    "                instruments_mask = self.default_mask[5]\n",
    "                velocity_mask    = self.default_mask[6]\n",
    "                key_sign_mask    = self.default_mask[7]\n",
    "                time_sign_mask   = self.default_mask[8]\n",
    "                tempo_mask       = self.default_mask[9]\n",
    "                # Create more specific masks depending on the type\n",
    "                if chosen_type == 4:\n",
    "                    if forbidden_key_sign != -1: ## forbidden_key_sign can only appear if chosen_type = 4\n",
    "                        # True in all places but the forbidden key signs\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 5:\n",
    "                    if forbidden_time_sign != -1: ## forbidden_time_sign can only appear if chosen_type = 5\n",
    "                        # True in all places but the forbidden time signs\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 6:\n",
    "                    if forbidden_tempo != -1: ## forbidden_tempo can only appear if chosen_type = 6\n",
    "                        # True in all places but the forbidden tempos\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 3:\n",
    "                    # If the event is a note, we have ALLOWED time signs/tempos/key signs, not\n",
    "                    # forbidden ones. Also, there are many other elements to take into account\n",
    "                    if min_beat != -1:\n",
    "                        # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                        max_beat = self.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                        # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                        beat_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_beat),\n",
    "                            tf.repeat([True],  max_beat-min_beat), \n",
    "                            tf.repeat([False], conf.INPUT_RANGES[\"beat\"]-max_beat)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    if min_position != -1:\n",
    "                        position_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_position), \n",
    "                            tf.repeat([True],  conf.INPUT_RANGES[\"position\"]-min_position)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    instruments_mask = tf.sparse.SparseTensor( # Allowed instruments\n",
    "                        indices=tf.expand_dims(tf.cast(allowed_instruments, tf.int64), axis=-1),\n",
    "                        values=tf.ones_like(allowed_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                    instruments_mask = tf.cast(\n",
    "                        tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=0),\n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    if allowed_key_sign != -1:\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_time_sign != -1:\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_tempo != -1:\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                # Write on the mask\n",
    "                mask.write(idx, tf.concat([\n",
    "                    measure_mask, beat_mask, position_mask, duration_mask,\n",
    "                    pitch_mask, instruments_mask, velocity_mask, key_sign_mask,\n",
    "                    time_sign_mask, tempo_mask], axis=-1))\n",
    "        # Return the whole mask\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Inputs:\n",
    "        - songs:                BATCH*(SEQ_LEN-1)*11\n",
    "        - out_logits:           BATCH*(SEQ_LEN-1)*1391 (all except type)\n",
    "        - types_probabilities:  BATCH*(SEQ_LEN-1)*8 --> becomes chosen_types through argmax --> BATCH*(SEQ_LEN-1)*1\n",
    "\n",
    "        passes through map_fn --> get_mask_fro_all_tokens to debatch\n",
    "        '''\n",
    "        songs, out_logits, types_probabilities = inputs\n",
    "        chosen_types  = tf.expand_dims(tf.math.argmax(types_probabilities[:,:-1], axis=2), axis=-1)\n",
    "        concat_logits = tf.concat(out_logits[1:], axis=-1)                 # Concatenate all logits (except type) into a tensor batch_size x seq_len x 1391\n",
    "        masks = tf.map_fn(fn=self.get_mask_for_all_tokens, elems=(         # Iterate function over batch dimension \n",
    "                tf.cast(chosen_types, concat_logits.dtype),                # BATCH*(SEQ_LEN-1)*1\n",
    "                tf.cast(songs,   concat_logits.dtype),                     # BATCH*(SEQ_LEN-1)*11\n",
    "                concat_logits[:, :conf.SEQ_LEN-1, :]                       # BATCH*(SEQ_LEN-1)*1391\n",
    "            ), fn_output_signature=tf.TensorSpec(                          # Total: a BATCH * SEQ_LEN-1 * 1403 tensor\n",
    "                (conf.SEQ_LEN-1, conf.input_ranges_sum - conf.INPUT_RANGES['type']),\n",
    "                dtype=tf.bool\n",
    "            ))\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: It's not working. There must be some logic problems... But if it works it's definetely faster\n",
    "# also there's a high chance that those problem are also in the original version... So it's worth looking into\n",
    "mask = MaskingActivationLayer()([song_batch, out_logits, types_probabilities])      # It's much faster!! If we can make this work we're good\n",
    "index = 0\n",
    "masks = []\n",
    "for key in conf.INPUT_RANGES:\n",
    "    if key != 'type':       # We have already checked for the type\n",
    "        masks.append(mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "        index += conf.INPUT_RANGES[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_input = tf.keras.layers.Input(shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), dtype=tf.int8)\n",
    "\n",
    "mask_type_probabilities_layer = MaskTypeProbabilitiesLayer()\n",
    "final_masking_layer = MaskingActivationLayer()\n",
    "activations = [tf.keras.layers.Softmax()]*len(conf.INPUT_RANGES)\n",
    "\n",
    "mask_for_type_probabilities = mask_type_probabilities_layer(song_input, training=True)\n",
    "type_probabilities = activations[0](out_logits[0], mask_for_type_probabilities)\n",
    "out_logits = [logit[:, :-1, :] for logit in out_logits]\n",
    "type_probabilities = type_probabilities[:, :-1, :]\n",
    "final_mask = final_masking_layer([song_input, out_logits, type_probabilities])\n",
    "\n",
    "# Unpack the final masks\n",
    "index = 0\n",
    "masks = []\n",
    "for key in conf.INPUT_RANGES:\n",
    "    if key != 'type':       # We have already checked for the type\n",
    "        masks.append(final_mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "        index += conf.INPUT_RANGES[key]\n",
    "\n",
    "model = tf.keras.Model(inputs=song_input, outputs=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorShape([2, 1023, 256]),\n",
       " TensorShape([2, 1023, 131]),\n",
       " TensorShape([2, 1023, 128]),\n",
       " TensorShape([2, 1023, 136]),\n",
       " TensorShape([2, 1023, 256]),\n",
       " TensorShape([2, 1023, 129]),\n",
       " TensorShape([2, 1023, 128]),\n",
       " TensorShape([2, 1023, 25]),\n",
       " TensorShape([2, 1023, 153]),\n",
       " TensorShape([2, 1023, 49])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = model(song_batch)\n",
    "[mask.shape for mask in masks]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
