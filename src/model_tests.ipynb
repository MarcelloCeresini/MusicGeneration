{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fpEh8pHNkB4r"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "SEQ_LEN = 8192\n",
    "TOKEN_DIM = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "# Custom configuration for using GPT2 as a standard transformer decoder\n",
    "config = GPT2Config(vocab_size=0, n_positions = SEQ_LEN, n_embd = TOKEN_DIM, \n",
    "                    n_layer = 6, n_head = 8, activation_function='relu')\n",
    "# Instantiate decoder\n",
    "decoder = TFGPT2Model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8192, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': tf.ones((BATCH_SIZE, SEQ_LEN, TOKEN_DIM))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2KCtXoPjbJS",
    "outputId": "97405255-686b-4047-de72-25d98f96428e"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'lmda_genres_tf_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 8192, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 18), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(BATCH_SIZE).cache().shuffle(256).prefetch(32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8192, 11) (2, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 21:28:10.419478: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.as_numpy_iterator())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xgKsIQtuxrb2"
   },
   "outputs": [],
   "source": [
    "## Ranges and dimensions for embedding layers\n",
    "TYPE_RANGE      = 8\n",
    "MEASURE_RANGE   = 256\n",
    "BEAT_RANGE      = 132\n",
    "POSITION_RANGE  = 128\n",
    "DURATION_RANGE  = 136\n",
    "PITCH_RANGE     = 256\n",
    "INSTRUMENT_RANGE= 129\n",
    "VELOCITY_RANGE  = 128\n",
    "KEY_SIGN_RANGE  = 24\n",
    "TIME_SIGN_RANGE = 153\n",
    "TEMPO_RANGE     = 49\n",
    "GENRE_RANGE     = 18\n",
    "\n",
    "OUTPUT_SIZE = 64\n",
    "GENRE_DIM   = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(TYPE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(MEASURE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(BEAT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(POSITION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(DURATION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(PITCH_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(INSTRUMENT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(VELOCITY_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(KEY_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(TIME_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(TEMPO_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X.shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[:,:SEQ_LEN,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 64])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(y)\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8192, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "repeat_layer = tf.keras.layers.RepeatVector(SEQ_LEN)\n",
    "genre_embedding = repeat_layer(genre_embedding)\n",
    "concat_outputs = concat_layer(outputs + [genre_embedding])\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8192, 512])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnls1ffVrRED"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add positional encodings to encode which is the position of each token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "01PpH7qxrZPh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_positional_embedding_matrix(seq_len=SEQ_LEN, dim=TOKEN_DIM):\n",
    "    # From \"Attention is all you need\", https://arxiv.org/pdf/1706.03762.pdf\n",
    "    PE = np.zeros((seq_len, dim))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(int(dim/2)):\n",
    "            PE[pos,2*i]   = math.sin(pos/(10000**(2*i/dim)))\n",
    "            PE[pos,2*i+1] = math.cos(pos/(10000**(2*i/dim)))\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "E3J8TF6kuPL3"
   },
   "outputs": [],
   "source": [
    "positional_encoding_matrix = get_positional_embedding_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gJp6amvZNw"
   },
   "source": [
    "In transformers, it is common to add the positional embedding to the elements embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb9HQ-0BSKGq",
    "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8192, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_layer = tf.keras.layers.Add()\n",
    "positional_encoding = tf.stack([positional_encoding_matrix]*BATCH_SIZE)\n",
    "final_encoding = sum_layer([encoding, positional_encoding])\n",
    "final_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 8192, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_encoding})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(TYPE_RANGE, activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(MEASURE_RANGE, activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(BEAT_RANGE, activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(POSITION_RANGE, activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(DURATION_RANGE, activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(PITCH_RANGE, activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(INSTRUMENT_RANGE, activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(VELOCITY_RANGE, activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(KEY_SIGN_RANGE, activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(TIME_SIGN_RANGE, activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(TEMPO_RANGE, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8192, 8)\n",
      "(2, 8192, 256)\n",
      "(2, 8192, 132)\n",
      "(2, 8192, 128)\n",
      "(2, 8192, 136)\n",
      "(2, 8192, 256)\n",
      "(2, 8192, 129)\n",
      "(2, 8192, 128)\n",
      "(2, 8192, 24)\n",
      "(2, 8192, 153)\n",
      "(2, 8192, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n",
      "(2, 8192)\n"
     ]
    }
   ],
   "source": [
    "gt_vectors = [X[:,:SEQ_LEN,i] for i in range(len(out_scores))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(gt_vectors[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function \n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.5348933, shape=(), dtype=float32)\n",
      "tf.Tensor(5.649028, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0095873, shape=(), dtype=float32)\n",
      "tf.Tensor(5.7224555, shape=(), dtype=float32)\n",
      "tf.Tensor(5.680168, shape=(), dtype=float32)\n",
      "tf.Tensor(6.1693664, shape=(), dtype=float32)\n",
      "tf.Tensor(5.9566793, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0991096, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6551266, shape=(), dtype=float32)\n",
      "tf.Tensor(6.261841, shape=(), dtype=float32)\n",
      "tf.Tensor(5.4754124, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(loss_function(gt_vectors[i], out_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "### CONSTANTS ###\n",
    "BATCH_SIZE   = 2\n",
    "SEQ_LEN      = 6144 #8192\n",
    "TOKEN_DIM    = 512\n",
    "EVENTS_ELEMS = 11\n",
    "\n",
    "## Ranges and dimensions for embedding layers\n",
    "TYPE_RANGE      = 8\n",
    "MEASURE_RANGE   = 256\n",
    "BEAT_RANGE      = 132\n",
    "POSITION_RANGE  = 128\n",
    "DURATION_RANGE  = 136\n",
    "PITCH_RANGE     = 256\n",
    "INSTRUMENT_RANGE= 129\n",
    "VELOCITY_RANGE  = 128\n",
    "KEY_SIGN_RANGE  = 24\n",
    "TIME_SIGN_RANGE = 153\n",
    "TEMPO_RANGE     = 49\n",
    "GENRE_RANGE     = 18\n",
    "OUTPUT_SIZE     = 64\n",
    "GENRE_DIM       = 64\n",
    "\n",
    "\n",
    "def get_positional_embedding_matrix(seq_len=SEQ_LEN, dim=TOKEN_DIM):\n",
    "    # From \"Attention is all you need\", https://arxiv.org/pdf/1706.03762.pdf\n",
    "    PE = np.zeros((seq_len, dim))\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(int(dim/2)):\n",
    "            PE[pos,2*i]   = math.sin(pos/(10000**(2*i/dim)))\n",
    "            PE[pos,2*i+1] = math.cos(pos/(10000**(2*i/dim)))\n",
    "    return PE\n",
    "\n",
    "\n",
    "def create_model(input_shape=(SEQ_LEN, EVENTS_ELEMS), num_genres=GENRE_RANGE, batch_size=BATCH_SIZE):\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate decoder\n",
    "    config = GPT2Config(vocab_size = 0, n_positions = seq_len, \n",
    "                        n_embd = TOKEN_DIM, n_layer = 6, \n",
    "                        n_head = 8, activation_function='relu')\n",
    "    decoder = TFGPT2Model(config, name='decoder')\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs')\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres')\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(TYPE_RANGE, OUTPUT_SIZE, input_length=seq_len, name='type_embedding'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(MEASURE_RANGE, OUTPUT_SIZE, input_length=seq_len, name='measure_embedding'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(BEAT_RANGE, OUTPUT_SIZE, input_length=seq_len, name='beat_embedding'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(POSITION_RANGE, OUTPUT_SIZE, input_length=seq_len, name='position_embedding'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(DURATION_RANGE, OUTPUT_SIZE, input_length=seq_len, name='duration_embedding'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(PITCH_RANGE, OUTPUT_SIZE, input_length=seq_len, name='pitch_embedding'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(INSTRUMENT_RANGE, OUTPUT_SIZE, input_length=seq_len, name='instrument_embedding'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(VELOCITY_RANGE, OUTPUT_SIZE, input_length=seq_len, name='velocity_embedding'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(KEY_SIGN_RANGE, OUTPUT_SIZE, input_length=seq_len, name='keysign_embedding'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(TIME_SIGN_RANGE, OUTPUT_SIZE, input_length=seq_len, name='timesign_embedding'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(TEMPO_RANGE, OUTPUT_SIZE, input_length=seq_len, name='tempo_embedding')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    concat_layer               = tf.keras.layers.Concatenate(axis=2)\n",
    "    repeat_layer               = tf.keras.layers.RepeatVector(seq_len)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = get_positional_embedding_matrix(seq_len=seq_len, dim=TOKEN_DIM)\n",
    "    positional_encoding        = tf.stack([positional_encoding_matrix]*batch_size)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(TYPE_RANGE, activation='softmax', name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(MEASURE_RANGE, activation='softmax', name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(BEAT_RANGE, activation='softmax', name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(POSITION_RANGE, activation='softmax', name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(DURATION_RANGE, activation='softmax', name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(PITCH_RANGE, activation='softmax', name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(INSTRUMENT_RANGE, activation='softmax', name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(VELOCITY_RANGE, activation='softmax', name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(KEY_SIGN_RANGE, activation='softmax', name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(TIME_SIGN_RANGE, activation='softmax', name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(TEMPO_RANGE, activation='softmax', name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    genre_embedding   = repeat_layer(genre_embedding)\n",
    "    concat_embeddings = concat_layer(embeddings + [genre_embedding])\n",
    "    input_embedding   = encoding_processing_layer(concat_embeddings)\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output) for i in range(len(output_dense_layers))]\n",
    "\n",
    "    return tf.keras.Model(inputs=[songs, genres], outputs=out_scores, name='music_generation_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(tf.config.list_physical_devices('GPU')) > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    training_strategy = tf.distribute.MirroredStrategy()\n",
    "    num_devices = training_strategy.num_replicas_in_sync\n",
    "    global_batch_size = BATCH_SIZE * num_devices\n",
    "    with training_strategy.scope():\n",
    "        model = create_model(batch_size=global_batch_size)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_generation_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " songs (InputLayer)             [(None, 6144, 11)]   0           []                               \n",
      "                                                                                                  \n",
      " genres (InputLayer)            [(None, 18)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 6144)        0           ['songs[0][0]']                  \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 6144)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 6144)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " genre_embedding (Sequential)   (None, 64)           21312       ['genres[0][0]']                 \n",
      "                                                                                                  \n",
      " type_embedding (Embedding)     (None, 6144, 64)     512         ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " measure_embedding (Embedding)  (None, 6144, 64)     16384       ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " beat_embedding (Embedding)     (None, 6144, 64)     8448        ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " position_embedding (Embedding)  (None, 6144, 64)    8192        ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " duration_embedding (Embedding)  (None, 6144, 64)    8704        ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " pitch_embedding (Embedding)    (None, 6144, 64)     16384       ['tf.__operators__.getitem_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " instrument_embedding (Embeddin  (None, 6144, 64)    8256        ['tf.__operators__.getitem_6[0][0\n",
      " g)                                                              ]']                              \n",
      "                                                                                                  \n",
      " velocity_embedding (Embedding)  (None, 6144, 64)    8192        ['tf.__operators__.getitem_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " keysign_embedding (Embedding)  (None, 6144, 64)     1536        ['tf.__operators__.getitem_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " timesign_embedding (Embedding)  (None, 6144, 64)    9792        ['tf.__operators__.getitem_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tempo_embedding (Embedding)    (None, 6144, 64)     3136        ['tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 6144, 64)     0           ['genre_embedding[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6144, 768)    0           ['type_embedding[0][0]',         \n",
      "                                                                  'measure_embedding[0][0]',      \n",
      "                                                                  'beat_embedding[0][0]',         \n",
      "                                                                  'position_embedding[0][0]',     \n",
      "                                                                  'duration_embedding[0][0]',     \n",
      "                                                                  'pitch_embedding[0][0]',        \n",
      "                                                                  'instrument_embedding[0][0]',   \n",
      "                                                                  'velocity_embedding[0][0]',     \n",
      "                                                                  'keysign_embedding[0][0]',      \n",
      "                                                                  'timesign_embedding[0][0]',     \n",
      "                                                                  'tempo_embedding[0][0]',        \n",
      "                                                                  'repeat_vector[0][0]']          \n",
      "                                                                                                  \n",
      " encoding_processing (Dense)    (None, 6144, 512)    393728      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " final_encoding (Add)           (4, 6144, 512)       0           ['encoding_processing[0][0]']    \n",
      "                                                                                                  \n",
      " decoder (TFGPT2Model)          TFBaseModelOutputWi  22061056    ['final_encoding[0][0]']         \n",
      "                                thPastAndCrossAtten                                               \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(4, 6144, 512)                                               \n",
      "                                , past_key_values=(                                               \n",
      "                                (2, 4, 8, 6144, 64)                                               \n",
      "                                , (2, 4, 8, 6144, 6                                               \n",
      "                                4),                                                               \n",
      "                                 (2, 4, 8, 6144, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (2, 4, 8, 6144, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (2, 4, 8, 6144, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (2, 4, 8, 6144, 64                                               \n",
      "                                )),                                                               \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None,                                                \n",
      "                                cross_attentions=No                                               \n",
      "                                ne)                                                               \n",
      "                                                                                                  \n",
      " type_probabilities (Dense)     (4, 6144, 8)         4104        ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " measure_probabilities (Dense)  (4, 6144, 256)       131328      ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " beat_probabilities (Dense)     (4, 6144, 132)       67716       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " position_probabilities (Dense)  (4, 6144, 128)      65664       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " duration_probabilities (Dense)  (4, 6144, 136)      69768       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " pitch_probabilities (Dense)    (4, 6144, 256)       131328      ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " instrument_probabilities (Dens  (4, 6144, 129)      66177       ['decoder[0][0]']                \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " velocity_probabilities (Dense)  (4, 6144, 128)      65664       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " keysign_probabilities (Dense)  (4, 6144, 24)        12312       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " timesign_probabilities (Dense)  (4, 6144, 153)      78489       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " tempo_probabilities (Dense)    (4, 6144, 49)        25137       ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,283,319\n",
      "Trainable params: 23,283,319\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'lmda_genres_tf_data')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(global_batch_size).cache().shuffle(256).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([4, 6144, 8]), TensorShape([4, 6144, 256]), TensorShape([4, 6144, 132]), TensorShape([4, 6144, 128]), TensorShape([4, 6144, 136]), TensorShape([4, 6144, 256]), TensorShape([4, 6144, 129]), TensorShape([4, 6144, 128]), TensorShape([4, 6144, 24]), TensorShape([4, 6144, 153]), TensorShape([4, 6144, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model([X[:,:SEQ_LEN,:], y])\n",
    "print([x.shape for x in output])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fd096c0f68c234ce42f352405a374f9608d011e25b44ffd11646331457b1b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
