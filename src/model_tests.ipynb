{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers tensorflow"
      ],
      "metadata": {
        "id": "-e5vVi69jfBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "bkFUntbMqg8U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PjBIrC7GaASB"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Config, TFGPT2Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "bCsKMkpyqiQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a fake input\n",
        "BATCH_SIZE = 2\n",
        "SEQ_LEN = 4096\n",
        "TOKEN_DIM = 512"
      ],
      "metadata": {
        "id": "fpEh8pHNkB4r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder creation"
      ],
      "metadata": {
        "id": "urmU6Nwaq9_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "35ZXAZOJZ21a"
      },
      "outputs": [],
      "source": [
        "# Custom configuration for using GPT2 as a standard transformer decoder\n",
        "config = GPT2Config(vocab_size=0, n_positions = SEQ_LEN, n_embd = TOKEN_DIM, n_layer = 6, n_head = 8, activation_function='relu')\n",
        "# Instantiate decoder\n",
        "decoder = TFGPT2Model(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the decoder on random inputs"
      ],
      "metadata": {
        "id": "7LF5x9H8qlI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gj4Yk5fmkxl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 4096, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "output = decoder({'inputs_embeds': tf.ones((BATCH_SIZE, SEQ_LEN, TOKEN_DIM))})\n",
        "output['last_hidden_state'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "edh1BIX-qv4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATASET_PATH = '/content/drive/MyDrive/Uni/Magistrale/AI4I/Project/Dataset/tf_data'\n",
        "except:\n",
        "    DATASET_PATH = os.path.join('..', 'data', 'tf_data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2KCtXoPjbJS",
        "outputId": "97405255-686b-4047-de72-25d98f96428e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IygWWia1t67e",
        "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 13450, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.load(DATASET_PATH).batch(BATCH_SIZE).cache().shuffle(256).prefetch(32)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGi_Mo6rjXuC",
        "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 13450, 11) (2,)\n"
          ]
        }
      ],
      "source": [
        "X, y = next(dataset.as_numpy_iterator())\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding layers"
      ],
      "metadata": {
        "id": "6DFjF1yHq7nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Ranges and dimensions for embedding layers\n",
        "TYPE_RANGE      = 8\n",
        "MEASURE_RANGE   = 256\n",
        "BEAT_RANGE      = 133\n",
        "POSITION_RANGE  = 128\n",
        "DURATION_RANGE  = 136\n",
        "PITCH_RANGE     = 256\n",
        "INSTRUMENT_RANGE= 129\n",
        "VELOCITY_RANGE  = 128\n",
        "KEY_SIGN_RANGE  = 24\n",
        "TIME_SIGN_RANGE = 153\n",
        "TEMPO_RANGE     = 49\n",
        "\n",
        "OUTPUT_SIZE = 64"
      ],
      "metadata": {
        "id": "xgKsIQtuxrb2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layers = [\n",
        "    # Type embedding\n",
        "    tf.keras.layers.Embedding(TYPE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Measure embedding\n",
        "    tf.keras.layers.Embedding(MEASURE_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Beat embedding\n",
        "    tf.keras.layers.Embedding(BEAT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Position embedding\n",
        "    tf.keras.layers.Embedding(POSITION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Duration embedding\n",
        "    tf.keras.layers.Embedding(DURATION_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Pitch embedding\n",
        "    tf.keras.layers.Embedding(PITCH_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Instrument embedding\n",
        "    tf.keras.layers.Embedding(INSTRUMENT_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Velocity embedding\n",
        "    tf.keras.layers.Embedding(VELOCITY_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Key sign embedding\n",
        "    tf.keras.layers.Embedding(KEY_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Time sign embedding\n",
        "    tf.keras.layers.Embedding(TIME_SIGN_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN),\n",
        "    # Tempo embedding\n",
        "    tf.keras.layers.Embedding(TEMPO_RANGE, OUTPUT_SIZE, input_length=SEQ_LEN)\n",
        "]"
      ],
      "metadata": {
        "id": "Uzpl4levsL71"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "for i in tf.range(X.shape[2]):\n",
        "    outputs.append(embedding_layers[i](X[:,:SEQ_LEN,i]))"
      ],
      "metadata": {
        "id": "pdHuYpJ76lrL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding concatenation"
      ],
      "metadata": {
        "id": "EJHY9TrIrJZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
        "concat_outputs = concat_layer(outputs)\n",
        "concat_outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciA8DOxC62Gh",
        "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 4096, 704])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding resizing"
      ],
      "metadata": {
        "id": "irDZX1pjrTAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense_layer = tf.keras.layers.Dense(TOKEN_DIM)\n",
        "encoding = dense_layer(concat_outputs)\n",
        "encoding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsmamU5FRYXj",
        "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 4096, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional encoding"
      ],
      "metadata": {
        "id": "Rnls1ffVrRED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def get_positional_embedding_matrix(seq_len=SEQ_LEN, dim=TOKEN_DIM):\n",
        "    # From \"Attention is all you need\", https://arxiv.org/pdf/1706.03762.pdf\n",
        "    PE = np.zeros((seq_len, dim))\n",
        "    for pos in range(seq_len):\n",
        "        for i in range(int(dim/2)):\n",
        "            PE[pos,2*i]   = math.sin(pos/(10000**(2*i/dim)))\n",
        "            PE[pos,2*i+1] = math.cos(pos/(10000**(2*i/dim)))\n",
        "    return PE"
      ],
      "metadata": {
        "id": "01PpH7qxrZPh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positional_encoding_matrix = get_positional_embedding_matrix()"
      ],
      "metadata": {
        "id": "E3J8TF6kuPL3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In transformers, it is common to add the positional embedding to the elements embeddings."
      ],
      "metadata": {
        "id": "H9gJp6amvZNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum_layer = tf.keras.layers.Add()\n",
        "positional_encoding = tf.stack([positional_encoding_matrix]*BATCH_SIZE)\n",
        "final_encoding = sum_layer([encoding, positional_encoding])\n",
        "final_encoding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb9HQ-0BSKGq",
        "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 4096, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Output management"
      ],
      "metadata": {
        "id": "46AFqwicyt7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = decoder({'inputs_embeds': final_encoding})\n",
        "output['last_hidden_state'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPx3E2fhTVZz",
        "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 4096, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
      ],
      "metadata": {
        "id": "3HblbvOUy_RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dense_layers = [\n",
        "    # Type\n",
        "    tf.keras.layers.Dense(TYPE_RANGE, activation='softmax'),\n",
        "    # Measure\n",
        "    tf.keras.layers.Dense(MEASURE_RANGE, activation='softmax'),\n",
        "    # Beat\n",
        "    tf.keras.layers.Dense(BEAT_RANGE, activation='softmax'),\n",
        "    # Position\n",
        "    tf.keras.layers.Dense(POSITION_RANGE, activation='softmax'),\n",
        "    # Duration\n",
        "    tf.keras.layers.Dense(DURATION_RANGE, activation='softmax'),\n",
        "    # Pitch\n",
        "    tf.keras.layers.Dense(PITCH_RANGE, activation='softmax'),\n",
        "    # Instrument\n",
        "    tf.keras.layers.Dense(INSTRUMENT_RANGE, activation='softmax'),\n",
        "    # Velocity\n",
        "    tf.keras.layers.Dense(VELOCITY_RANGE, activation='softmax'),\n",
        "    # Key sign\n",
        "    tf.keras.layers.Dense(KEY_SIGN_RANGE, activation='softmax'),\n",
        "    # Time sign\n",
        "    tf.keras.layers.Dense(TIME_SIGN_RANGE, activation='softmax'),\n",
        "    # Tempo\n",
        "    tf.keras.layers.Dense(TEMPO_RANGE, activation='softmax')\n",
        "]"
      ],
      "metadata": {
        "id": "QNCtfIZAy0oE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
        "              for i in range(len(output_dense_layers))]\n",
        "\n",
        "for i in range(len(out_scores)):\n",
        "    print(out_scores[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4yR5-mn0RKj",
        "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 4096, 8)\n",
            "(2, 4096, 256)\n",
            "(2, 4096, 133)\n",
            "(2, 4096, 128)\n",
            "(2, 4096, 136)\n",
            "(2, 4096, 256)\n",
            "(2, 4096, 129)\n",
            "(2, 4096, 128)\n",
            "(2, 4096, 24)\n",
            "(2, 4096, 153)\n",
            "(2, 4096, 49)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Groundtruth vectors definition"
      ],
      "metadata": {
        "id": "eP3itCXL2usl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gt_vectors = [X[:,:SEQ_LEN,i] for i in range(len(out_scores))]\n",
        "\n",
        "for i in range(len(out_scores)):\n",
        "    print(gt_vectors[i].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKq9Gw71Pph",
        "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n",
            "(2, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Loss definition"
      ],
      "metadata": {
        "id": "Q0ed_yLa21HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "for i in range(len(out_scores)):\n",
        "    print(loss_function(gt_vectors[i], out_scores[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ExZcplE2t2N",
        "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.3346944, shape=(), dtype=float32)\n",
            "tf.Tensor(6.237889, shape=(), dtype=float32)\n",
            "tf.Tensor(4.7969894, shape=(), dtype=float32)\n",
            "tf.Tensor(5.776598, shape=(), dtype=float32)\n",
            "tf.Tensor(5.461115, shape=(), dtype=float32)\n",
            "tf.Tensor(5.213531, shape=(), dtype=float32)\n",
            "tf.Tensor(4.542588, shape=(), dtype=float32)\n",
            "tf.Tensor(3.9674158, shape=(), dtype=float32)\n",
            "tf.Tensor(4.785807, shape=(), dtype=float32)\n",
            "tf.Tensor(6.601122, shape=(), dtype=float32)\n",
            "tf.Tensor(5.358327, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
      ],
      "metadata": {
        "id": "ahyobawI6NNd"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ai4i')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "15ef3e0ab0adec7be592ab47f06e4d3b98c0d8692b1a5adde79c94ffcbd33e70"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}