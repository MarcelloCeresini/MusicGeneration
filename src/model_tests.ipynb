{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:56:34.946551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 12:56:35.096400: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-07 12:56:35.129315: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-07 12:56:35.723256: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:35.723329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:56:35.723337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for very high loads on GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:56:37.594233: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "decoder = conf.get_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': tf.ones((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=((TensorSpec(shape=(None, 6143, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 3), dtype=tf.uint8, name=None)), TensorSpec(shape=(None, 11, 6143), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6143, 11) (6, 3) (6, 11, 6143)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:56:45.119704: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())\n",
    "print(X[0].shape, X[1].shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['type'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['position'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X[0].shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[0][:, : ,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(conf.SINGLE_EMB_SIZE, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(conf.GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(X[1])\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6143, 704])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "concat_outputs = types_concat_layer(outputs)\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6143, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(conf.TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to preprend the genre embedding token to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "final_sequence = sequence_concat_layer([genre_embedding[:, np.newaxis, :], encoding])\n",
    "final_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnls1ffVrRED"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add positional encodings to encode which is the position of each token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E3J8TF6kuPL3"
   },
   "outputs": [],
   "source": [
    "positional_encoding_matrix = conf.get_positional_embedding_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gJp6amvZNw"
   },
   "source": [
    "In transformers, it is common to add the positional embedding to the elements embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb9HQ-0BSKGq",
    "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_layer = tf.keras.layers.Add()\n",
    "positional_encoding = tf.repeat(positional_encoding_matrix[np.newaxis, :, :], \n",
    "                                tf.constant(conf.BATCH_SIZE), axis=0)\n",
    "final_encoding = sum_layer([final_sequence, positional_encoding])\n",
    "final_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 6144, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_encoding})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['type'], activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['measure'], activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['beat'], activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['position'], activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['duration'], activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'], activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'], activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'], activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'], activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'], activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6144, 8)\n",
      "(6, 6144, 256)\n",
      "(6, 6144, 131)\n",
      "(6, 6144, 128)\n",
      "(6, 6144, 136)\n",
      "(6, 6144, 256)\n",
      "(6, 6144, 129)\n",
      "(6, 6144, 128)\n",
      "(6, 6144, 25)\n",
      "(6, 6144, 153)\n",
      "(6, 6144, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n",
      "(6, 6143)\n"
     ]
    }
   ],
   "source": [
    "gt_vectors = [y[:,i,:] for i in range(len(out_scores))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(gt_vectors[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function. The two distributions we are comparing are the input sequence (so we ignore the genre embedding token representation) and the output sequence up to the last token representation (`output[:-1]`)\n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=2.8545265>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1058583>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.7402787>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.391606>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.2320466>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.898656>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.850886>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.384283>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=3.990712>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.932314>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.7609296>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "losses = []\n",
    "for i in range(len(out_scores)):\n",
    "    losses.append(loss_function(gt_vectors[i], out_scores[i][:, :-1, :]))\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To these loss terms we can add some regularization terms that can help the model produce a grammatically correct sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "\n",
    "    \n",
    "class InstrumentsChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(InstrumentsChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types, instrument_scores = inputs\n",
    "        reg_term_2_list = []\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            instruments_in_batch = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 1)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_batch, _ = tf.unique(instruments_in_batch)\n",
    "            instruments_in_notes = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 3)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_notes, _, count_of_instruments_in_notes = \\\n",
    "                tf.unique_with_counts(instruments_in_notes)\n",
    "            undefined_instruments_in_notes = tf.sparse.to_dense(\n",
    "                  tf.sets.difference(tf.expand_dims(unique_instruments_in_notes, axis=0), \n",
    "                                     tf.expand_dims(unique_instruments_in_batch, axis=0)))[0]\n",
    "            indices_of_undefined_instruments = tf.where(\n",
    "                tf.expand_dims(undefined_instruments_in_notes, axis=1) == unique_instruments_in_notes)[:, 1]\n",
    "            count_of_undefined_instruments = tf.gather(count_of_instruments_in_notes, indices_of_undefined_instruments)\n",
    "            # Difference between the number of selected instruments and the number of unique instruments\n",
    "            # (AKA: number of duplicates)\n",
    "            reg_term_2_1 = tf.shape(instruments_in_batch)[0] - tf.shape(unique_instruments_in_batch)[0]\n",
    "            # Sum the number of undefined instruments in notes\n",
    "            reg_term_2_2 = tf.math.reduce_sum(count_of_undefined_instruments)\n",
    "            reg_term_2_list.append(reg_term_2_1 + reg_term_2_2)\n",
    "        return tf.math.reduce_sum(reg_term_2_list)\n",
    "\n",
    "    \n",
    "subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "instruments_checker = InstrumentsChecker()\n",
    "reg_scaler = 0.001\n",
    "\n",
    "    \n",
    "def custom_regularizers(y_pred):\n",
    "    # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "    max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "    ####### 1: PUNISHMENT FOR NON-CONSECUTIVE TYPES ##########\n",
    "    consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "    # Compute difference\n",
    "    differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "    # Compute regularization terms\n",
    "    # Difference between one element's type and the next is >= 0\n",
    "    reg_term_1_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "    # Difference between one element's type and the next is < 1\n",
    "    reg_term_1_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))  \n",
    "    reg_term_1 = reg_term_1_1 + reg_term_1_2\n",
    "    ####### 2: PUNISHMENT FOR NOTES WHOSE INSTRUMENT IS NOT DEFINED AND FOR DUPLICATE INSTRUMENTS ########\n",
    "    reg_term_2 = instruments_checker([max_pred_types, y_pred[6]])\n",
    "    return reg_scaler * ((tf.cast(reg_term_1, tf.float32)) + (tf.cast(reg_term_2, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.817>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_regularizers(out_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:11:09.239036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-07 12:11:09.374825: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-07 12:11:09.411998: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-07 12:11:09.947407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:11:09.947470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-07 12:11:09.947477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:11:11.790953: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "# Workaround for very high loads on GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from config import Config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CUSTOM LAYERS\n",
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "    \n",
    "# Custom intermediate layer for regularization that computes the loss related to duplicate instruments\n",
    "# definition and instruments that are used wrongly in the notes.\n",
    "class InstrumentsChecker(tf.keras.layers.Layer):\n",
    "     def __init__(self):\n",
    "        super(InstrumentsChecker, self).__init__()\n",
    "    \n",
    "     def call(self, inputs):\n",
    "        max_pred_types, instrument_scores = inputs\n",
    "        reg_term_2_list = tf.TensorArray(dtype=tf.int32, size=tf.shape(max_pred_types)[0])\n",
    "        for b in tf.range(tf.shape(max_pred_types)[0]):\n",
    "            instruments_in_batch = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 1)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_batch, _ = tf.unique(instruments_in_batch)\n",
    "            instruments_in_notes = tf.argmax(\n",
    "                tf.gather(instrument_scores[b], tf.where(max_pred_types[b] == 3)[:, 0]),\n",
    "                axis=-1)\n",
    "            unique_instruments_in_notes, _, count_of_instruments_in_notes = \\\n",
    "                tf.unique_with_counts(instruments_in_notes)\n",
    "            undefined_instruments_in_notes = tf.sparse.to_dense(\n",
    "                  tf.sets.difference(tf.expand_dims(unique_instruments_in_notes, axis=0), \n",
    "                                     tf.expand_dims(unique_instruments_in_batch, axis=0)))[0]\n",
    "            indices_of_undefined_instruments = tf.where(\n",
    "                tf.expand_dims(undefined_instruments_in_notes, axis=1) == unique_instruments_in_notes)[:, 1]\n",
    "            count_of_undefined_instruments = tf.gather(count_of_instruments_in_notes, indices_of_undefined_instruments)\n",
    "            # Difference between the number of selected instruments and the number of unique instruments\n",
    "            # (AKA: number of duplicates)\n",
    "            reg_term_2_1 = tf.shape(instruments_in_batch)[0] - tf.shape(unique_instruments_in_batch)[0]\n",
    "            # Sum the number of undefined instruments in notes\n",
    "            reg_term_2_2 = tf.math.reduce_sum(count_of_undefined_instruments)\n",
    "            reg_term_2_list = reg_term_2_list.write(b, reg_term_2_1 + reg_term_2_2)\n",
    "        return tf.math.reduce_sum(reg_term_2_list.concat())\n",
    "    \n",
    "    \n",
    "# Custom layer that computes masks for type probabilities computation\n",
    "class MaskTypeProbabilitiesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def create_mask(self, inputs):\n",
    "        '''\n",
    "        Takes as input the token types of ONE song --> conf.SEQ_LEN-1 * 1\n",
    "        Since the decoder creates an output for token i in output i-1 (i.e. the last output is not correlated with any token)\n",
    "        Creates the mask for the NEXT token (depending on token i it masks output i, that corresponds to scores for token i+1)\n",
    "        '''\n",
    "        batch_gt_types = inputs\n",
    "        mask = tf.TensorArray(tf.bool, size=conf.SEQ_LEN-1)\n",
    "        for i in tf.range(conf.SEQ_LEN-1):\n",
    "            token_type = batch_gt_types[i]\n",
    "            if token_type == 0: # only start of song token: cannot be anything else than instrument choice (1)\n",
    "                type_mask = tf.constant([False, True, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 1: # we reached instrument choice: cannot be anything else than instrument choice (1) or start of events (2)\n",
    "                type_mask = tf.constant([False, True, True, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 2: # after a 2 there must be at least a 4\n",
    "                type_mask = tf.constant([False, False, False, False, True, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 3: # allow 3,4,5,6,7\n",
    "                type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type >= 4 and token_type <= 6:\n",
    "                # - if there are at least a 5 and a 6 (there is always a 4)   --> [3, 4, 5, 6, 7]\n",
    "                # - if a 5 is missing, we only allow 5                        --> [5]\n",
    "                # - if a 6 is missing, we only allow 6                        --> [6]\n",
    "                # i+1 is needed because if current token_type is 5 it counts (otherwise it would always put 2 consecutive 5)\n",
    "                if tf.size(tf.where(batch_gt_types[:i+1] == 5)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, True, False, False], dtype=tf.bool)\n",
    "                elif tf.size(tf.where(batch_gt_types[:i+1] == 6)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, False, True, False], dtype=tf.bool)\n",
    "                else:\n",
    "                    type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change ending token to type 7s -> 7000000000\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, True], dtype=tf.bool)\n",
    "            else:\n",
    "                # ERROR. Define a random type mask so that it's defined in all branches for tf.function\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            mask = mask.write(i, type_mask)\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Takes as input the ground truth song (at training time) or the logits (at testing time) \n",
    "        and computes a mask for the type probabilities.\n",
    "        output masks is BATCH_SIZE * SEQ_LEN * 1 --> we mask also the last output even if it's useless\n",
    "        '''\n",
    "        if training:\n",
    "            # Use the groundtruth song as a target\n",
    "            song        = inputs\n",
    "            gt_types    = song[:,:,0]       # Get the token types from the song (batch_size x seq_len-1)\n",
    "            # Iterate over the batch to collect the appropriate masks from the song\n",
    "            masks = tf.vectorized_map(\n",
    "                fn=self.create_mask, \n",
    "                elems=gt_types\n",
    "            )\n",
    "            return masks\n",
    "        else:\n",
    "            # Compute the types and their masks one by one based on the type chosen at the previous iteration\n",
    "            # TODO: implement this branch\n",
    "            pass\n",
    "\n",
    "\n",
    "# The main masking layer applying all constraints based on the predicted types \n",
    "class MaskingActivationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        self.default_mask = conf.default_mask\n",
    "        self.full_mask    = conf.full_mask\n",
    "        self._numerators  = tf.constant(conf.numerators)\n",
    "        self._tot_numerators = tf.constant(conf.tot_numerators)\n",
    "\n",
    "    @tf.function\n",
    "    def get_max_beat_from_time_sign(self, time_sign):\n",
    "        '''\n",
    "        Since the time sign is defined (in utils.time_sign_map()) as: \n",
    "            conf.numerators.index(time_sign[0]) + conf.denominators.index(time_sign[1])*conf.tot_numerators\n",
    "\n",
    "        to retrieve the NUMERATOR of the time_sign given the index you need to divide by conf.tot_numerators and take the rest of the division\n",
    "        that gives you the index of the corresponding numerator in conf.numerators\n",
    "        then you use gather or, more simply, a slice to get the actual value of the numerator\n",
    "        '''\n",
    "        idx = tf.math.floormod(time_sign, self._tot_numerators)\n",
    "        return self._numerators[idx]\n",
    "\n",
    "    @tf.function\n",
    "    def get_mask_for_all_tokens(self, inputs): \n",
    "        '''\n",
    "        Inputs:\n",
    "        - chosen_types:         (SEQ_LEN-1)*1\n",
    "        - song_tokens:          (SEQ_LEN-1)*11\n",
    "        - seq_scores:           (SEQ_LEN-1)*1391\n",
    "\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "        Inputs are for a SINGLE ELEMENT OF A BATCH of size SEQ_LEN*(1+11+1391) where 1391 is the summed length of logits (minus the type)\n",
    "        '''\n",
    "        # Collect inputs from longer tensor\n",
    "        chosen_types, song_tokens, seq_scores = inputs\n",
    "        chosen_types = tf.cast(chosen_types, dtype=tf.int32)\n",
    "        song_tokens  = tf.cast(song_tokens , dtype=tf.int32)\n",
    "        # Indexes\n",
    "        index_tensor = tf.range(conf.SEQ_LEN-1, dtype=tf.int32)\n",
    "        # Define mask (output) using a TensorArray\n",
    "        mask = tf.TensorArray(dtype=tf.bool, size=conf.SEQ_LEN-1)\n",
    "        # Iterate over the indexes\n",
    "        for idx in index_tensor:\n",
    "            until_idx = idx+1\n",
    "            ## SETUP ##\n",
    "            # Define the default variables and flags\n",
    "            default_token_parts   = [True]*(len(conf.INPUT_RANGES)-1)\n",
    "            default_flag          = False\n",
    "            min_measure           = tf.constant(-1, dtype=tf.int32)\n",
    "            min_beat              = tf.constant(-1, dtype=tf.int32)\n",
    "            min_position          = tf.constant(-1, dtype=tf.int32)\n",
    "            # TODO: variable length arrays: can we do it with tensorarrays?\n",
    "            allowed_instruments   = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            allowed_key_sign      = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_time_sign     = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_tempo         = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_instruments_flag = False\n",
    "            forbidden_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            forbidden_key_sign    = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_time_sign   = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_tempo       = tf.constant(-1, dtype=tf.int32)\n",
    "            # Define the inputs\n",
    "            chosen_type = chosen_types[idx]\n",
    "            scores      = seq_scores[idx]\n",
    "            song = song_tokens # TODO: don't need to mask? Yeah we don't really need it!\n",
    "            ### song = song_tokens * (tf.expand_dims([1]*idx + [0]*(conf.SEQ_LEN-1-idx), axis=-1)) # Mask all tokens after index idx\n",
    "            ## MAIN BODY ##\n",
    "            if chosen_type == 0 or chosen_type == 2 or chosen_type == 7:\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "            elif chosen_type == 1: # Instrument selection, false only for type and instrument type (the ones that you can choose)\n",
    "                if tf.size(tf.where(song[:until_idx, 0] == 1)[:,0]) == 0:\n",
    "                    # Choice of first instrument\n",
    "                    default_token_parts = [True, True, True, True, True, False, True, True, True, True]\n",
    "                    default_flag = True\n",
    "                else:\n",
    "                    forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                        song[:until_idx, 6], \n",
    "                        tf.where(song[:until_idx, 0] == 1)[:,0]        # Cast to 1D array\n",
    "                    ))\n",
    "                    forbidden_instruments_flag = True\n",
    "            # Notes: They have the same key_sign, time_sign and tempo as last previous event, \n",
    "            # everything has to be manually decided\n",
    "            elif chosen_type == 3: \n",
    "                min_measure = song[idx, 1]   # It has to be >= than the last measure\n",
    "                # If in the MEASURE SCORES the MAX SCORE between all \n",
    "                # possible measures == min_measure, the measure is min_measure.\n",
    "                # In this case, we need to make sure that beat >= last_beat\n",
    "                if tf.math.argmax(\n",
    "                    scores[:conf.INPUT_RANGES[\"measure\"]], \n",
    "                        output_type=tf.int32) == min_measure:  \n",
    "                    min_beat = song[idx,2]      # It has to be >= than the last beat when measure is the same\n",
    "\n",
    "                    if tf.math.argmax(scores[\n",
    "                        conf.INPUT_RANGES[\"measure\"] : \n",
    "                        conf.INPUT_RANGES[\"measure\"] + conf.INPUT_RANGES[\"beat\"]], \n",
    "                        output_type=tf.int32) == min_beat:\n",
    "                        min_position = song[idx,3]  # It has to be >= than the last position (if beat and measure are the same)\n",
    "                    else:\n",
    "                        min_position = tf.constant(0, dtype=tf.int32)\n",
    "                else:\n",
    "                    min_beat = tf.constant(0, dtype=tf.int32)\n",
    "                    min_position = tf.constant(0, dtype=tf.int32)\n",
    "\n",
    "                # Only some instruments, key signs, time signs and tempos are allowed for these events: \n",
    "                # - for instruments, the allowed ones are the ones that have been defined previously with type = 1\n",
    "                # - for the others, the allowed ones are the ones that are collected right before the note \n",
    "                #   from event types 4, 5 and 6\n",
    "                allowed_instruments, _ = tf.unique(tf.gather(\n",
    "                    song[:until_idx, 6], \n",
    "                    tf.where(song[:until_idx, 0] == 1)[:,0]\n",
    "                ))\n",
    "                # We have made it so that the model should output 3s only after at least a 4, 5 and 6.\n",
    "                allowed_key_sign = tf.gather(\n",
    "                    song[:until_idx, 8], \n",
    "                    tf.where(song[:until_idx, 0] == 4)[:,0]   # if type == 4 --> read the LAST key_sign\n",
    "                )[-1] \n",
    "                allowed_time_sign = tf.gather(\n",
    "                    song[:until_idx, 9], \n",
    "                    tf.where(song[:until_idx, 0] == 5)[:,0]   # if type == 5 --> read the LAST time_sign\n",
    "                )[-1] \n",
    "                allowed_tempo = tf.gather(\n",
    "                    song[:until_idx, 10], \n",
    "                    tf.where(song[:until_idx, 0] == 6)[:,0]   # if type == 6 --> read the LAST tempo\n",
    "                )[-1] \n",
    "            elif chosen_type >= 4 and chosen_type <= 6:     # key_sign, time_sign, tempo\n",
    "                # If last event is at the beginning of a measure, you can add an event at the same time\n",
    "                if song[idx, 3] == 0 and song[idx, 2] == 0:  # if beat and position == 0, the event can be at this measure\n",
    "                    min_measure = song[idx, 1]\n",
    "                else:\n",
    "                    min_measure = song[idx, 1] + 1                   # otherwise it goes to the next measure\n",
    "                # Fine-grain checks\n",
    "                # Here, there are cases where there is not a LAST key_sign/time_sign (when this is the first 4, 5 or 6). \n",
    "                # In these cases we should use the default masks.\n",
    "                if chosen_type == 4:\n",
    "                    # Cannot put the same key_sign again\n",
    "                    tmp = tf.gather(\n",
    "                        song[:until_idx, 8], \n",
    "                        tf.where(song[:until_idx, 0] == 4)[:,0]) # if type == 4 --> read all the key_sign\n",
    "                    if tf.size(tmp) > 0: # if there is at least one before this\n",
    "                        forbidden_key_sign = tmp[-1] # cannot choose the LAST key_sign\n",
    "                elif chosen_type == 5:\n",
    "                    # Cannot put the same time_sign again\n",
    "                    tmp = tf.gather(\n",
    "                        song[:until_idx, 9], \n",
    "                        tf.where(song[:until_idx, 0] == 5)[:,0]) # if type == 5 --> read the LAST time_sign\n",
    "                    if tf.size(tmp) > 0:\n",
    "                        forbidden_time_sign = tmp[-1]\n",
    "                elif chosen_type == 6:\n",
    "                    # Cannot put the same tempo again\n",
    "                    tmp = tf.gather(\n",
    "                        song[:until_idx, 10], \n",
    "                        tf.where(song[:until_idx, 0] == 6)[:,0]) # if type == 6 --> read the LAST tempo\n",
    "                    if tf.size(tmp) > 9:\n",
    "                        forbidden_tempo = tmp[-1]\n",
    "\n",
    "            ## ENDING PART ##\n",
    "            # Put together the masks\n",
    "            if default_flag:                \n",
    "                # No manual masking required, either \"can freely choose this part of the token\" (True) or \n",
    "                # \"can only choose default for this part of the token\" (False)\n",
    "                mask = mask.write(idx, tf.concat(\n",
    "                    # Default mask only allows to predict a 0\n",
    "                    # Full mask allows to predict any value\n",
    "                    [self.default_mask[i] if default_token_parts[i] else self.full_mask[i] \n",
    "                        for i in range(len(default_token_parts))], axis=-1)\n",
    "                )\n",
    "            elif forbidden_instruments_flag:\n",
    "                # Default flag is False and forbidden instruments contains some elmeents \n",
    "                # (which means that the chosen type is 1)\n",
    "                instruments_mask = tf.sparse.SparseTensor(  # Forbidden instruments\n",
    "                        indices= tf.expand_dims(tf.cast(forbidden_instruments, tf.int64), axis=-1),\n",
    "                        values = tf.zeros_like(forbidden_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                instruments_mask = tf.cast(\n",
    "                    tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "                \n",
    "                # Only mask the forbidden instruments, all the rest is default\n",
    "                mask = mask.write(idx, tf.concat(\n",
    "                    [self.default_mask[i] for i in range(5)] + \\\n",
    "                    [instruments_mask] + \\\n",
    "                    [self.default_mask[i] for i in range(6,len(default_token_parts))], \n",
    "                    axis=-1))\n",
    "            elif chosen_type >= 3 and chosen_type <= 6:\n",
    "                # General event. What we do depends on which specific event it is, but\n",
    "                # in general there is always a measure mask.\n",
    "                \n",
    "                measure_mask = tf.cast(\n",
    "                    tf.concat([\n",
    "                            tf.repeat([False], min_measure),        # Can be equal to or greater than min_measure\n",
    "                            tf.repeat([True],  conf.INPUT_RANGES[\"measure\"]-min_measure)\n",
    "                        ], axis=-1\n",
    "                    ), dtype=tf.bool\n",
    "                )\n",
    "                # We need to do manual masking. Define all tensors (default_masks will most probably \n",
    "                # be changed, full_masks won't)\n",
    "                beat_mask        = self.default_mask[1]\n",
    "                position_mask    = self.default_mask[2]\n",
    "                duration_mask    = self.default_mask[3]\n",
    "                pitch_mask       = self.default_mask[4]\n",
    "                instruments_mask = self.default_mask[5]\n",
    "                velocity_mask    = self.default_mask[6]\n",
    "                key_sign_mask    = self.default_mask[7]\n",
    "                time_sign_mask   = self.default_mask[8]\n",
    "                tempo_mask       = self.default_mask[9]\n",
    "                # Create more specific masks depending on the type\n",
    "                if chosen_type == 4:\n",
    "                    if forbidden_key_sign != -1: ## forbidden_key_sign can only appear if chosen_type = 4\n",
    "                        # True in all places but the forbidden key signs\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    else:\n",
    "                        key_sign_mask = self.full_mask[7]\n",
    "                elif chosen_type == 5:\n",
    "                    if forbidden_time_sign != -1: ## forbidden_time_sign can only appear if chosen_type = 5\n",
    "                        # True in all places but the forbidden time signs\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    else:\n",
    "                        time_sign_mask = self.full_mask[8]\n",
    "                elif chosen_type == 6:\n",
    "                    if forbidden_tempo != -1: ## forbidden_tempo can only appear if chosen_type = 6\n",
    "                        # True in all places but the forbidden tempos\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    else:\n",
    "                        tempo_mask = self.full_mask[9]\n",
    "                elif chosen_type == 3:\n",
    "                    # can always choose any of the below for a note\n",
    "                    duration_mask    = self.full_mask[3]\n",
    "                    pitch_mask       = self.full_mask[4]\n",
    "                    velocity_mask    = self.full_mask[6]\n",
    "\n",
    "                    # If the event is a note, we have ALLOWED time signs/tempos/key signs, not\n",
    "                    # forbidden ones. Also, there are many other elements to take into account\n",
    "                    if min_beat != -1: # it is ALWAYS != -1 if chosen_type == 3\n",
    "                        # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                        max_beat = self.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                        # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                        beat_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_beat),\n",
    "                            tf.repeat([True],  max_beat-min_beat), \n",
    "                            tf.repeat([False], conf.INPUT_RANGES[\"beat\"]-max_beat)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.bool)\n",
    "                        \n",
    "                    if min_position != -1: # it is ALWAYS != -1 if chosen_type == 3\n",
    "                        position_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_position), \n",
    "                            tf.repeat([True],  conf.INPUT_RANGES[\"position\"]-min_position)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.dtypes.bool)\n",
    "\n",
    "                    instruments_mask = tf.sparse.SparseTensor( # Allowed instruments\n",
    "                        indices=tf.expand_dims(tf.cast(allowed_instruments, tf.int64), axis=-1),\n",
    "                        values=tf.ones_like(allowed_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                    instruments_mask = tf.cast(\n",
    "                        tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=0),\n",
    "                        dtype=tf.dtypes.bool)\n",
    "\n",
    "                    if allowed_key_sign != -1: # it is ALWAYS != -1 if chosen_type == 3\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_time_sign != -1: # it is ALWAYS != -1 if chosen_type == 3\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_tempo != -1: # it is ALWAYS != -1 if chosen_type == 3\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                \n",
    "                mask = mask.write(idx, tf.concat([\n",
    "                    measure_mask, beat_mask, position_mask, duration_mask,\n",
    "                    pitch_mask, instruments_mask, velocity_mask, key_sign_mask,\n",
    "                    time_sign_mask, tempo_mask], axis=-1))\n",
    "\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Inputs:\n",
    "        - songs:                BATCH*(SEQ_LEN-1)*11\n",
    "        - out_logits:           BATCH*(SEQ_LEN-1)*1391 (all except type)\n",
    "        - types_probabilities:  BATCH*(SEQ_LEN-1)*8 --> becomes chosen_types through argmax --> BATCH*(SEQ_LEN-1)*1\n",
    "\n",
    "        passes through map_fn --> get_mask_fro_all_tokens to debatch\n",
    "        '''\n",
    "        songs, out_logits, types_probabilities = inputs\n",
    "        chosen_types  = tf.expand_dims(tf.math.argmax(types_probabilities, axis=2), axis=-1) # TODO: check if SEQ_LEN -1 or -2\n",
    "        concat_logits = tf.concat(out_logits[1:], axis=-1)   # Concatenate all logits (except type) into a tensor batch_size x seq_len x 1391\n",
    "        masks = tf.map_fn(fn=self.get_mask_for_all_tokens, elems=(         # Iterate function over batch dimension \n",
    "                tf.cast(chosen_types, concat_logits.dtype),                # BATCH*(SEQ_LEN-1)*1\n",
    "                tf.cast(songs,   concat_logits.dtype),                     # BATCH*(SEQ_LEN-1)*11\n",
    "                concat_logits                                              # BATCH*(SEQ_LEN-1)*1391 \n",
    "                # TODO: check if SLICE is needed or we could directly pass the full concat_logits\n",
    "            ), fn_output_signature=tf.TensorSpec(                          # Total: a BATCH * SEQ_LEN-1 * 1403 tensor\n",
    "                (conf.SEQ_LEN-1, conf.input_ranges_sum - conf.INPUT_RANGES['type']),\n",
    "                dtype=tf.bool\n",
    "            ))\n",
    "\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation function (to be called within a scope in case of MultiGPU training)\n",
    "def create_model(input_shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), num_genres=len(conf.accepted_subgenres), \n",
    "                 use_regularization=True, use_masking_layers=False, reg_loss_scale=conf.REG_LOSS_SCALE):\n",
    "    \n",
    "    # Get input shapes\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate transformer decoder (n_emb % n_head must be 0)\n",
    "    decoder = conf.get_decoder()\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs',  dtype=tf.int32)\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres', dtype=tf.float32)\n",
    "    \n",
    "    # Define loss\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "    instruments_checker = InstrumentsChecker()\n",
    "    reg_scaler = tf.constant(reg_loss_scale, dtype=tf.float32)\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['type'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='type_embeddings'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'],    conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='measure_embeddings'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='beat_embeddings'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['position'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='position_embeddings'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='duration_embeddings'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='pitch_embeddings'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='instrument_embeddings'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='velocity_embeddings'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='key_sign_embeddings'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'],  conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='time_sign_embeddings'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='tempo_embeddings')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(conf.GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    input_concat_layer         = tf.keras.layers.Concatenate(axis=2)\n",
    "    sequence_concat_layer      = tf.keras.layers.Concatenate(axis=1)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(conf.TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = conf.get_positional_embedding_matrix()\n",
    "    positional_encoding        = tf.repeat(positional_encoding_matrix[tf.newaxis, :, :], tf.shape(songs)[0], axis=0)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['type'],       name='type_scores'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['measure'],    name='measure_scores'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['beat'],       name='beat_scores'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['position'],   name='position_scores'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['duration'],   name='duration_scores'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'],      name='pitch_scores'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], name='instrument_scores'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'],   name='velocity_scores'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'],   name='keysign_scores'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'],  name='timesign_scores'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'],      name='tempo_scores')\n",
    "    ]\n",
    "    \n",
    "    output_probs_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Softmax(name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Softmax(name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Softmax(name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Softmax(name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Softmax(name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Softmax(name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Softmax(name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Softmax(name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Softmax(name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Softmax(name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Softmax(name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Masking layers\n",
    "    if use_masking_layers:\n",
    "        type_masking_layer = MaskTypeProbabilitiesLayer()\n",
    "        activations_masking =  MaskingActivationLayer()\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    input_embedding   = input_concat_layer(embeddings)\n",
    "    input_embedding   = encoding_processing_layer(input_embedding)\n",
    "    input_embedding   = sequence_concat_layer([genre_embedding[:, np.newaxis, :], input_embedding])\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output)[:,:-1,:] \n",
    "                         for i in range(len(output_dense_layers))]\n",
    "    # We don't care about the last scores, since they refer to a token that's out of bounds.\n",
    "    if use_masking_layers:\n",
    "        type_mask           = type_masking_layer(songs, training=True)\n",
    "        types_probabilities = output_probs_layers[0](out_scores[0], type_mask) # BATCH_SIZE * SEQ_LEN-1 * 8\n",
    "        full_mask           = activations_masking([songs, out_scores, types_probabilities])\n",
    "        # Unpack the final masks into a list of masks\n",
    "        index = 0; masks = []          \n",
    "        for key in conf.INPUT_RANGES:\n",
    "            if key != 'type':\n",
    "                masks.append(full_mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "                index += conf.INPUT_RANGES[key]\n",
    "        # Call all the softmax layers\n",
    "        out_probabilities = [types_probabilities] + [\n",
    "            output_probs_layers[i](out_scores[i], masks[i-1]) \n",
    "            for i in range(1, len(output_dense_layers))]\n",
    "    else:\n",
    "        out_probabilities = [output_probs_layers[i](out_scores[i]) \n",
    "                             for i in range(len(output_dense_layers))]\n",
    "                \n",
    "    out_probabilities_dict = {\n",
    "        key: out_probabilities[i] \n",
    "        for i, key in enumerate(conf.INPUT_RANGES.keys())\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=[songs, genres], \n",
    "                           outputs=out_probabilities_dict, \n",
    "                           name='music_generation_model')\n",
    "    \n",
    "    # Define loss\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        y_true_concat_batch = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "        y_pred_concat_batch = tf.reshape(y_pred, [-1, y_pred.shape[2]])\n",
    "        print(tf.shape(y_true_concat_batch), tf.shape(y_pred_concat_batch))\n",
    "        loss = loss_function(y_true_concat_batch, y_pred_concat_batch) * \\\n",
    "                (1. / (conf.GLOBAL_BATCH_SIZE * (conf.SEQ_LEN-1)))\n",
    "        return loss\n",
    "    \n",
    "    # Define regularizers\n",
    "    def custom_regularizers(y_pred):\n",
    "        # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "        max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "        \n",
    "        ####### 1: PUNISHMENT FOR NON-CONSECUTIVE TYPES ##########\n",
    "        consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "        # Compute difference\n",
    "        differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "        # Compute regularization terms\n",
    "        # Difference between one element's type and the next is >= 0\n",
    "        reg_term_1_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "        # Difference between one element's type and the next is < 1\n",
    "        reg_term_1_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))  \n",
    "        reg_term_1 = reg_term_1_1 + reg_term_1_2\n",
    "        \n",
    "        ####### 2: PUNISHMENT FOR NOTES WHOSE INSTRUMENT IS NOT DEFINED AND FOR DUPLICATE INSTRUMENTS ########\n",
    "        reg_term_2 = instruments_checker([max_pred_types, y_pred[6]])\n",
    "        \n",
    "        ####### PUT TOGETHER THE REGULARIZATION TERMS #######\n",
    "        return reg_scaler * ((tf.cast(reg_term_1, tf.float32)) + (tf.cast(reg_term_2, tf.float32)))\n",
    "    \n",
    "    # Add losses\n",
    "    for i in range(len(conf.INPUT_RANGES.keys())):\n",
    "        loss_name = list(conf.INPUT_RANGES.keys())[i] + '_loss'\n",
    "        loss = custom_loss(y_true = songs[:,:,i], y_pred = out_probabilities[i])\n",
    "        model.add_loss(loss)\n",
    "        model.add_metric(loss, name=loss_name)\n",
    "    \n",
    "    if use_regularization:\n",
    "        reg_loss = custom_regularizers(out_scores)\n",
    "        model.add_loss(reg_loss)\n",
    "        model.add_metric(reg_loss, name='regularization_loss')\n",
    "    \n",
    "    # Compile and return\n",
    "    model.compile(optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = create_model(num_genres=3)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = create_model(num_genres=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.GLOBAL_BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 12:11:18.416811: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([6, 6143, 8]), TensorShape([6, 6143, 256]), TensorShape([6, 6143, 131]), TensorShape([6, 6143, 128]), TensorShape([6, 6143, 136]), TensorShape([6, 6143, 256]), TensorShape([6, 6143, 129]), TensorShape([6, 6143, 128]), TensorShape([6, 6143, 25]), TensorShape([6, 6143, 153]), TensorShape([6, 6143, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model(X)\n",
    "print([v.shape for _, v in output.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([7.9883321e-05, 1.7104689e-04, 1.5939602e-04, ..., 9.0220765e-06,\n",
       "        1.6190688e-05, 2.6771866e-05], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00016506, 0.00016132, 0.00016299, ..., 0.00020587, 0.00020113,\n",
       "        0.00020101], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00014699, 0.00013932, 0.0001286 , ..., 0.00018773, 0.00018012,\n",
       "        0.00016372], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00012519, 0.00011968, 0.0001362 , ..., 0.00015573, 0.00017212,\n",
       "        0.00017882], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([1.02272301e-04, 9.45103602e-05, 1.03286424e-04, ...,\n",
       "        2.37903514e-04, 2.27107870e-04, 2.18184228e-04], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00020506, 0.00019206, 0.00019558, ..., 0.00013992, 0.0001384 ,\n",
       "        0.00013836], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([1.5584241e-04, 1.5136448e-04, 9.7535245e-05, ..., 1.0538345e-04,\n",
       "        1.1626913e-04, 1.3360748e-04], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00014247, 0.00015433, 0.00017274, ..., 0.00016056, 0.00015998,\n",
       "        0.00015774], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([1.0917363e-04, 9.5506810e-05, 1.0259436e-04, ..., 9.7679615e-05,\n",
       "        9.7821030e-05, 1.0321919e-04], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00011944, 0.000129  , 0.0001437 , ..., 0.00018432, 0.00019097,\n",
       "        0.0001877 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(36858,), dtype=float32, numpy=\n",
       " array([0.00012539, 0.00014042, 0.00014543, ..., 0.00011097, 0.00010419,\n",
       "        0.00010162], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.295>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
