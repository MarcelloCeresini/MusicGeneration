{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFJBJsxdptr0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import muspy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# muspy.download_musescore_soundfont()\n",
        "\n",
        "\n",
        "N_CPUS = os.cpu_count()\n",
        "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVGWCb8ptr5"
      },
      "source": [
        "# Warning, ~ 10 hours required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFO8spMhptr9",
        "outputId": "5b0bc28b-4d90-4c97-df85-068266d081ef"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = os.path.join(ROOT_PATH, \"data/lmd/\")\n",
        "\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    os.mkdir(DATASET_PATH)\n",
        "    \n",
        "if len(os.listdir(DATASET_PATH)) == 0:\n",
        "    lmd = muspy.LakhMIDIDataset(DATASET_PATH, download_and_extract=True, convert=True, n_jobs=N_CPUS)\n",
        "else:\n",
        "    lmd = muspy.LakhMIDIDataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPWbZwBgptr-",
        "outputId": "52a2978a-b9dc-4e2f-efc6-f211d835c5a7"
      },
      "outputs": [],
      "source": [
        "# print(len(lmd[1]))\n",
        "# print(np.unique(list(track.program for track in lmd[1].tracks)))\n",
        "for i in range(10000):\n",
        "    if len(k_sings := lmd[i].key_signatures) > 1: \n",
        "        print(k_sings)\n",
        "\n",
        "# print(i)\n",
        "# print(lmd[i])\n",
        "\n",
        "# muspy.write_audio(os.path.join(ROOT_PATH, \"data/songs\"), lmd[19])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug_q_wM_ptsA",
        "outputId": "3f3de27a-03fc-438a-fc76-0457926e0e20"
      },
      "outputs": [],
      "source": [
        "((time_s.numerator, time_s.denominator) for time_s in lmd[7].time_signatures)\n",
        "\n",
        "for i in range(100):\n",
        "    print(\"----\")\n",
        "    for tims_s in lmd[i].time_signatures:\n",
        "        print((tims_s.numerator, tims_s.denominator))\n",
        "    \n",
        "# time_signatures = np.unique(((time_s.numerator, time_s.denominator) for time_s in lmd[7].time_signatures)) \n",
        "# time_signatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QigYOSOuptsC",
        "outputId": "2b797967-cdd5-4300-bca7-d1f267174f83"
      },
      "outputs": [],
      "source": [
        "lmd[19].beats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw-8FZCBqH-W"
      },
      "outputs": [],
      "source": [
        "def transform_representation(song: muspy.music.Music, verbose=0):\n",
        "\n",
        "    '''\n",
        "    This function accepts as input a song in the muspy format and transforms it in a series of tuples written in the following way\n",
        "\n",
        "                            Description                                                     Interval                                                Possible values\n",
        "    (\n",
        "        type,               # see below -->                                                 [0, 7] -->                                              8\n",
        "        measure,            # index of the measure inside the song in interval -->          [0, last_measure] -->                                   512?\n",
        "        beat,               # index of beat inside measure -->                              [0, numerator of time_signature] -->                    ??\n",
        "        position,           # index with 1/64 beat length granularity -->                   [0, 63/64] -->                                          64\n",
        "        duration,           # hierarchical structure? -->                                   ??? better to specify after dataset exploration                                  \n",
        "        pitch,              # height of pitch (128) + drums (another 128) -->               [0, 255] -->                                            256\n",
        "        instrument_type,    # 128 instrument types + 1 for drums -->                        [0, 128] -->                                            129\n",
        "        n_instrument,       # same instrument twice in the song for multiple voices -->     [0, 7??] -->                                            8\n",
        "        velocity,           # amplitude of note, strength of play -->                       [0, 127] -->                                            128\n",
        "        key_sign,           # [0,11] (all possible notes) and [maj,min] -->                 [0, 23] -->                                             24\n",
        "        time_sign,          # denominator pow(2) in [1,64] and numerator int in [0,128] --> ??? better to specify after dataset exploration\n",
        "        tempo,              # qpm, geometric progression from 16 to 256 -->                 [0, 48] -->                                             49\n",
        "    )\n",
        "\n",
        "    type:\n",
        "        0: start of song\n",
        "        1: new instrument\n",
        "        2: start of events\n",
        "        3: note\n",
        "        4: key_signature change event\n",
        "        5: time_signature change event\n",
        "        6: tempo change event\n",
        "        7: end of song\n",
        "\n",
        "    if type = 0 --> all values 0\n",
        "    if type = 1 --> only instrument_type must be specified (and n_instrument is 1 bigger than the previous identical instrument defined) (other values are 0)\n",
        "    if type = 2 --> all values 0\n",
        "\n",
        "    then, before ANY type = 3, MUST FOLLOW at least one of each:\n",
        "        type = 4 --> only key_sign (other values are 0)\n",
        "        type = 5 --> only time_sign (other values are 0)\n",
        "        type = 6 --> only tempo (other values are 0)\n",
        "\n",
        "    if type = 3 --> all values are full, and key_sign, time_sign and tempo are identical to the last 4, 5 or 6 respectively\n",
        "    if type = 7 --> all values 0, end of the representation\n",
        "    '''\n",
        "    \n",
        "    final_song = []\n",
        "\n",
        "    t = 0\n",
        "    events = []\n",
        "    n_battuta = 0\n",
        "\n",
        "\n",
        "    for t_sign, i in enumerate(song.time_signatures):\n",
        "        if i == 0:\n",
        "            current_t_sign = (t_sign.numerator, t_sign.denominator)\n",
        "        else:\n",
        "            events.append((t_sign.timestep, \"t_sign\", t_sign.numerator, t_sign.denominator))\n",
        "\n",
        "    for beat, i in enumerate(song.beats):\n",
        "        if i == 0:\n",
        "            current_beat = beat.qpm\n",
        "        else:\n",
        "            events.append((beat.timestep, \"beat\", beat.qpm))\n",
        "\n",
        "    for k_sign, i in enumerate(song.key_signatures):\n",
        "        if i == 0:\n",
        "            current_k_sign = (k_sign.key, k_sign.major_minor)\n",
        "        else:\n",
        "            events.append((k_sign.timestep, \"k_sign\", k_sign.key, k_sign.major_minor))\n",
        "\n",
        "    events.sort(key = lambda x: x[0])\n",
        "\n",
        "\n",
        "    notes = np.concatenate([track.notes for track in song.tracks if len(track) > 0])    # stats on notes\n",
        "\n",
        "    resolution = song.resolution\n",
        "    length_battuta = time_signatures[idx_t_sing].denominator * resolution\n",
        "    length_beat = length_battuta / time_signatures[idx_t_sing].numerator\n",
        "\n",
        "    current_settings = (\n",
        "        current_t_sign,\n",
        "        current_beat,\n",
        "        current_k_sign\n",
        "    )\n",
        "\n",
        "    current_note_idx = 0\n",
        "\n",
        "    while i < len(events):\n",
        "        event = events[i]\n",
        "        flag_new_event = False\n",
        "        \n",
        "        if event[1] == \"t_sign\":\n",
        "            if event[2] != current_t_sign[0] and event[3] != current_t_sign[1]:\n",
        "                current_t_sign = (event[2], event[3])\n",
        "                final_song.append(current_t_sign)   # WRITE CORRECT REPRESENTATION\n",
        "                flag_new_event = True\n",
        "        \n",
        "        if event[1] == \"beat\":\n",
        "            if event[2] != current_beat:\n",
        "                current_beat = event[2]\n",
        "                final_song.append(current_beat) ############\n",
        "                flag_new_event = True\n",
        "\n",
        "        if event[1] == \"k_sign\":\n",
        "            if event[2] != current_k_sign[0] and event[3] != current_k_sign[1]:\n",
        "                current_k_sign = (event[2], event[3])\n",
        "                final_song.append(current_k_sign) #########\n",
        "                flag_new_event = True\n",
        "\n",
        "        if flag_new_event:\n",
        "            \n",
        "            delta_t = event[0] - ((event[0]-t) % length_battuta) # events can only happen at the beginning of a battuta\n",
        "            # if the event happens in the middle of a beat because midi is \"wrong\" --> move the event to the beginning of THAT battuta (not the following one)\n",
        "\n",
        "            final_song, current_note_idx = add_notes( # shouldn't do anything if there are no notes between current time and t+delta_t\n",
        "                current_settings, \n",
        "                current_note_idx, \n",
        "                \n",
        "            )\n",
        "\n",
        "            t = t + \n",
        "            \n",
        "            current_settings = (\n",
        "                current_t_sign,\n",
        "                current_beat,\n",
        "                current_k_sign\n",
        "            )\n",
        "\n",
        "        i+=1\n",
        "\n",
        "\n",
        "    final_song, _ = add_notes(current_settings, current_note_idx, song_finish) # should append every note between current note and note with timestep \"song_finish\", should return index of last note added \n",
        "\n",
        "\n",
        "    next_event = \n",
        "\n",
        "    length_battuta = resolution * \n",
        "\n",
        "\n",
        "    time_signatures = np.unique(list((time_s.numerator, time_s.denominator) for time_s in lmd[i].time_signatures)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u277Y0l4ptsC",
        "outputId": "998cc900-df89-4e92-c2d6-aa4c0c9b4583"
      },
      "outputs": [],
      "source": [
        "stats = {\n",
        "    \"n_tracks\" : np.zeros(1000),            # how many instruments are playing in a song (can also be 2 of the same instrument)\n",
        "    \"programs\" : np.zeros(128),             # which type of instrument\n",
        "    \"velocity\" : np.zeros(128),             # how loud (0-127)\n",
        "    \"durations\": np.zeros(100000),          # how many quarters does the note last(?)\n",
        "    \"tempos\": {},                           # how fast is the song in qpm (quarters per minute) --> can be non integer\n",
        "    \"time_signatures\": {},                  # 4/4 or 3/4 etc... store it as a dict\n",
        "    \"key_signatures\": np.zeros(100),        # which is the main key\n",
        "    \"key_mode\": {\"major\": 0 , \"minor\":0}    # if main key is major or minor\n",
        "}\n",
        "\n",
        "for song in tqdm(lmd):\n",
        "    stats[\"n_tracks\"][len(song)] += 1                                                   # how many tracks are in the song (tracks = different \"instrument voices\" but could be 4 pianos)\n",
        "    \n",
        "    programs = np.unique(list(track.program for track in song.tracks))                  # how many different instruments and which\n",
        "    for program in programs:\n",
        "        stats[\"programs\"][program] += 1\n",
        "\n",
        "             \n",
        "    tempos = np.unique(list(tempo.qpm for tempo in lmd[i].tempos))                      # stats on tempos (maybe not useful, but what do we do if tempo changes mid song?)\n",
        "\n",
        "    for tempo in tempos:\n",
        "        if tempo in stats[\"tempos\"].keys():\n",
        "            stats[\"tempos\"][tempo] += 1\n",
        "        else:\n",
        "            stats[\"tempos\"][tempo] = 1\n",
        "\n",
        "\n",
        "                                                                                        # stats on time_signatures --> need to know which exist / are used to create possible tokens\n",
        "    time_signatures = np.unique(list((time_s.numerator, time_s.denominator) for time_s in lmd[i].time_signatures)) \n",
        "\n",
        "    for time_s in time_signatures:\n",
        "        if time_s in stats[\"time_signatures\"].keys():\n",
        "            stats[\"time_signatures\"][time_s] += 1\n",
        "        else:\n",
        "            stats[\"time_signatures\"][time_s] = 1\n",
        "\n",
        "\n",
        "    key_signatures = song.key_signatures\n",
        "\n",
        "\n",
        "    notes = np.concatenate([track.notes for track in song.tracks if len(track) > 0])    # stats on notes\n",
        "    \n",
        "    for duration in np.unique(list(note.duration for note in notes)):\n",
        "        stats[\"durations\"][duration] += 1\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
