{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58bf6029-bdb2-4dcc-a429-296ca8191125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 21:49:18.893660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 21:49:19.026741: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-04 21:49:19.065592: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-06-04 21:49:19.623197: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-04 21:49:19.623264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-04 21:49:19.623271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 21:49:21.262958: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import scipy.stats as st\n",
    "\n",
    "# # Workaround for very high loads on GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# # Or use single GPU\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "\n",
    "MODEL_TYPE = 'GPT'\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH, model_type=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ce7d7-39be-47e2-9434-08e6521bfd79",
   "metadata": {},
   "source": [
    "# Music Generation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b974aa-2795-4118-a625-5470ad32c06f",
   "metadata": {},
   "source": [
    "We implemented several metrics and statistics that we compare across our sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bbbcc-5e60-4ed2-b196-afce41caed4d",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e44e0d6-05d1-4aaa-9907-927459bb7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_note(token):\n",
    "    return token[0] == 3 and token[6] < 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb536f86-84ac-47c6-b606-a6fb45d6ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes_in_measures(song, start_measure, end_measure):\n",
    "    # If it's a note with the same measure and its pitch is not drums-related\n",
    "    return [token for token in song \n",
    "            if (is_note(token) and start_measure <= token[1] < end_measure)]\n",
    "\n",
    "def pitch_class_histogram_entropy_metric(song, window_size=1):\n",
    "    # Compute the mean pitch class histogram entropy in a song\n",
    "    # using the specified number of measures (window_size).\n",
    "    # Usually, interesting metrics use window_size 1 and 4\n",
    "    song_measures = np.unique(song[:,1])\n",
    "    if len(song_measures) < window_size:\n",
    "        # print(f\"\\tSong has too few measures for window size {window_size}:\"\n",
    "        #      f\" reverting back to a window size of {len(song_measures)}\")\n",
    "        window_size = len(song_measures)\n",
    "    # Slide the window over the song to compute the entropy of notes in those measures\n",
    "    entropy_for_windows = []\n",
    "    for st_measure in range(0, len(song_measures) - window_size + 1):\n",
    "        end_measure = st_measure + window_size\n",
    "        notes = get_notes_in_measures(song, st_measure, end_measure) \n",
    "        if len(notes) > 0:\n",
    "            notes_pitches = np.array([n[5] for n in notes])\n",
    "            notes_classes = notes_pitches % 12 # {C, C#, ..., Bb, B}\n",
    "            hist, edges = np.histogram(notes_classes, bins=list(range(12)))\n",
    "            hist = hist / np.sum(hist)   # Normalize by total note count in the period\n",
    "            hist = hist + 1e-10 # Avoid log of 0\n",
    "            entropy = -np.sum(hist * (np.log(hist) / np.log(2))) # Fast log2 implementation\n",
    "            entropy_for_windows.append(entropy)\n",
    "        else:\n",
    "            # print(f\"\\tWindow from measures {st_measure} to {end_measure} has no notes.\")\n",
    "            continue\n",
    "    if len(entropy_for_windows) > 0:\n",
    "        return np.mean(entropy_for_windows)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9ca8ef-fcee-4797-80b5-1c5d2cbf6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poliphony_metric(song):\n",
    "    notes_by_start_time = {}\n",
    "    notes_in_song = 0\n",
    "    for token in song:\n",
    "        if is_note(token):   # Notes\n",
    "            notes_in_song += 1\n",
    "            start_time = token[1]*conf.INPUT_RANGES['beat']*conf.INPUT_RANGES['position'] + \\\n",
    "                         token[2]*conf.INPUT_RANGES['position'] + token[3]\n",
    "            if start_time in notes_by_start_time:\n",
    "                notes_by_start_time[start_time].append(token)\n",
    "            else:\n",
    "                notes_by_start_time[start_time] = [token]\n",
    "    return sum([len(notes_list) > 1 for notes_list in notes_by_start_time.values()]) / notes_in_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a57ed78-ade8-4927-a278-6ad268cbbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_span_metric(song):\n",
    "    lowest_pitch = 128\n",
    "    highest_pitch = 0\n",
    "    for token in song:\n",
    "        if is_note(token):  # Notes\n",
    "            if token[5] < lowest_pitch:\n",
    "                lowest_pitch = token[5]\n",
    "            if token[5] > highest_pitch:\n",
    "                highest_pitch = token[5]\n",
    "    return highest_pitch - lowest_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fd9a3e-5e78-43bc-a004-e6fc21f90410",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tones = {'C':   0,\n",
    "              'C#':  1, \n",
    "              'D':   2,\n",
    "              'D#':  3,\n",
    "              'E':   4,\n",
    "              'F':   5,\n",
    "              'F#':  6,\n",
    "              'G':   7,\n",
    "              'G#':  8,\n",
    "              'A':   9,\n",
    "              'A#': 10,\n",
    "              'B':  11}\n",
    "\n",
    "scale = {}\n",
    "# Most important scales:\n",
    "# Major scale:\n",
    "scale['major'] = [0,2,4,5,7,9,11]\n",
    "#(W-W-H-W-W-W-H)\n",
    "#(2 2 1 2 2 2 1)\n",
    "\n",
    "# Natural minor scale:\n",
    "scale['natural_minor'] = [0,2,3,5,7,8,10]\n",
    "#(W-H-W-W-H-W-W)\n",
    "#(2 1 2 2 1 2 2)\n",
    " \n",
    "# Harmonic minor scale:\n",
    "scale['harmonic_minor'] = [0,2,3,5,7,8,11]\n",
    "#(W-H-W-W-H-WH-H)\n",
    "#(2 1 2 2 1 3 1)\n",
    " \n",
    "def tones_to_scales(tones):\n",
    "    counts = {}\n",
    "    for base_tone in base_tones:\n",
    "        counts[base_tone] = {}\n",
    "        counts[base_tone]['major'] = 0\n",
    "        counts[base_tone]['natural_minor'] = 0\n",
    "        counts[base_tone]['harmonic_minor'] = 0\n",
    "\n",
    "    # If no tones, return 0 for each note in each scale\n",
    "    if not len(tones):\n",
    "        frequencies = {}\n",
    "        for base_tone in base_tones:\n",
    "            frequencies[base_tone] = {}\n",
    "            for scale_label in scale:\n",
    "                frequencies[base_tone][scale_label] = 0.0\n",
    "        return frequencies\n",
    "    \n",
    "    # Otherwise, compute scale consistency and their frequency\n",
    "    for tone in tones:\n",
    "        # For each note...\n",
    "        for base_tone in base_tones:\n",
    "            # For each of the base pitches...\n",
    "            for scale_label in scale:\n",
    "                # For each of the available scales...\n",
    "                if tone%12-base_tones[base_tone] in scale[scale_label]:\n",
    "                    # If the distance between the tone and the base tone is in a scale, \n",
    "                    # add 1 to that scale starting from that base tone\n",
    "                    counts[base_tone][scale_label] += 1\n",
    "    # Transform these counts into frequencies\n",
    "    frequencies = {}\n",
    "    for base_tone in counts:\n",
    "        frequencies[base_tone] = {}\n",
    "        for scale_label in counts[base_tone]:\n",
    "            frequencies[base_tone][scale_label] = float(counts[base_tone][scale_label])/float(len(tones))\n",
    "    return frequencies\n",
    "\n",
    "def max_likelihood_scale(tones):\n",
    "    # Get scale statistics\n",
    "    scale_statistics = tones_to_scales(tones) \n",
    "    stat_list = []\n",
    "    for base_tone in scale_statistics:\n",
    "        for scale_label in scale_statistics[base_tone]:\n",
    "            stat_list.append((base_tone, scale_label, scale_statistics[base_tone][scale_label]))\n",
    "    # Get the most likely scale and its likelihood\n",
    "    stat_list.sort(key=lambda e: e[2], reverse=True)\n",
    "    return (stat_list[0][0]+' '+stat_list[0][1], stat_list[0][2])\n",
    "\n",
    "def scale_consistency_metric(song):\n",
    "    tones = [token[5] for token in song if is_note(token)]\n",
    "    ml = max_likelihood_scale(tones)\n",
    "    stats = {}\n",
    "    stats['scale'] = ml[0] # <-- we ignore it for now but it's cool to see which is the most likely scale for a song\n",
    "    stats['scale_score'] = ml[1]\n",
    "    return stats['scale_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dbb020-fa1e-4fa9-a54a-b2f037175448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF NOTES\n",
    "def n_notes_metric(song):\n",
    "    return sum([1 for token in song if is_note(token)])\n",
    "\n",
    "# AVERAGE NOTE DURATION\n",
    "def avg_note_duration_metric(song):\n",
    "    return np.mean([token[4] for token in song if is_note(token)])\n",
    "\n",
    "# MAX SILENCE BETWEEN EVENTS\n",
    "def max_offset_duration_metric(song):\n",
    "    offsets = []\n",
    "    for i in range(len(song)-1):\n",
    "        token = song[i]\n",
    "        if is_note(token):\n",
    "            j = i+1; next_token = song[j]\n",
    "            while not is_note(next_token) and j < len(song)-1:\n",
    "                j += 1; next_token = song[j]\n",
    "            if not is_note(next_token): break\n",
    "            empty_measures = next_token[1] - token[1]\n",
    "            empty_beats = (int(next_token[2]) - int(token[2])) % conf.numerators[token[9] % conf.tot_numerators]\n",
    "            empty_positions = (int(next_token[3]) - int(token[3])) % len(conf.np_positions)\n",
    "            beats_offset = empty_measures * conf.numerators[token[9] % conf.tot_numerators] + empty_beats\n",
    "            offset = beats_offset * len(conf.np_positions) + empty_positions\n",
    "            offsets.append(offset)\n",
    "        elif token[0] == 7:\n",
    "            break\n",
    "    return max(offsets) if len(offsets) > 0 else 0\n",
    "\n",
    "# REPETITIONS IN MEASURES\n",
    "def avg_unique_pitches_in_measure_metric(song):\n",
    "    # Average number of different pitches in a measures\n",
    "    pitches_per_measure = {}\n",
    "    for token in song:\n",
    "        if is_note(token):\n",
    "            measure = token[1]\n",
    "            if measure in pitches_per_measure:\n",
    "                # Add pitch to set\n",
    "                pitches_per_measure[measure].add(token[5])\n",
    "            else:\n",
    "                # Create set\n",
    "                pitches_per_measure[measure] = set([token[5]])\n",
    "    avg_pitches_per_measure = np.mean([len(s) for s in pitches_per_measure.values()])\n",
    "    return avg_pitches_per_measure\n",
    "\n",
    "def repetition_factor_metric(song):\n",
    "    measures = {}\n",
    "    for token in song:\n",
    "        if is_note(token):\n",
    "            measure = token[1]\n",
    "            if measure in measures:\n",
    "                measures[measure].append((token[2], token[3], token[5])) # beat, position, pitch\n",
    "            else:\n",
    "                measures[measure] = [(token[2], token[3], token[5])]\n",
    "    tot_measures = len(measures)\n",
    "    matchings = {}\n",
    "    for measure_1 in measures:\n",
    "        matchings[measure_1] = 0\n",
    "        for measure_2 in measures:\n",
    "            if measure_1 != measure_2 and measures[measure_1] == measures[measure_2]:\n",
    "                matchings[measure_1] += 1\n",
    "        matchings[measure_1] /= tot_measures\n",
    "    return max(matchings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ede0a9-7c45-40ed-9e0a-d996c633e898",
   "metadata": {},
   "source": [
    "## Metrics computation on our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bcdf16-c5b4-4cd8-b9a6-9fc63641b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, _, test_set = utils.get_dataset_splits(conf.dataset_paths['lmd_matched_final_2048_cut'], conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd973e41-49e5-4434-a0df-52af946e3e32",
   "metadata": {},
   "source": [
    "The generated set has to be created \"manually\". We load all of the related songs and stack them into a large matrix. Then use dataloader utilities to create a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c05527fa-8ca2-4c84-b49e-acf63bc608c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the songs of the generated dataset (tensor of shape (4000, 2047, 11))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=TensorSpec(shape=(None, 2047, 11), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# FIND MATRICES\n",
    "filename_pattern = os.path.join(conf.DATA_PATH, 'generated_songs', 'repr', '*top_p_0_9_*.npy')\n",
    "filenames = glob(filename_pattern)\n",
    "# LOAD + CONCAT MATRICES\n",
    "songs = [np.load(fn) for fn in filenames]\n",
    "songs = np.concatenate(songs, axis=0)\n",
    "print(f\"Loaded the songs of the generated dataset (tensor of shape {songs.shape})\")\n",
    "# CREATE DATASET AROUND MATRICES\n",
    "gen_set = tf.data.Dataset.from_tensor_slices(songs).batch(conf.GLOBAL_BATCH_SIZE).\\\n",
    "                                                    cache().\\\n",
    "                                                    shuffle(conf.SHUFFLE_SIZE).\\\n",
    "                                                    prefetch(conf.PREFETCH_SIZE)\n",
    "gen_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d106634-610b-4334-9f26-015f73d1a4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55596, 6960, 4002)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set) * conf.BATCH_SIZE, len(test_set) * conf.BATCH_SIZE, len(gen_set) * conf.BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d13f3-2b56-4afd-89eb-9822b218ea3f",
   "metadata": {},
   "source": [
    "Note: for the metric computation we randomly sample 1/5 of the dataset, to make the analysis a little faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0dbdfed-33eb-4b93-ba01-e99e15819b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collect_stats_batch(song_batch, stat):\n",
    "    vals = []\n",
    "    for song in song_batch:\n",
    "        if stat == 'entropy_1':\n",
    "            val = pitch_class_histogram_entropy_metric(song, window_size = 1)\n",
    "        elif stat == 'entropy_4':\n",
    "            val = pitch_class_histogram_entropy_metric(song, window_size = 4)\n",
    "        elif stat == 'poliphony':\n",
    "            val = poliphony_metric(song)\n",
    "        elif stat == 'tone_span':\n",
    "            val = tone_span_metric(song)\n",
    "        elif stat == 'scale_consistency':\n",
    "            val = scale_consistency_metric(song)\n",
    "        elif stat == 'n_notes':\n",
    "            val = n_notes_metric(song)\n",
    "        elif stat == 'avg_note_duration':\n",
    "            val = avg_note_duration_metric(song)\n",
    "        elif stat == 'max_offset':\n",
    "            val = max_offset_duration_metric(song)\n",
    "        elif stat == 'unique_pitches_in_measure':\n",
    "            val = avg_unique_pitches_in_measure_metric(song)\n",
    "        elif stat == 'measure_repetition':\n",
    "            val = repetition_factor_metric(song)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        vals.append(val)\n",
    "    return vals\n",
    "\n",
    "def collect_stats(dataset, stat, portion=20, iterator_mode='default'):\n",
    "    values = []\n",
    "    dataset = dataset.shuffle(len(dataset) // 100 * portion).take(len(dataset) // 100 * portion)\n",
    "    dataset_iter = dataset.as_numpy_iterator()\n",
    "    if iterator_mode == 'default':\n",
    "        for X, _ in tqdm(dataset_iter, total=len(dataset)):\n",
    "            batch_vals = _collect_stats_batch(X[0], stat)\n",
    "            for v in batch_vals: values.append(v)\n",
    "    elif iterator_mode == 'gen_set':\n",
    "        for song_batch in tqdm(dataset_iter, total=len(dataset)):\n",
    "            batch_vals = _collect_stats_batch(song_batch, stat)\n",
    "            for v in batch_vals: values.append(v)\n",
    "    else:\n",
    "        raise ValueError(f'iterator_mode {iterator_mode} not supported')\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d4da750-87f1-40cc-ab85-00d2b3d5a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stat(dataset, stat_name, stats, eval_name = 'train'):\n",
    "    print(f\"Computing metric {stat_name}\")\n",
    "    s = time.time()\n",
    "    vals = collect_stats(dataset, stat_name, portion=100, \n",
    "                         iterator_mode='default' if 'gen' not in eval_name else 'gen_set')\n",
    "    e = time.time()\n",
    "    stats[stat_name + '_mean'] = float(np.mean(vals))\n",
    "    stats[stat_name + '_std'] = float(np.std(vals))\n",
    "    stats[stat_name + '_interval'] = [float(x) \n",
    "        for x in st.t.interval(\n",
    "            0.95, len(vals)-1, \n",
    "            loc=np.mean(vals), \n",
    "            scale=st.sem(vals)\n",
    "        )]\n",
    "    stats[stat_name + '_time'] = float(e-s)\n",
    "    with open(f'evaluation_stats_{eval_name}.json', 'w') as f:\n",
    "        json.dump(stats, f)\n",
    "\n",
    "def evaluate(dataset, eval_name='train'):\n",
    "    stats = {}\n",
    "    run_stat(dataset, 'entropy_1', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'entropy_4', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'poliphony', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'tone_span', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'scale_consistency', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'n_notes', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'avg_note_duration', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'max_offset', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'unique_pitches_in_measure', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'measure_repetition', stats, eval_name=eval_name)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb401e-6499-4600-aca9-5f713485a0de",
   "metadata": {},
   "source": [
    "### Train set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36f0c0-35ea-4f7a-9142-48d272c30e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(train_set, eval_name='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee2e30-b2b0-4eb2-bf2f-70ed9ada4728",
   "metadata": {},
   "source": [
    "### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73b78-c7ad-4283-9f99-72d32feaa9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_set, eval_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb47b8-9fda-4820-9aad-0a1e1f78c941",
   "metadata": {},
   "source": [
    "### Generated set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "364ad32c-91bb-4be9-8b29-8b6d2283537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric entropy_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [14:16<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric entropy_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [12:54<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric poliphony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:45<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric tone_span\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:21<00:00, 28.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric scale_consistency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [07:18<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric n_notes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:19<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric avg_note_duration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:20<00:00, 29.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric max_offset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:40<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric unique_pitches_in_measure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:22<00:00, 26.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric measure_repetition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:25<00:00, 23.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'entropy_1_mean': 1.1916802662785957,\n",
       " 'entropy_1_std': 0.5802743191916998,\n",
       " 'entropy_1_interval': [1.1727107007735627, 1.2106498317836287],\n",
       " 'entropy_1_time': 856.3519761562347,\n",
       " 'entropy_4_mean': 1.2298731605167605,\n",
       " 'entropy_4_std': 0.6255078695915011,\n",
       " 'entropy_4_interval': [1.2094248792234268, 1.2503214418100943],\n",
       " 'entropy_4_time': 774.6415026187897,\n",
       " 'poliphony_mean': 0.07734177408677449,\n",
       " 'poliphony_std': 0.10476434322110692,\n",
       " 'poliphony_interval': [0.07391695584892308, 0.08076659232462591],\n",
       " 'poliphony_time': 45.98257493972778,\n",
       " 'tone_span_mean': 38.225403001667594,\n",
       " 'tone_span_std': 21.483981895575045,\n",
       " 'tone_span_interval': [37.523076897619525, 38.92772910571566],\n",
       " 'tone_span_time': 21.375214338302612,\n",
       " 'scale_consistency_mean': 0.9578259564450549,\n",
       " 'scale_consistency_std': 0.08844709185678003,\n",
       " 'scale_consistency_interval': [0.9549353643874049, 0.9607165485027048],\n",
       " 'scale_consistency_time': 438.4157907962799,\n",
       " 'n_notes_mean': 2026.0430794886047,\n",
       " 'n_notes_std': 26.93125460020563,\n",
       " 'n_notes_interval': [2025.162678303553, 2026.9234806736563],\n",
       " 'n_notes_time': 19.374397039413452,\n",
       " 'avg_note_duration_mean': 13.211417104241143,\n",
       " 'avg_note_duration_std': 19.475315898224178,\n",
       " 'avg_note_duration_interval': [12.574755669392212, 13.848078539090073],\n",
       " 'avg_note_duration_time': 20.25498390197754,\n",
       " 'max_offset_mean': 1099.7078932740412,\n",
       " 'max_offset_std': 4417.765789562346,\n",
       " 'max_offset_interval': [955.2880994638804, 1244.127687084202],\n",
       " 'max_offset_time': 101.013112783432,\n",
       " 'unique_pitches_in_measure_mean': 5.224628503904369,\n",
       " 'unique_pitches_in_measure_std': 3.229618620107222,\n",
       " 'unique_pitches_in_measure_interval': [5.119050056014865, 5.330206951793873],\n",
       " 'unique_pitches_in_measure_time': 22.66651678085327,\n",
       " 'measure_repetition_mean': 0.018501203231335518,\n",
       " 'measure_repetition_std': 0.09517604144023807,\n",
       " 'measure_repetition_interval': [0.015389833155325171, 0.021612573307345864],\n",
       " 'measure_repetition_time': 25.295456886291504}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gen_set, eval_name='gen_p_0_9')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313399b-84fc-4df4-af84-5a2f6b22199b",
   "metadata": {},
   "source": [
    "## Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7ba1c5a-e40e-40af-b1de-f4526e9a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evaluation_stats_train.json', 'r') as f:\n",
    "    train_stats = json.load(f)\n",
    "    \n",
    "with open('evaluation_stats_test.json', 'r') as f:\n",
    "    test_stats = json.load(f)\n",
    "    \n",
    "with open('evaluation_stats_gen_p_0_9.json', 'r') as f:\n",
    "    gen_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f33cce18-5045-4364-9f34-dcb08b1f5359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= TRAIN =============\n",
      "entropy_1: $2.33 \\pm 0.01$\n",
      "entropy_4: $2.68 \\pm 0.00$\n",
      "poliphony: $0.21 \\pm 0.00$\n",
      "tone_span: $58.39 \\pm 0.23$\n",
      "scale_consistency: $0.81 \\pm 0.00$\n",
      "n_notes: $1929.77 \\pm 6.46$\n",
      "avg_note_duration: $26.23 \\pm 0.19$\n",
      "max_offset: $796.34 \\pm 7.22$\n",
      "unique_pitches_in_measure: $13.18 \\pm 0.07$\n",
      "measure_repetition: $0.00 \\pm 0.00$\n",
      "============= TEST =============\n",
      "entropy_1: $2.31 \\pm 0.02$\n",
      "entropy_4: $2.68 \\pm 0.01$\n",
      "poliphony: $0.21 \\pm 0.00$\n",
      "tone_span: $58.10 \\pm 0.66$\n",
      "scale_consistency: $0.81 \\pm 0.01$\n",
      "n_notes: $1924.47 \\pm 18.35$\n",
      "avg_note_duration: $26.29 \\pm 0.59$\n",
      "max_offset: $805.82 \\pm 31.45$\n",
      "unique_pitches_in_measure: $12.99 \\pm 0.21$\n",
      "measure_repetition: $0.00 \\pm 0.00$\n",
      "============= GEN_P_0.9 =============\n",
      "entropy_1: $1.19 \\pm 0.02$\n",
      "entropy_4: $1.23 \\pm 0.02$\n",
      "poliphony: $0.08 \\pm 0.00$\n",
      "tone_span: $38.23 \\pm 0.70$\n",
      "scale_consistency: $0.96 \\pm 0.00$\n",
      "n_notes: $2026.04 \\pm 0.88$\n",
      "avg_note_duration: $13.21 \\pm 0.64$\n",
      "max_offset: $1099.71 \\pm 144.42$\n",
      "unique_pitches_in_measure: $5.22 \\pm 0.11$\n",
      "measure_repetition: $0.02 \\pm 0.00$\n"
     ]
    }
   ],
   "source": [
    "metrics = ['entropy_1', 'entropy_4', 'poliphony', 'tone_span',\n",
    "           'scale_consistency', 'n_notes', 'avg_note_duration', \n",
    "           'max_offset', 'unique_pitches_in_measure', \n",
    "           'measure_repetition']\n",
    "\n",
    "stat_sets = {'train': train_stats, 'test': test_stats, 'gen_p_0.9': gen_stats}\n",
    "\n",
    "for k, v in stat_sets.items():\n",
    "    print(\"============= \" + k.upper() + \" =============\")\n",
    "    for metric in metrics:\n",
    "        m = v[f'{metric}_mean']\n",
    "        m_around =  m - v[f'{metric}_interval'][0]\n",
    "        print(f\"{metric}: ${m:.2f} \\pm {m_around:.2f}$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
