{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:23.734772: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 18:14:23.851201: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-26 18:14:23.882939: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 18:14:24.447294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:14:24.447350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:14:24.447357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:25.498247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:26.588167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30970 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-11-26 18:14:26.588759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30970 MB memory:  -> device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "decoder = conf.get_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': tf.ones((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 6143, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 3), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6143, 11) (12, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:31:55.627353: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.as_numpy_iterator())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['type'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['position'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X.shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[:, : ,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(conf.SINGLE_EMB_SIZE, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(conf.GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(y)\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6143, 704])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "concat_outputs = types_concat_layer(outputs)\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6143, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(conf.TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to preprend the genre embedding token to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "final_sequence = sequence_concat_layer([genre_embedding[:, np.newaxis, :], encoding])\n",
    "final_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnls1ffVrRED"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add positional encodings to encode which is the position of each token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "E3J8TF6kuPL3"
   },
   "outputs": [],
   "source": [
    "positional_encoding_matrix = conf.get_positional_embedding_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gJp6amvZNw"
   },
   "source": [
    "In transformers, it is common to add the positional embedding to the elements embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb9HQ-0BSKGq",
    "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_layer = tf.keras.layers.Add()\n",
    "positional_encoding = tf.repeat(positional_encoding_matrix[np.newaxis, :, :], tf.constant(conf.BATCH_SIZE), axis=0)\n",
    "final_encoding = sum_layer([final_sequence, positional_encoding])\n",
    "final_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_encoding})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['type'], activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['measure'], activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['beat'], activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['position'], activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['duration'], activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'], activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'], activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'], activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'], activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'], activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6144, 8)\n",
      "(12, 6144, 256)\n",
      "(12, 6144, 131)\n",
      "(12, 6144, 128)\n",
      "(12, 6144, 136)\n",
      "(12, 6144, 256)\n",
      "(12, 6144, 129)\n",
      "(12, 6144, 128)\n",
      "(12, 6144, 25)\n",
      "(12, 6144, 153)\n",
      "(12, 6144, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n"
     ]
    }
   ],
   "source": [
    "gt_vectors = [X[:,:,i] for i in range(len(out_scores))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(gt_vectors[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function. The two distributions we are comparing are the input sequence (so we ignore the genre embedding token representation) and the output sequence up to the last token representation (`output[:-1]`)\n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=3.624619>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1048756>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.639281>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1507883>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.737446>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3642745>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.920309>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8808045>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.109704>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3772664>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1257977>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "losses = []\n",
    "for i in range(len(out_scores)):\n",
    "    losses.append(loss_function(gt_vectors[i], out_scores[i][:, :-1, :]))\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To these loss terms we can add some regularization terms that can help the model produce a grammatically correct sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "types = gt_vectors[0]\n",
    "max_pred_types = tf.argmax(out_scores[0], axis=2) # 6, 6144\n",
    "# Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "keys_tensor = tf.range(TYPE_RANGE, dtype=tf.int32)\n",
    "vals_tensor = tf.constant([0,1,2,3,3,3,3,4], dtype=tf.int32)\n",
    "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), default_value=-1)\n",
    "consecutive_gt_types   = table.lookup(tf.cast(types, tf.int32))\n",
    "consecutive_pred_types = table.lookup(tf.cast(max_pred_types, tf.int32))\n",
    "# Note: we assume that after token token type 7 all following token types are 7s\n",
    "differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=5554>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1567>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some constraint to pose for regularization\n",
    "reg_term_1 = tf.reduce_sum(tf.math.maximum(0, -differences))                           # Difference between one element's type and the next is >= 0\n",
    "reg_term_2 = tf.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))    # Difference between one element's type and the next is < 1\n",
    "\n",
    "reg_term_1, reg_term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=67.156166>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REG_SCALER = 0.001\n",
    "\n",
    "total_loss = tf.reduce_sum(losses) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_1, tf.float32) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_2, tf.float32)\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 03:33:15.938035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 03:33:16.091152: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-27 03:33:16.126891: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-27 03:33:16.745832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-27 03:33:16.745904: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-27 03:33:16.745911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-27 03:33:17.814817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 03:33:18.948459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 26391 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-11-27 03:33:18.949039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30487 MB memory:  -> device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "from config import Config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CUSTOM LAYERS\n",
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "    \n",
    "    \n",
    "# Custom layer that computes masks for type probabilities computation\n",
    "class MaskTypeProbabilitiesLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "\n",
    "    @tf.function\n",
    "    def create_mask(self, inputs):\n",
    "        batch_gt_types = inputs\n",
    "        mask = tf.TensorArray(tf.bool, size=conf.SEQ_LEN)\n",
    "        mask = mask.write(0, tf.constant([True, False, False, False, False, False, False, False], dtype=tf.bool))\n",
    "        for i in tf.range(conf.SEQ_LEN-1):\n",
    "            token_type = batch_gt_types[i]\n",
    "            if token_type == 0: # only start of song token: cannot be anything else than instrument choice (1)\n",
    "                type_mask = tf.constant([False, True, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 1: # we reached instrument choice: cannot be anything else than instrument choice (1) or start of events (2)\n",
    "                type_mask = tf.constant([False, True, True, False, False, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 2: # after a 2 there must be at least a 4\n",
    "                type_mask = tf.constant([False, False, False, False, True, False, False, False], dtype=tf.bool)\n",
    "            elif token_type == 3: # allow 3,4,5,6,7\n",
    "                type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type >= 4 and token_type <= 6:\n",
    "                # - if there are at least a 5 and a 6 (there is always a 4)   --> [3, 4, 5, 6, 7]\n",
    "                # - if a 5 is missing, we only allow 5                        --> [5]\n",
    "                # - if a 6 is missing, we only allow 6                        --> [6]\n",
    "                if tf.size(tf.where(batch_gt_types[:i] == 5)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, True, False, False], dtype=tf.bool)\n",
    "                if tf.size(tf.where(batch_gt_types[:i] == 6)) == 0:\n",
    "                    type_mask = tf.constant([False, False, False, False, False, False, True, False], dtype=tf.bool)\n",
    "                else:\n",
    "                    type_mask = tf.constant([False, False, False, True, True, True, True, True], dtype=tf.bool)\n",
    "            elif token_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change ending token to type 7s -> 7000000000\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, True], dtype=tf.bool)\n",
    "            else:\n",
    "                # ERROR. Define a random type mask so that it's defined in all branches for tf.function\n",
    "                type_mask = tf.constant([False, False, False, False, False, False, False, False], dtype=tf.bool)\n",
    "            mask = mask.write(i+1, type_mask)\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Takes as input the ground truth song (at training time) or the logits (at testing time) \n",
    "        and computes a mask for the type probabilities.\n",
    "        '''\n",
    "        if training:\n",
    "            # Use the groundtruth song as a target\n",
    "            song        = inputs\n",
    "            gt_types    = song[:,:,0]       # Get the token types from the song (batch_size x seq_len-1)\n",
    "            # Iterate over the batch to collect the appropriate masks from the song\n",
    "            masks = tf.map_fn(fn=self.create_mask, \n",
    "                elems=gt_types, \n",
    "                fn_output_signature=tf.TensorSpec(\n",
    "                    (conf.SEQ_LEN, conf.INPUT_RANGES['type']), \n",
    "                    dtype=tf.bool)\n",
    "            )\n",
    "            return masks\n",
    "        else:\n",
    "            # Compute the types and their masks one by one based on the type chosen at the previous iteration\n",
    "            # TODO: implement this branch\n",
    "            pass\n",
    "\n",
    "\n",
    "# The main masking layer applying all constraints based on the predicted types \n",
    "class MaskingActivationLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, trainable=False, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        self.default_mask = conf.default_mask\n",
    "        self.full_mask    = conf.full_mask\n",
    "        self._numerators  = tf.constant(conf.numerators)\n",
    "        self._tot_numerators = tf.constant(conf.tot_numerators)\n",
    "\n",
    "    @tf.function\n",
    "    def get_max_beat_from_time_sign(self, time_sign):\n",
    "        '''\n",
    "        Since the time sign is defined (in utils.time_sign_map()) as: \n",
    "            conf.numerators.index(time_sign[0]) + conf.denominators.index(time_sign[1])*conf.tot_numerators\n",
    "\n",
    "        to retrieve the NUMERATOR of the time_sign given the index you need to divide by conf.tot_numerators and take the rest of the division\n",
    "        that gives you the index of the corresponding numerator in conf.numerators\n",
    "        then you use gather or, more simply, a slice to get the actual value of the numerator\n",
    "\n",
    "        You then subtract 1 because the beat is in [0, numerator)\n",
    "        '''\n",
    "        idx = tf.math.floormod(time_sign, self._tot_numerators)\n",
    "        return self._numerators[idx] - 1\n",
    "\n",
    "    @tf.function\n",
    "    def get_mask_for_all_tokens(self, inputs): \n",
    "        '''\n",
    "        Inputs:\n",
    "        - chosen_types:         (SEQ_LEN-1)*1\n",
    "        - song_tokens:          (SEQ_LEN-1)*11\n",
    "        - seq_scores:           (SEQ_LEN-1)*1391\n",
    "\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "        Inputs are for a SINGLE ELEMENT OF A BATCH of size SEQ_LEN*(1+11+1391) where 1391 is the summed length of logits (minus the type)\n",
    "        '''\n",
    "        # Collect inputs from longer tensor\n",
    "        chosen_types, song_tokens, seq_scores = inputs\n",
    "        chosen_types = tf.cast(chosen_types, dtype=tf.int32)\n",
    "        song_tokens  = tf.cast(song_tokens , dtype=tf.int32)\n",
    "        seq_scores   = tf.cast(seq_scores  , dtype=tf.int32)\n",
    "        # Indexes\n",
    "        index_tensor = tf.range(conf.SEQ_LEN-1, dtype=tf.int32)\n",
    "        # Define mask (output) using a TensorArray\n",
    "        mask = tf.TensorArray(dtype=tf.bool, size=conf.SEQ_LEN-1)\n",
    "        # Iterate over the indexes\n",
    "        for idx in index_tensor:\n",
    "            ## SETUP ##\n",
    "            # Define the default variables and flags\n",
    "            default_token_parts   = [True]*(len(conf.INPUT_RANGES)-1)\n",
    "            default_flag          = False\n",
    "            min_measure           = tf.constant(-1, dtype=tf.int32)\n",
    "            min_beat              = tf.constant(-1, dtype=tf.int32)\n",
    "            min_position          = tf.constant(-1, dtype=tf.int32)\n",
    "            # TODO: variable length arrays: can we do it with tensorarrays?\n",
    "            allowed_instruments   = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            allowed_key_sign      = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_time_sign     = tf.constant(-1, dtype=tf.int32)\n",
    "            allowed_tempo         = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_instruments_flag = False\n",
    "            forbidden_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.int32)\n",
    "            forbidden_key_sign    = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_time_sign   = tf.constant(-1, dtype=tf.int32)\n",
    "            forbidden_tempo       = tf.constant(-1, dtype=tf.int32)\n",
    "            # Define the inputs\n",
    "            chosen_type = chosen_types[idx]\n",
    "            scores      = seq_scores[idx]\n",
    "            song        = song_tokens * (tf.expand_dims([1]*idx + [0]*(conf.SEQ_LEN-1-idx), axis=-1)) # Mask all tokens after index idx\n",
    "            ## MAIN BODY ##\n",
    "            if chosen_type == 0 or chosen_type == 2: # TODO: change 0s to 7s at the end of the song\n",
    "                # Original comments: \n",
    "                # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "                # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "            elif chosen_type == 1: # Instrument selection, false only for type and instrument type (the ones that you can choose)\n",
    "                if tf.size(tf.where(song[:idx, 0] == 1)[:,0]) == 0:\n",
    "                    # Choice of first instrument\n",
    "                    default_token_parts = [True, True, True, True, True, False, True, True, True, True]  # TODO: Element 6 should not be default = True right?\n",
    "                    default_flag = True\n",
    "                else:\n",
    "                    forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                        song[:idx, 6], \n",
    "                        tf.where(song[:idx, 0] == 1)[:,0]        # Cast to 1D array\n",
    "                    ))\n",
    "                    forbidden_instruments_flag = True\n",
    "            elif chosen_type == 3: # Notes: They have the same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "                min_measure = song[idx, 1]   # It has to be >= than the last measure\n",
    "                # If in the MEASURE SCORES the MAX SCORE between all possible measures == min_measure, the measure is min_measure.\n",
    "                # In this case, we need to make sure that beat >= last_beat\n",
    "                if tf.math.argmax(\n",
    "                    scores[:conf.INPUT_RANGES[\"measure\"]], \n",
    "                        output_type=tf.int32) == min_measure:  \n",
    "                    min_beat = song[idx,2]      # It has to be >= than the last beat when measure is the same\n",
    "                    if tf.math.argmax(scores[\n",
    "                        conf.INPUT_RANGES[\"measure\"] : \n",
    "                        conf.INPUT_RANGES[\"measure\"] + conf.INPUT_RANGES[\"beat\"]], \n",
    "                        output_type=tf.int32) == min_beat:\n",
    "                        min_position = song[idx,3]  # It has to be >= than the last position (if beat and measure are the same)\n",
    "                    else:\n",
    "                        min_position = tf.constant(0, dtype=tf.int32)\n",
    "                else:\n",
    "                    min_beat = tf.constant(0, dtype=tf.int32)\n",
    "                    min_position = tf.constant(0, dtype=tf.int32)\n",
    "                # Only some instruments, key signs, time signs and tempos are allowed for these events: \n",
    "                # - for instruments, the allowed ones are the ones that have been defined previously with type = 1\n",
    "                # - for the others, the allowed ones are the ones that are collected right before the note from event types 4, 5 and 6\n",
    "                allowed_instruments, _ = tf.unique(tf.gather(\n",
    "                    song[:idx, 6], \n",
    "                    tf.where(song[:idx, 0] == 1)[:,0]\n",
    "                ))\n",
    "                # We have made it so that the model should output 3s only after at least a 4, 5 and 6.\n",
    "                allowed_key_sign = tf.gather(\n",
    "                    song[:idx, 8], \n",
    "                    tf.where(song[:idx, 0] == 4)[:,0]   # if type == 4 --> read the LAST key_sign\n",
    "                )[-1] \n",
    "                allowed_time_sign = tf.gather(\n",
    "                    song[:idx, 9], \n",
    "                    tf.where(song[:idx, 0] == 5)[:,0]   # if type == 5 --> read the LAST time_sign\n",
    "                )[-1] \n",
    "                allowed_tempo = tf.gather(\n",
    "                    song[:idx, 10], \n",
    "                    tf.where(song[:idx, 0] == 6)[:,0]   # if type == 6 --> read the LAST tempo\n",
    "                )[-1] \n",
    "            elif chosen_type >= 4 and chosen_type <= 6:     # key_sign, time_sign, tempo\n",
    "                # If last event is at the beginning of a measure, you can add an event at the same time\n",
    "                if song[idx, 3] == 0 and song[idx, 2] == 0:  # if beat and position == 0, the event can be at this measure\n",
    "                    min_measure = song[idx, 1]\n",
    "                else:\n",
    "                    min_measure = song[idx, 1] + 1                   # otherwise it goes to the next measure\n",
    "                # Fine-grain checks\n",
    "                # Here, there are cases where there is not a LAST key_sign/time_sign (when this is the first 4, 5 or 6). \n",
    "                # In these cases we should use the default masks.\n",
    "                if chosen_type == 4:\n",
    "                    # Cannot put the same key_sign again\n",
    "                    forbidden_key_signs = tf.gather(\n",
    "                        song[:idx, 8], \n",
    "                        tf.where(song[:idx, 0] == 4)[:,0]) # if type == 4 --> read the LAST key_sign\n",
    "                    if tf.size(forbidden_key_signs) > 0:\n",
    "                        forbidden_key_sign = forbidden_key_signs[-1]\n",
    "                elif chosen_type == 5:\n",
    "                    # Cannot put the same time_sign again\n",
    "                    forbidden_time_signs = tf.gather(\n",
    "                        song[:idx, 9], \n",
    "                        tf.where(song[:idx, 0] == 5)[:,0]) # if type == 5 --> read the LAST time_sign\n",
    "                    if tf.size(forbidden_time_signs) > 0:\n",
    "                        forbidden_time_sign = forbidden_time_signs[-1]\n",
    "                elif chosen_type == 6:\n",
    "                    # Cannot put the same tempo again\n",
    "                    forbidden_tempos = tf.gather(\n",
    "                        song[:idx, 10], \n",
    "                        tf.where(song[:idx, 0] == 6)[:,0]) # if type == 6 --> read the LAST tempo\n",
    "                    if tf.size(forbidden_tempos) > 9:\n",
    "                        forbidden_tempo = forbidden_tempos[-1]\n",
    "            elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "\n",
    "            ## ENDING PART ##\n",
    "            # Put together the masks\n",
    "            if default_flag: \n",
    "                # No manual masking required, either \"can freely choose this part of the token\" (True) or \n",
    "                # \"can only choose default for this part of the token\" (False)\n",
    "                mask.write(idx, tf.concat(\n",
    "                    # Default mask only allows to predict a 0\n",
    "                    # Full mask allows to predict any value\n",
    "                    [self.default_mask[i] if default_token_parts[i] else self.full_mask[i] \n",
    "                        for i in range(len(default_token_parts))], axis=-1)\n",
    "                )\n",
    "            elif forbidden_instruments_flag:\n",
    "                # Default flag is False and forbidden instruments contains some elmeents (which means that the chosen type is 1)\n",
    "                instruments_mask = tf.sparse.SparseTensor(  # Forbidden instruments\n",
    "                        indices= tf.expand_dims(tf.cast(forbidden_instruments, tf.int64), axis=-1),\n",
    "                        values = tf.zeros_like(forbidden_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                instruments_mask = tf.cast(\n",
    "                    tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=1), \n",
    "                    dtype=tf.dtypes.bool)\n",
    "                # Only mask the forbidden instruments, all the rest is default\n",
    "                mask.write(idx, tf.concat(\n",
    "                    [self.default_mask[i] for i in range(5)] + \\\n",
    "                    [instruments_mask] + \\\n",
    "                    [self.default_mask[i] for i in range(6,len(default_token_parts))], \n",
    "                    axis=-1))\n",
    "            elif chosen_type >= 3 and chosen_type <= 6:\n",
    "                # General event. What we do depends on which specific event it is, but\n",
    "                # in general there is always a measure mask.\n",
    "                measure_mask = tf.cast(\n",
    "                    tf.concat([\n",
    "                        tf.repeat([False], min_measure),        # Can be equal to or greater than min_measure\n",
    "                        tf.repeat([True],  conf.INPUT_RANGES[\"measure\"]-min_measure)], \n",
    "                        axis=-1),\n",
    "                    dtype=tf.dtypes.bool)\n",
    "                # We need to do manual masking. Define all tensors\n",
    "                measure_mask     = self.default_mask[0]\n",
    "                beat_mask        = self.default_mask[1]\n",
    "                position_mask    = self.default_mask[2]\n",
    "                duration_mask    = self.default_mask[3]\n",
    "                pitch_mask       = self.default_mask[4]\n",
    "                instruments_mask = self.default_mask[5]\n",
    "                velocity_mask    = self.default_mask[6]\n",
    "                key_sign_mask    = self.default_mask[7]\n",
    "                time_sign_mask   = self.default_mask[8]\n",
    "                tempo_mask       = self.default_mask[9]\n",
    "                # Create more specific masks depending on the type\n",
    "                if chosen_type == 4:\n",
    "                    if forbidden_key_sign != -1: ## forbidden_key_sign can only appear if chosen_type = 4\n",
    "                        # True in all places but the forbidden key signs\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 5:\n",
    "                    if forbidden_time_sign != -1: ## forbidden_time_sign can only appear if chosen_type = 5\n",
    "                        # True in all places but the forbidden time signs\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 6:\n",
    "                    if forbidden_tempo != -1: ## forbidden_tempo can only appear if chosen_type = 6\n",
    "                        # True in all places but the forbidden tempos\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i != forbidden_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                elif chosen_type == 3:\n",
    "                    # If the event is a note, we have ALLOWED time signs/tempos/key signs, not\n",
    "                    # forbidden ones. Also, there are many other elements to take into account\n",
    "                    if min_beat != -1:\n",
    "                        # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                        max_beat = self.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                        # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                        beat_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_beat),\n",
    "                            tf.repeat([True],  max_beat-min_beat), \n",
    "                            tf.repeat([False], conf.INPUT_RANGES[\"beat\"]-max_beat)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    if min_position != -1:\n",
    "                        position_mask = tf.cast(tf.concat([\n",
    "                            tf.repeat([False], min_position), \n",
    "                            tf.repeat([True],  conf.INPUT_RANGES[\"position\"]-min_position)],\n",
    "                            axis=-1), \n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    instruments_mask = tf.sparse.SparseTensor( # Allowed instruments\n",
    "                        indices=tf.expand_dims(tf.cast(allowed_instruments, tf.int64), axis=-1),\n",
    "                        values=tf.ones_like(allowed_instruments),\n",
    "                        dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                    )\n",
    "                    instruments_mask = tf.cast(\n",
    "                        tf.sparse.to_dense(tf.sparse.reorder(instruments_mask), default_value=0),\n",
    "                        dtype=tf.dtypes.bool)\n",
    "                    if allowed_key_sign != -1:\n",
    "                        key_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_key_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"key_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_time_sign != -1:\n",
    "                        time_sign_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_time_sign \n",
    "                            for i in range(conf.INPUT_RANGES[\"time_sign\"])], \n",
    "                            dtype=tf.bool)\n",
    "                    if allowed_tempo != -1:\n",
    "                        tempo_mask = tf.convert_to_tensor([\n",
    "                            i == allowed_tempo \n",
    "                            for i in range(conf.INPUT_RANGES[\"tempo\"])], \n",
    "                            dtype=tf.bool)\n",
    "                # Write on the mask\n",
    "                mask.write(idx, tf.concat([\n",
    "                    measure_mask, beat_mask, position_mask, duration_mask,\n",
    "                    pitch_mask, instruments_mask, velocity_mask, key_sign_mask,\n",
    "                    time_sign_mask, tempo_mask], axis=-1))\n",
    "        # Return the whole mask\n",
    "        return mask.stack()\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        '''\n",
    "        Inputs:\n",
    "        - songs:                BATCH*(SEQ_LEN-1)*11\n",
    "        - out_logits:           BATCH*(SEQ_LEN-1)*1391 (all except type)\n",
    "        - types_probabilities:  BATCH*(SEQ_LEN-1)*8 --> becomes chosen_types through argmax --> BATCH*(SEQ_LEN-1)*1\n",
    "\n",
    "        passes through map_fn --> get_mask_fro_all_tokens to debatch\n",
    "        '''\n",
    "        songs, out_logits, types_probabilities = inputs\n",
    "        chosen_types  = tf.expand_dims(tf.math.argmax(types_probabilities[:,:-1], axis=2), axis=-1)# TODO: check if SEQ_LEN -1 or -2\n",
    "        concat_logits = tf.concat(out_logits[1:], axis=-1)                 # Concatenate all logits (except type) into a tensor batch_size x seq_len x 1391\n",
    "        masks = tf.map_fn(fn=self.get_mask_for_all_tokens, elems=(         # Iterate function over batch dimension \n",
    "                tf.cast(chosen_types, concat_logits.dtype),                # BATCH*(SEQ_LEN-1)*1\n",
    "                tf.cast(songs,   concat_logits.dtype),                     # BATCH*(SEQ_LEN-1)*11\n",
    "                concat_logits[:, :conf.SEQ_LEN-1, :]                       # BATCH*(SEQ_LEN-1)*1391 # TODO: check if SLICE is needed or we could directly pass the full concat_logits\n",
    "            ), fn_output_signature=tf.TensorSpec(                          # Total: a BATCH * SEQ_LEN-1 * 1403 tensor\n",
    "                (conf.SEQ_LEN-1, conf.input_ranges_sum - conf.INPUT_RANGES['type']),\n",
    "                dtype=tf.bool\n",
    "            ))\n",
    "        return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation function (to be called within a scope in case of MultiGPU training)\n",
    "def create_model(input_shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), num_genres=len(conf.accepted_subgenres), \n",
    "                 use_regularization=True, use_masking_layers=True, reg_loss_scale=conf.REG_LOSS_SCALE):\n",
    "    \n",
    "    # Get input shapes\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate transformer decoder (n_emb % n_head must be 0)\n",
    "    decoder = conf.get_decoder()\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs',  dtype=tf.int32)\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres', dtype=tf.float32)\n",
    "    \n",
    "    # Define loss\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "    reg_scaler = tf.constant(reg_loss_scale, dtype=tf.float32)\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['type'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='type_embeddings'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'],    conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='measure_embeddings'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'],       conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='beat_embeddings'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['position'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='position_embeddings'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='duration_embeddings'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='pitch_embeddings'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='instrument_embeddings'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='velocity_embeddings'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'],   conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='key_sign_embeddings'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'],  conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='time_sign_embeddings'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'],      conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='tempo_embeddings')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(conf.GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    input_concat_layer         = tf.keras.layers.Concatenate(axis=2)\n",
    "    sequence_concat_layer      = tf.keras.layers.Concatenate(axis=1)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(conf.TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = conf.get_positional_embedding_matrix()\n",
    "    positional_encoding        = tf.repeat(positional_encoding_matrix[tf.newaxis, :, :], tf.shape(songs)[0], axis=0)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['type'],       name='type_scores'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['measure'],    name='measure_scores'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['beat'],       name='beat_scores'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['position'],   name='position_scores'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['duration'],   name='duration_scores'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'],      name='pitch_scores'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], name='instrument_scores'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'],   name='velocity_scores'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'],   name='keysign_scores'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'],  name='timesign_scores'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'],      name='tempo_scores')\n",
    "    ]\n",
    "    \n",
    "    output_probs_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Softmax(name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Softmax(name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Softmax(name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Softmax(name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Softmax(name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Softmax(name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Softmax(name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Softmax(name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Softmax(name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Softmax(name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Softmax(name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Masking layers\n",
    "    if use_masking_layers:\n",
    "        type_masking_layer = MaskTypeProbabilitiesLayer()\n",
    "        activations_masking =  MaskingActivationLayer()\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    input_embedding   = input_concat_layer(embeddings)\n",
    "    input_embedding   = encoding_processing_layer(input_embedding)\n",
    "    input_embedding   = sequence_concat_layer([genre_embedding[:, np.newaxis, :], input_embedding])\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output)[:,:-1,:] for i in range(len(output_dense_layers))]\n",
    "    # We don't care about the last scores, since they refer to a token that's out of bounds.\n",
    "    if use_masking_layers:\n",
    "        type_mask           = type_masking_layer(songs, training=True)[:,:-1,:]\n",
    "        types_probabilities = output_probs_layers[0](out_scores[0], type_mask)\n",
    "        full_mask           = activations_masking([songs, out_scores, types_probabilities])\n",
    "        index = 0;    masks = []          # Unpack the final masks into a list of masks\n",
    "        for key in conf.INPUT_RANGES:\n",
    "            if key != 'type':\n",
    "                masks.append(full_mask[:, :, index:index+conf.INPUT_RANGES[key]])\n",
    "                index += conf.INPUT_RANGES[key]\n",
    "        out_probabilities = [types_probabilities] + [\n",
    "            output_probs_layers[i](out_scores[i], masks[i-1]) \n",
    "            for i in range(1, len(output_dense_layers))]\n",
    "    else:\n",
    "        out_probabilities = [output_probs_layers[i](out_scores[i]) for i in range(len(output_dense_layers))]\n",
    "\n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=[songs, genres], outputs=out_probabilities, name='music_generation_model')\n",
    "    \n",
    "    # Define loss\n",
    "    def custom_loss(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(len(conf.INPUT_RANGES))]\n",
    "        # Base loss term\n",
    "        losses = []\n",
    "        for i in range(len(y_pred)):\n",
    "            losses.append(tf.math.reduce_sum(\n",
    "                tf.cast(loss_function(gt_vectors[i], y_pred[i]), tf.float32) * \\\n",
    "                (1. / conf.GLOBAL_BATCH_SIZE)))\n",
    "        return tf.math.reduce_sum(losses)\n",
    "    \n",
    "    # Define regularizers\n",
    "    def custom_regularizers(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(len(conf.INPUT_RANGES))]\n",
    "        # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "        types = gt_vectors[0]\n",
    "        max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "        consecutive_gt_types   = subsequent_type_transform_layer(types)\n",
    "        consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "        # Compute difference\n",
    "        differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "        # Compute regularization terms\n",
    "        # Difference between one element's type and the next is >= 0\n",
    "        reg_term_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "        # Difference between one element's type and the next is < 1\n",
    "        reg_term_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))\n",
    "        return reg_scaler * tf.cast(reg_term_1, tf.float32) + reg_scaler * tf.cast(reg_term_2, tf.float32)\n",
    "    \n",
    "    # Add losses\n",
    "    model.add_loss(custom_loss(songs, out_scores))\n",
    "    if use_regularization:\n",
    "        model.add_loss(custom_regularizers(songs, out_scores))\n",
    "    \n",
    "    # Compile and return\n",
    "    model.compile(optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multiple GPUs with Mirrored Strategy\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_generation_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " songs (InputLayer)             [(None, 6143, 11)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " genres (InputLayer)            [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " type_embeddings (Embedding)    (None, 6143, 64)     512         ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " measure_embeddings (Embedding)  (None, 6143, 64)    16384       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " beat_embeddings (Embedding)    (None, 6143, 64)     8384        ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " position_embeddings (Embedding  (None, 6143, 64)    8192        ['tf.__operators__.getitem_4[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " duration_embeddings (Embedding  (None, 6143, 64)    8704        ['tf.__operators__.getitem_5[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " pitch_embeddings (Embedding)   (None, 6143, 64)     16384       ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " instrument_embeddings (Embeddi  (None, 6143, 64)    8256        ['tf.__operators__.getitem_7[0][0\n",
      " ng)                                                             ]']                              \n",
      "                                                                                                  \n",
      " velocity_embeddings (Embedding  (None, 6143, 64)    8192        ['tf.__operators__.getitem_8[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " key_sign_embeddings (Embedding  (None, 6143, 64)    1600        ['tf.__operators__.getitem_9[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " time_sign_embeddings (Embeddin  (None, 6143, 64)    9792        ['tf.__operators__.getitem_10[0][\n",
      " g)                                                              0]']                             \n",
      "                                                                                                  \n",
      " tempo_embeddings (Embedding)   (None, 6143, 64)     3136        ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " genre_embedding (Sequential)   (None, 512)          33536       ['genres[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6143, 704)    0           ['type_embeddings[0][0]',        \n",
      "                                                                  'measure_embeddings[0][0]',     \n",
      "                                                                  'beat_embeddings[0][0]',        \n",
      "                                                                  'position_embeddings[0][0]',    \n",
      "                                                                  'duration_embeddings[0][0]',    \n",
      "                                                                  'pitch_embeddings[0][0]',       \n",
      "                                                                  'instrument_embeddings[0][0]',  \n",
      "                                                                  'velocity_embeddings[0][0]',    \n",
      "                                                                  'key_sign_embeddings[0][0]',    \n",
      "                                                                  'time_sign_embeddings[0][0]',   \n",
      "                                                                  'tempo_embeddings[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['songs[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_12 (S  (None, 1, 512)      0           ['genre_embedding[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " encoding_processing (Dense)    (None, 6143, 512)    360960      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 6144, 512)    0           ['tf.__operators__.getitem_12[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'encoding_processing[0][0]']    \n",
      "                                                                                                  \n",
      " tf.repeat (TFOpLambda)         (None, 6144, 512)    0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " final_encoding (Add)           (None, 6144, 512)    0           ['concatenate_1[0][0]',          \n",
      "                                                                  'tf.repeat[0][0]']              \n",
      "                                                                                                  \n",
      " tfgpt2_model (TFGPT2Model)     TFBaseModelOutputWi  22061056    ['final_encoding[0][0]']         \n",
      "                                thPastAndCrossAtten                                               \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(None, 6144, 5                                               \n",
      "                                12),                                                              \n",
      "                                 past_key_values=((                                               \n",
      "                                2, None, 2, 6144, 2                                               \n",
      "                                56),                                                              \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256)),                                                           \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None,                                                \n",
      "                                cross_attentions=No                                               \n",
      "                                ne)                                                               \n",
      "                                                                                                  \n",
      " type_scores (Dense)            (None, 6144, 8)      4104        ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " mask_type_probabilities_layer   (None, 6144, 8)     0           ['songs[0][0]']                  \n",
      " (MaskTypeProbabilitiesLayer)                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_13 (S  (None, 6143, 8)     0           ['type_scores[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_24 (S  (None, 6143, 8)     0           ['mask_type_probabilities_layer[0\n",
      " licingOpLambda)                                                 ][0]']                           \n",
      "                                                                                                  \n",
      " measure_scores (Dense)         (None, 6144, 256)    131328      ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " beat_scores (Dense)            (None, 6144, 131)    67203       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " position_scores (Dense)        (None, 6144, 128)    65664       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " duration_scores (Dense)        (None, 6144, 136)    69768       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " pitch_scores (Dense)           (None, 6144, 256)    131328      ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " instrument_scores (Dense)      (None, 6144, 129)    66177       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " velocity_scores (Dense)        (None, 6144, 128)    65664       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " keysign_scores (Dense)         (None, 6144, 25)     12825       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " timesign_scores (Dense)        (None, 6144, 153)    78489       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " tempo_scores (Dense)           (None, 6144, 49)     25137       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " type_probabilities (Softmax)   (None, 6143, 8)      0           ['tf.__operators__.getitem_13[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_24[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_14 (S  (None, 6143, 256)   0           ['measure_scores[0][0]']         \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_15 (S  (None, 6143, 131)   0           ['beat_scores[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_16 (S  (None, 6143, 128)   0           ['position_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_17 (S  (None, 6143, 136)   0           ['duration_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_18 (S  (None, 6143, 256)   0           ['pitch_scores[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_19 (S  (None, 6143, 129)   0           ['instrument_scores[0][0]']      \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_20 (S  (None, 6143, 128)   0           ['velocity_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_21 (S  (None, 6143, 25)    0           ['keysign_scores[0][0]']         \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_22 (S  (None, 6143, 153)   0           ['timesign_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_23 (S  (None, 6143, 49)    0           ['tempo_scores[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " masking_activation_layer (Mask  (None, 6143, 1391)  0           ['songs[0][0]',                  \n",
      " ingActivationLayer)                                              'tf.__operators__.getitem_13[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_14[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_15[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_16[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_17[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_20[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_21[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_22[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_23[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'type_probabilities[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_25 (S  (None, 6143, 256)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_26 (S  (None, 6143, 131)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_27 (S  (None, 6143, 128)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_28 (S  (None, 6143, 136)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_29 (S  (None, 6143, 256)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_30 (S  (None, 6143, 129)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_31 (S  (None, 6143, 128)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_32 (S  (None, 6143, 25)    0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_33 (S  (None, 6143, 153)   0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_34 (S  (None, 6143, 49)    0           ['masking_activation_layer[0][0]'\n",
      " licingOpLambda)                                                 ]                                \n",
      "                                                                                                  \n",
      " measure_probabilities (Softmax  (None, 6143, 256)   0           ['tf.__operators__.getitem_14[0][\n",
      " )                                                               0]',                             \n",
      "                                                                  'tf.__operators__.getitem_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " beat_probabilities (Softmax)   (None, 6143, 131)    0           ['tf.__operators__.getitem_15[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_26[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " position_probabilities (Softma  (None, 6143, 128)   0           ['tf.__operators__.getitem_16[0][\n",
      " x)                                                              0]',                             \n",
      "                                                                  'tf.__operators__.getitem_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " duration_probabilities (Softma  (None, 6143, 136)   0           ['tf.__operators__.getitem_17[0][\n",
      " x)                                                              0]',                             \n",
      "                                                                  'tf.__operators__.getitem_28[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " pitch_probabilities (Softmax)  (None, 6143, 256)    0           ['tf.__operators__.getitem_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " instrument_probabilities (Soft  (None, 6143, 129)   0           ['tf.__operators__.getitem_19[0][\n",
      " max)                                                            0]',                             \n",
      "                                                                  'tf.__operators__.getitem_30[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " velocity_probabilities (Softma  (None, 6143, 128)   0           ['tf.__operators__.getitem_20[0][\n",
      " x)                                                              0]',                             \n",
      "                                                                  'tf.__operators__.getitem_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " keysign_probabilities (Softmax  (None, 6143, 25)    0           ['tf.__operators__.getitem_21[0][\n",
      " )                                                               0]',                             \n",
      "                                                                  'tf.__operators__.getitem_32[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " timesign_probabilities (Softma  (None, 6143, 153)   0           ['tf.__operators__.getitem_22[0][\n",
      " x)                                                              0]',                             \n",
      "                                                                  'tf.__operators__.getitem_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tempo_probabilities (Softmax)  (None, 6143, 49)     0           ['tf.__operators__.getitem_23[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_34[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_35 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_36 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_37 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_38 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_39 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_40 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_41 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_42 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_43 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_44 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_45 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_35[0][\n",
      " rical_crossentropy (TFOpLambda                                  0]',                             \n",
      " )                                                                'tf.__operators__.getitem_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_36[0][\n",
      " rical_crossentropy_1 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_37[0][\n",
      " rical_crossentropy_2 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_38[0][\n",
      " rical_crossentropy_3 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_16[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_39[0][\n",
      " rical_crossentropy_4 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_40[0][\n",
      " rical_crossentropy_5 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_18[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_41[0][\n",
      " rical_crossentropy_6 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_42[0][\n",
      " rical_crossentropy_7 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_20[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_43[0][\n",
      " rical_crossentropy_8 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_21[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_44[0][\n",
      " rical_crossentropy_9 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_22[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_45[0][\n",
      " rical_crossentropy_10 (TFOpLam                                  0]',                             \n",
      " bda)                                                             'tf.__operators__.getitem_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 6143)         0           ['tf.keras.backend.sparse_categor\n",
      "                                                                 ical_crossentropy[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_4[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_6[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_7[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_8[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_9[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_10[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_5 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_7 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_6[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_9 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_11 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_13 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_15 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_17 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_16[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_19 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_18[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_21 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_20[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 6143)        0           ['tf.cast_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 6143)        0           ['tf.cast_3[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 6143)        0           ['tf.cast_5[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 6143)        0           ['tf.cast_7[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 6143)        0           ['tf.cast_9[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 6143)        0           ['tf.cast_11[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 6143)        0           ['tf.cast_13[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 6143)        0           ['tf.cast_15[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 6143)        0           ['tf.cast_17[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 6143)        0           ['tf.cast_19[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None, 6143)        0           ['tf.cast_21[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  ()                  0           ['tf.math.multiply_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  ()                  0           ['tf.math.multiply_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  ()                  0           ['tf.math.multiply_5[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  ()                  0           ['tf.math.multiply_7[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_4 (TFOpLamb  ()                  0           ['tf.math.multiply_9[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOpLamb  ()                  0           ['tf.math.multiply_11[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_6 (TFOpLamb  ()                  0           ['tf.math.multiply_13[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_7 (TFOpLamb  ()                  0           ['tf.math.multiply_15[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOpLamb  ()                  0           ['tf.math.multiply_17[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_9 (TFOpLamb  ()                  0           ['tf.math.multiply_19[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_10 (TFOpLam  ()                  0           ['tf.math.multiply_21[0][0]']    \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_11 (TFOpLam  ()                  0           ['tf.math.reduce_sum[0][0]',     \n",
      " bda)                                                             'tf.math.reduce_sum_1[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_2[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_3[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_4[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_5[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_6[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_7[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_8[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_9[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_10[0][0]']  \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_sum_11[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.argmax (TFOpLambda)    (None, 6143)         0           ['tf.__operators__.getitem_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " subsequent_type_transformation  (None, 6143)        0           ['tf.math.argmax[0][0]']         \n",
      " _layer (SubsequentTypeTransfor                                                                   \n",
      " mationLayer)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_57 (S  (None, 6142)        0           ['subsequent_type_transformation_\n",
      " licingOpLambda)                                                 layer[1][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_58 (S  (None, 6142)        0           ['subsequent_type_transformation_\n",
      " licingOpLambda)                                                 layer[1][0]']                    \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 6142)         0           ['tf.__operators__.getitem_57[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_58[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.maximum_1 (TFOpLambda)  (None, 6142)        0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None, 6142)         0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 6142)        0           ['tf.math.maximum_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   (None, 6142)         0           ['tf.math.negative[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.maximum_2 (TFOpLambda)  (None, 6142)        0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_12 (TFOpLam  ()                  0           ['tf.math.maximum[0][0]']        \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_13 (TFOpLam  ()                  0           ['tf.math.maximum_2[0][0]']      \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.cast_22 (TFOpLambda)        ()                   0           ['tf.math.reduce_sum_12[0][0]']  \n",
      "                                                                                                  \n",
      " tf.cast_23 (TFOpLambda)        ()                   0           ['tf.math.reduce_sum_13[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpLambd  ()                  0           ['tf.cast_22[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpLambd  ()                  0           ['tf.cast_23[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.multiply_22[0][0]',    \n",
      " da)                                                              'tf.math.multiply_23[0][0]']    \n",
      "                                                                                                  \n",
      " add_loss_1 (AddLoss)           ()                   0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,262,775\n",
      "Trainable params: 23,262,775\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.GLOBAL_BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 03:33:30.144708: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([12, 6143, 8]), TensorShape([12, 6143, 256]), TensorShape([12, 6143, 131]), TensorShape([12, 6143, 128]), TensorShape([12, 6143, 136]), TensorShape([12, 6143, 256]), TensorShape([12, 6143, 129]), TensorShape([12, 6143, 128]), TensorShape([12, 6143, 25]), TensorShape([12, 6143, 153]), TensorShape([12, 6143, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model([X, y])\n",
    "print([x.shape for x in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=656649.5>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=7.8700004>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: There is something weird with the multi-GPU loss. I bet I have to divide for the global batch size or something."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
