{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 23:35:36.226295: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 23:35:36.331713: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-27 23:35:36.766350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/volpepe/miniconda3/envs/music_gen/lib/:/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-27 23:35:36.766439: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/volpepe/miniconda3/envs/music_gen/lib/:/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-04-27 23:35:36.766445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-27 23:35:38.149062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.167152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.167305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 23:35:38.237196: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-27 23:35:38.237925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.238078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.238192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.615400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.615564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.615687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-27 23:35:38.615785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5743 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "import config, music_model, utils\n",
    "\n",
    "### CONFIGURATION ###\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'lmd_matched_final_2048_cut'\n",
    "WEIGHTS_PATH = os.path.join(ROOT_PATH, 'training', 'checkpoints', 'model_GPT_baseline_with_mse_vellmd_matched_2048', 'model_GPT_baseline_with_mse_vellmd_matched_2048')\n",
    "\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "USE_ONE_GPU = True\n",
    "\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1\n",
    "\n",
    "### MODEL CREATION ###\n",
    "\n",
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf,\n",
    "                                         num_genres=len(conf.accepted_subgenres),\n",
    "                                         use_regularization=False,\n",
    "                                         use_masking_layers=False)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf,\n",
    "                                     num_genres=len(conf.accepted_subgenres),\n",
    "                                     use_regularization=False,\n",
    "                                     use_masking_layers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fe0215e6d70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Function to choose a style for the song\n",
    "def encode_styles(styles_array):\n",
    "    one_hot_enc = np.zeros((len(styles_array), len(conf.accepted_subgenres)), dtype=np.int8)\n",
    "    for i, style in enumerate(styles_array):\n",
    "        one_hot_enc[i, conf.accepted_subgenres.index(style)] = 1\n",
    "    return one_hot_enc\n",
    "\n",
    "# Example:\n",
    "styles = encode_styles(['rock', 'pop', 'dance', 'electronic'])\n",
    "print(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "# transformer = model.get_layer('tfgpt2_model')\n",
    "# output_layers = [\n",
    "#     model.get_layer('type_scores'),\n",
    "#     model.get_layer('measure_scores'),\n",
    "#     model.get_layer('beat_scores'),\n",
    "#     model.get_layer('position_scores'),\n",
    "#     model.get_layer('duration_scores'),\n",
    "#     model.get_layer('pitch_scores'),\n",
    "#     model.get_layer('instrument_scores'),\n",
    "#     model.get_layer('velocity_values'),\n",
    "#     model.get_layer('keysign_scores'),\n",
    "#     model.get_layer('timesign_scores'),\n",
    "#     model.get_layer('tempo_scores')\n",
    "# ]\n",
    "# activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "\n",
    "# ## Test this pipeline\n",
    "# # Let's assume we need to only send the first 2 token.\n",
    "# # Therefore we will build an attention mask where only the first 2 values are 1 and the others are 0\n",
    "# CUR_IDX = 2\n",
    "# GEN_BATCH_SIZE = 4\n",
    "# attention_mask = np.ones((GEN_BATCH_SIZE, 1+CUR_IDX), dtype=np.int8)\n",
    "# padding_attention_mask = np.zeros((GEN_BATCH_SIZE, conf.SEQ_LEN-1-CUR_IDX), dtype=np.int8)\n",
    "# attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "# preprocessed_tensors = preprocessing_model(X)\n",
    "# out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "#                                    attention_mask=attention_mask)['last_hidden_state']\n",
    "# out_scores           = [output_layers[i](out_transformer)[:,:-1,:] \n",
    "#                         for i in range(len(output_layers))]\n",
    "# out_probs            = [np.array(activations[i](out_scores[i])) \n",
    "#                         for i in range(len(activations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the token components\n",
    "# generation_mode = 'top_p_sampling'\n",
    "\n",
    "# if generation_mode == 'top_p_sampling':\n",
    "#     # Compute the dynamic top-p thresholds\n",
    "#     top_p_sequence = np.linspace(0.9, 0.6, conf.SEQ_LEN-1)  # Generate max_length-1 evenly spaced values\n",
    "\n",
    "# token_components = []\n",
    "# for head_idx in range(len(out_probs)):\n",
    "#     # Velocity is just a number, not a probability distribution\n",
    "#     if head_idx == 7: token_components.append(\n",
    "#         np.asarray(out_probs[7][:, CUR_IDX, :], dtype=np.int32))\n",
    "#     else:\n",
    "#     # Sample the next token from the output probabilities using the desired sampling mode\n",
    "\n",
    "#         ## 1. Top-k sampling: sample from the top-k most probable tokens.\n",
    "#         ## k is expressed as a ratio of the number of possibilities, because each component has different ranges.\n",
    "#         if generation_mode == 'top_k_sampling':\n",
    "#             k = int(out_probs[head_idx].shape[-1] * 0.3)\n",
    "#             top_k_indices = np.argsort(-np.asarray(out_probs[head_idx][:, CUR_IDX, :]))[:, :k]\n",
    "#             for song in range(GEN_BATCH_SIZE):\n",
    "#                 redistrib_mass = sum(np.take(out_probs[head_idx][song, CUR_IDX, :], top_k_indices[song]))\n",
    "#                 # redistrib_mass : 1 = prob[i] : x --> x = prob[i] / redistrib_mass\n",
    "#                 for idx in range(out_probs[head_idx].shape[-1]):\n",
    "#                     out_probs[head_idx][song, CUR_IDX, idx] = \\\n",
    "#                         (out_probs[head_idx][song, CUR_IDX, idx] / redistrib_mass) if idx in top_k_indices[song] else 0\n",
    "\n",
    "#         ## 2. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "#         elif generation_mode == 'top_p_sampling':\n",
    "#             best_indices = np.argsort(-np.asarray(out_probs[head_idx][:, CUR_IDX, :]))\n",
    "#             for song in range(GEN_BATCH_SIZE):\n",
    "#                 # Take elements until the cumulative probability exceeds the threshold (always at least one element)\n",
    "#                 cum_prob = 0; k = 0\n",
    "#                 while cum_prob < top_p_sequence[CUR_IDX]:\n",
    "#                     cum_prob += out_probs[head_idx][song, CUR_IDX, best_indices[song, k]]\n",
    "#                     k += 1\n",
    "#                 # Directly modify the probability array\n",
    "#                 # cum_prob : 1 = prob[i] : x --> x = prob[i] / cum_prob\n",
    "#                 # For the other elements, the probability is 0\n",
    "#                 for idx in range(out_probs[head_idx].shape[-1]):\n",
    "#                     out_probs[head_idx][song, CUR_IDX, idx] = \\\n",
    "#                         (out_probs[head_idx][song, CUR_IDX, idx] / cum_prob) if idx in best_indices[song, :k] else 0\n",
    "        \n",
    "#         ## 3. Standard mapping: simply sample from the probability distributions with no additional frills.\n",
    "#         batch = [[np.random.choice(\n",
    "#             np.arange(out_probs[head_idx].shape[-1]),\n",
    "#             p=out_probs[head_idx][song, CUR_IDX, :]\n",
    "#             )] for song in range(GEN_BATCH_SIZE)]\n",
    "#         token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "\n",
    "# # Create the tokens concatenating the sampled components\n",
    "# new_tokens = np.concatenate(token_components, axis=1)\n",
    "# new_tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_current_token(song, current_token_idx, current_token_probabilities, current_settings):\n",
    "    mask_from_previous_token = conf.full_mask.copy() # TODO: initiate with np.ones with right dimensions (excluding the token type, see)\n",
    "    mask_from_current_token = conf.full_mask.copy()\n",
    "\n",
    "    previous_token = song[current_token_idx-1, :]\n",
    "\n",
    "    if previous_token[0] == 0: # only type 1 is acceptable\n",
    "        mask_from_previous_token[0][0] = 0\n",
    "        mask_from_previous_token[0][2:] = 0\n",
    "    elif previous_token[0] == 1: # only type 1 and 2 are acceptable\n",
    "        mask_from_previous_token[0][0] = 0\n",
    "        mask_from_previous_token[0][3:] = 0\n",
    "    elif previous_token[0] == 2: # only type 4 is acceptable\n",
    "        mask_from_previous_token[0][0:4] = 0\n",
    "        mask_from_previous_token[0][5:] = 0\n",
    "    elif previous_token[0] == 3: # only type 3-4-5-6-7 are acceptable\n",
    "        mask_from_previous_token[0][0:3] = 0\n",
    "    elif previous_token[0] == 4: # cannot write type 0-1-2\n",
    "        mask_from_previous_token[0][0:3] = 0\n",
    "        if np.sum(song[:,0] == 5) == 0: # if no time_sign has been defined, you must define it\n",
    "            mask_from_previous_token[0][3:5] = 0\n",
    "            mask_from_previous_token[0][6:] = 0\n",
    "        else:\n",
    "            pass\n",
    "    elif previous_token[0] == 5: # cannot write type 0-1-2\n",
    "        mask_from_previous_token[0][0:3] = 0\n",
    "        if np.sum(song[:,0] == 6) == 0: # if no tempo has been defined, you must define it\n",
    "                mask_from_previous_token[0][3:6] = 0\n",
    "                mask_from_previous_token[0][7] = 0\n",
    "        else:\n",
    "            pass\n",
    "    elif previous_token[0] == 6: # cannot write type 0-1-2\n",
    "        mask_from_previous_token[0][0:3] = 0\n",
    "    elif previous_token[0] == 7:\n",
    "        mask_from_previous_token[0][0:7] = 0\n",
    "\n",
    "\n",
    "    # TODO: now with this mask you sample the token type for the current token\n",
    "    current_token_type = 0 # TODO: this is just a filler\n",
    "\n",
    "    if current_token_type == 0:\n",
    "        mask_from_current_token = conf.default_mask.copy() # only index zero on the other parts of the token\n",
    "    elif current_token_type == 1:\n",
    "        mask_from_current_token = conf.default_mask.copy()[:5] + conf.full_mask.copy()[5] + conf.default_mask.copy()[6:] # only index zero on the other (except instruments)\n",
    "    elif current_token_type == 2:\n",
    "        mask_from_current_token = conf.default_mask.copy() # only index zero on the other parts of the token\n",
    "    elif current_token_type == 3:\n",
    "\n",
    "        # mask for measure / beat / position\n",
    "\n",
    "        # mask for key_sign / time_sign / tempo\n",
    "        pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Song generation function\n",
    "def generate_songs(model, style_list:List[str], max_length:int=conf.SEQ_LEN-1, \n",
    "                   terminator_type:int=7, generation_mode:str='standard_sampling', \n",
    "                   temperature:float=1.0, top_k_ratio=0.3, top_p_start:float=0.9, \n",
    "                   top_p_min=0.9):\n",
    "    \n",
    "    # Check the validity of the parameters\n",
    "    assert temperature > 0, \"Temperature must be greater than 0\"\n",
    "    assert max_length <= conf.SEQ_LEN-1, f\"The maximum length of the generated song must be less than {conf.SEQ_LEN-1}\"\n",
    "    assert generation_mode in ['standard_sampling', 'top_k_sampling', 'top_p_sampling'], \\\n",
    "        f\"Parameter 'generation_mode' must be one of the following: 'standard_sampling', 'top_k_sampling', 'top_p_sampling'\"\n",
    "\n",
    "    # Collect explicitly the number of songs to generate\n",
    "    num_songs = len(style_list)\n",
    "\n",
    "    # Separate preprocessing model, transformer and output layers in order to be able to\n",
    "    # inject the attention masks into the transformer and still use the loaded weights\n",
    "    preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "    transformer = model.get_layer('tfgpt2_model')\n",
    "    output_layers = [\n",
    "        model.get_layer('type_scores'), model.get_layer('measure_scores'), model.get_layer('beat_scores'),\n",
    "        model.get_layer('position_scores'), model.get_layer('duration_scores'), model.get_layer('pitch_scores'),\n",
    "        model.get_layer('instrument_scores'), model.get_layer('velocity_values'), model.get_layer('keysign_scores'),\n",
    "        model.get_layer('timesign_scores'), model.get_layer('tempo_scores')\n",
    "    ]\n",
    "    activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "    \n",
    "    # Create the empty song array.\n",
    "    # The first token of the songs is always the start token (0,...,0)\n",
    "    # The rest of the tensor is filled with padding of zeroes, which will be masked by the attention masks\n",
    "    generated_songs = np.zeros((num_songs, conf.SEQ_LEN-1, 11), dtype=np.int32)\n",
    "\n",
    "    if generation_mode == 'top_p_sampling':\n",
    "        # Compute the dynamic top-p thresholds\n",
    "        top_p_sequence = np.linspace(top_p_start, top_p_min, max_length-1)  # Generate max_length-1 evenly spaced values\n",
    "    \n",
    "    # Generate the one-hot encodings of the genres\n",
    "    styles = encode_styles(style_list)\n",
    "\n",
    "    # Start to generate the songs token by token\n",
    "    for i in trange(1, max_length):\n",
    "\n",
    "        # Create the attention mask (the first 2 tokens are always attended: genre and starting token)\n",
    "        attention_mask = np.ones((num_songs, 1+i), dtype=np.int8)\n",
    "        padding_attention_mask = np.zeros((num_songs, conf.SEQ_LEN-1-i), dtype=np.int8)\n",
    "        attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "        # Preprocess the songs and pass them through the transformer\n",
    "        preprocessed_tensors = preprocessing_model((generated_songs, styles))\n",
    "        out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                               attention_mask=attention_mask)['last_hidden_state']\n",
    "        # Use the output layers to generate the probabilities for the next token\n",
    "        # Output from transformer has SEQ_LEN tokens, so we trim it by removing the last one,\n",
    "        # since it's the probability of a token that's out of our bounds.\n",
    "        out_scores           = [output_layers[i](out_transformer)[:,:-1,:]\n",
    "                                for i in range(len(output_layers))]\n",
    "        # Apply temperature to the scores but mind the velocity scores which is a scalar\n",
    "        out_scores_tempered  = [out_scores[i] / temperature for i in range(7)] + \\\n",
    "            [out_scores[7]]  + [out_scores[i] / temperature for i in range(8, 11)]\n",
    "        out_probs            = [np.array(activations[i](out_scores_tempered[i]))\n",
    "                                for i in range(len(activations))]\n",
    "        \n",
    "        # Used for compliance with song representation\n",
    "\n",
    "        \n",
    "        # Create the token components\n",
    "        token_components = []\n",
    "        for head_idx in range(len(out_probs)):\n",
    "            # Velocity is just a number, not a probability distribution\n",
    "            if head_idx == 7: token_components.append(\n",
    "                    np.asarray(out_probs[7][:, i, :] * conf.INPUT_RANGES['velocity'], dtype=np.int32))\n",
    "            else:\n",
    "                # Sample the next token from the output probabilities using the desired sampling mode\n",
    "                if generation_mode != 'standard_sampling':\n",
    "                    # Use some method to modify the probabilities, such as top-k or top-p sampling\n",
    "\n",
    "                    ## 1. Top-k sampling: sample from the top-k most probable tokens.\n",
    "                    ## k is expressed as a ratio of the number of possibilities, because each component has different ranges.\n",
    "                    if generation_mode == 'top_k_sampling':\n",
    "                        # Compute the top-k indices in the probability array\n",
    "                        k = np.ceil(out_probs[head_idx].shape[-1] * top_k_ratio)\n",
    "                        top_k_indices = np.argsort(-np.asarray(out_probs[head_idx][:, i, :]))[:, :k]\n",
    "                        for song in range(num_songs):\n",
    "                            # For each song, compute the mass of probability to be redistributed between the top-k elements\n",
    "                            redistrib_mass = sum(np.take(out_probs[head_idx][song, i, :], top_k_indices[song]))\n",
    "                            # Directly modify the probability array \n",
    "                            # redistrib_mass : 1 = prob[i] : x --> x = prob[i] / redistrib_mass\n",
    "                            # For the non-top-k elements, the probability is 0\n",
    "                            for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                                out_probs[head_idx][song, i, idx] = \\\n",
    "                                    (out_probs[head_idx][song, i, idx] / redistrib_mass) if idx in top_k_indices[song] else 0\n",
    "\n",
    "                    ## 2. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "                    elif generation_mode == 'top_p_sampling':\n",
    "                        best_indices = np.argsort(-np.asarray(out_probs[head_idx][:, i, :]))\n",
    "                        for song in range(num_songs):\n",
    "                            # Take elements until the cumulative probability exceeds the threshold (always at least one element)\n",
    "                            cum_prob = 0; k = 0\n",
    "                            while cum_prob < top_p_sequence[i-1]:\n",
    "                                cum_prob += out_probs[head_idx][song, i, best_indices[song, k]]\n",
    "                                k += 1\n",
    "                            # Directly modify the probability array\n",
    "                            # cum_prob : 1 = prob[i] : x --> x = prob[i] / cum_prob\n",
    "                            # For the other elements, the probability is 0\n",
    "                            for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                                out_probs[head_idx][song, i, idx] = \\\n",
    "                                    (out_probs[head_idx][song, i, idx] / cum_prob) if idx in best_indices[song, :k] else 0\n",
    "                \n",
    "                ## Use standard mapping to sample from the (potentially modified) probability distributions\n",
    "                batch = [[np.random.choice(\n",
    "                    np.arange(out_probs[head_idx].shape[-1]),\n",
    "                    p=out_probs[head_idx][song, i, :]\n",
    "                    )] for song in range(num_songs)]\n",
    "                token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "                \n",
    "        # Create the tokens concatenating the sampled components\n",
    "        new_tokens = np.concatenate(token_components, axis=1)\n",
    "        # Add the new tokens to the songs\n",
    "        generated_songs[:, i] = new_tokens\n",
    "\n",
    "    # If a token in a song has type of terminator, simply overwrite the rest of the song with end tokens\n",
    "    for song in range(num_songs):\n",
    "        terminator_indices = np.argwhere(generated_songs[song, :, 0] == terminator_type)\n",
    "        if len(terminator_indices) > 0:\n",
    "            first_terminator_index = terminator_indices[0,0]\n",
    "            generated_songs[song, first_terminator_index:, :] = [7] + [0]*10\n",
    "        \n",
    "    # Internally, the generated song is always SEQ_LEN - 1 long, so we cut it before returning it.\n",
    "    return generated_songs[:, :max_length, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rock songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2046 [00:00<?, ?it/s]2023-04-27 23:35:43.830282: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████| 2046/2046 [04:33<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pop songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:34<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dance songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:37<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating country songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:37<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating metal songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:36<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classical songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:23<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating folk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:23<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating blues songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:23<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating house songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:23<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating indie songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:39<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating latin songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:39<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating jazz songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:52<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating funk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:38<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rap songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:31<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating punk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:32<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating r&b songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:31<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating gospel songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:22<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating electronic songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:23<00:00,  7.77it/s]\n"
     ]
    }
   ],
   "source": [
    "for genre in conf.accepted_subgenres:\n",
    "    print(f\"Generating {genre} songs...\")\n",
    "    out_songs = generate_songs(model, [genre]*4, max_length=2047, temperature=0.9, \n",
    "                            generation_mode='top_p_sampling', top_p_start=0.9, top_p_min=0.6)\n",
    "    np.save(os.path.join(conf.DATA_PATH, 'generated_songs', 'repr', f'songs_{genre}.npy'), out_songs, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ed98097e12b2e5cb24acca5eaecb045ae6fa1f3d168a26bde2bb15ec97be77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
