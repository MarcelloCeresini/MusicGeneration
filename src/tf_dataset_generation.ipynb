{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelloceresini/miniconda/envs/env-MusicGeneration/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import muspy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import config\n",
    "import utils\n",
    "\n",
    "config_string = \"single_instruments_type\"\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "conf = config.Config(config_string, ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115190"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(conf.dataset_paths[\"lmd_matched\"], \"lakh_matched_genre_vectors.pickle\"), \"rb\") as f:\n",
    "    genre_vectors = pickle.load(f)\n",
    "\n",
    "dataset = utils.get_dataset(\"lmd_matched\", conf)\n",
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study to choose final length of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Long dataset matched: : 69031it [43:55, 22.51it/s] "
     ]
    }
   ],
   "source": [
    "study_lengths = False\n",
    "\n",
    "lengths = np.zeros(10000000)\n",
    "\n",
    "discarded_samples = {\n",
    "    0:0, # empty song\n",
    "    1:0, # time_signatures not all acceptable\n",
    "    2:0, # n_measures too big\n",
    "    3:0, # too many notes\n",
    "    4:0, # no genre\n",
    "}\n",
    "\n",
    "if study_lengths:\n",
    "\n",
    "    for song, genre in (pbar := tqdm(zip(dataset, genre_vectors), total=len(dataset))):\n",
    "        pbar.set_description(\"Long dataset matched\")\n",
    "        if type(genre) == type(None):\n",
    "            discarded_samples[4] += 1\n",
    "\n",
    "        else:\n",
    "            converted_song = utils.transform_representation(song, conf)\n",
    "\n",
    "            lengths[len(converted_song)] += 1\n",
    "\n",
    "            if len(converted_song) <= 1:\n",
    "                discarded_samples[converted_song[0]] += 1\n",
    "else:\n",
    "    lengths[10] = 1 # to avoid errors in the cells below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "for i in range(len(lengths)):\n",
    "    if lengths[i]>0:\n",
    "        max = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = lengths[:max+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(lengths)), lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_len=1024\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))\n",
    "chosen_len=2048 \n",
    "chosen_len -= 2\n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))\n",
    "chosen_len=2048 + 1024\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))\n",
    "chosen_len=2048 + 2048\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighed_lenghts = lengths.astype(np.int64)*np.arange(len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_len=1024\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))\n",
    "chosen_len=2048\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))\n",
    "chosen_len=2048 + 1024\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))\n",
    "chosen_len=2048 + 2048\n",
    "chosen_len -= 2\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n",
      "[1, 2, 0, 0]\n",
      "[1, 2, 3, 0]\n",
      "[1, 2, 3, 0]\n",
      "[1, 2, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "a = [[1],\n",
    "     [1, 2],\n",
    "     [1, 2, 3],\n",
    "     [1, 2, 3, 4], \n",
    "     [1, 2, 3, 4, 5]]\n",
    "\n",
    "chosen_len = 5\n",
    "# devono uscire lunghezza 4 alla fine\n",
    "chosen_len-=2\n",
    "\n",
    "for l in a:\n",
    "    if len(l) >= chosen_len:\n",
    "        print(l[:chosen_len]+[0])\n",
    "    else:\n",
    "        print(l+[0]*(chosen_len-len(l)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Long dataset matched:   0%|          | 10/115190 [00:00<2:16:42, 14.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_tf_dataset(dataset, genre_vectors, chosen_len, cut_songs):\n",
    "\n",
    "    chosen_len -= 2\n",
    "\n",
    "    samples = []\n",
    "    genres = []\n",
    "    labels = {key:[] for key in conf.INPUT_RANGES.keys()}\n",
    "\n",
    "    discarded_samples = {\n",
    "        0:0, # empty song\n",
    "        1:0, # time_signatures not all acceptable\n",
    "        2:0, # n_measures too big\n",
    "        3:0, # too many notes\n",
    "        4:0, # no genre\n",
    "    }\n",
    "\n",
    "    for song, genre in (pbar := tqdm(zip(dataset, genre_vectors), total=len(dataset))):\n",
    "        pbar.set_description(\"Long dataset matched\")\n",
    "\n",
    "        bool_accepted = False\n",
    "\n",
    "        if type(genre) == type(None):\n",
    "            discarded_samples[4] += 1\n",
    "\n",
    "        else:\n",
    "            converted_song = utils.transform_representation(song, conf)\n",
    "\n",
    "            if len(converted_song) <= 1:\n",
    "                discarded_samples[converted_song[0]] += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                if len(converted_song) >= chosen_len:\n",
    "                    if cut_songs:\n",
    "                        padding = tf.cast([[7]+[0]*10], dtype=np.uint8) # only add the final token to be sure that the song ends\n",
    "                        bool_accepted = True\n",
    "                    else:\n",
    "                        discarded_samples[3] += 1\n",
    "                    \n",
    "                else:\n",
    "                    padding = tf.cast(np.stack([[7]+[0]*10]*(chosen_len-len(converted_song)+1), axis=0), dtype=np.uint8)\n",
    "                    bool_accepted = True\n",
    "\n",
    "        \n",
    "        if bool_accepted:\n",
    "            sample = np.concatenate((\n",
    "                    converted_song[:chosen_len], # also works for songs shorter than chosen_len\n",
    "                    tf.identity(padding)\n",
    "                ), dtype=np.uint8\n",
    "            )\n",
    "\n",
    "            samples.append(sample)\n",
    "            genres.append(genre)\n",
    "\n",
    "            for i, key in enumerate(labels.keys()):\n",
    "                labels[key].append(sample[:,i])\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices(((samples, genres), labels)), discarded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset, discarded_samples = create_tf_dataset(dataset, genre_vectors, chosen_len=4096, cut_songs=True)\n",
    "tf_dataset.save(conf.dataset_paths[\"lmd_matched_final_4096_cut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset, discarded_samples = create_tf_dataset(dataset, genre_vectors, chosen_len=2048, cut_songs=True)\n",
    "tf_dataset.save(conf.dataset_paths[\"lmd_matched_final_2048_cut\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_discarded = sum(discarded_samples.values())\n",
    "print(\"Kept {}% of the songs\".format(((len(dataset)-tot_discarded))/len(dataset)*100))\n",
    "print(\"Of the discarded: \")\n",
    "print(\"- {:.2f}% were empty\".format(discarded_samples[0]/tot_discarded*100))\n",
    "print(\"- {:.2f}% contained not accepted time signatures\".format(discarded_samples[1]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had too many measures\".format(discarded_samples[2]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had too many events/notes\".format(discarded_samples[3]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had no accepted genre\".format(discarded_samples[4]/tot_discarded*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-MusicGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
