{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 21:22:56.216183: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 21:22:56.922193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2022-11-23 21:22:56.922238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64:/usr/local/cuda-11.6/lib64\n",
      "2022-11-23 21:22:56.922244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-23 21:22:57.554932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:57.584034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:57.584221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "/home/marcello/github/MusicGeneration/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-23 21:22:58.178400: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-23 21:22:58.179477: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.179658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.179774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.590933: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.591103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.591227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-23 21:22:58.591339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3624 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# from transformers import GPT2Config, TFGPT2Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "  except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "import utils\n",
    "import config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.load(conf.lmda_genres_tf_data_path)   \\\n",
    "dataset = tf.data.Dataset.load(conf.tf_data_path)   \\\n",
    "    .shuffle(conf.SHUFFLE_SIZE)                                 \\\n",
    "    .batch(conf.BATCH_SIZE)                                     \\\n",
    "    .prefetch(conf.PREFETCH_SIZE)                               \\\n",
    "    .cache()                                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024, 512)\n",
      "(2, 1024, 8)\n",
      "(2, 1024, 256)\n",
      "(2, 1024, 131)\n",
      "(2, 1024, 128)\n",
      "(2, 1024, 136)\n",
      "(2, 1024, 256)\n",
      "(2, 1024, 129)\n",
      "(2, 1024, 128)\n",
      "(2, 1024, 25)\n",
      "(2, 1024, 153)\n",
      "(2, 1024, 49)\n",
      "song_shape: (2, 1023, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 21:22:59.428969: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "decoder_output = tf.random.uniform((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM), minval=-1, maxval=1)\n",
    "\n",
    "print(decoder_output.shape)\n",
    "\n",
    "out_logits = [layer(decoder_output) for layer in conf.output_dense_layers]\n",
    "\n",
    "for out_logit_part in out_logits:\n",
    "    print(out_logit_part.shape)\n",
    "\n",
    "for song, _ in dataset.take(1):\n",
    "    pass\n",
    "\n",
    "song= tf.slice(song, begin=[0, 0, 0], size = [-1,conf.SEQ_LEN-1,-1])\n",
    "\n",
    "print(\"song_shape: {}\".format(song.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskingActivationLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, conf: config.Config, trainable=True, name=None, dtype=None, dynamic=False, **kwargs):\n",
    "        super().__init__(trainable, name, dtype, dynamic, **kwargs)\n",
    "        \n",
    "        self.conf = conf\n",
    "\n",
    "        self.full_mask = conf.full_mask\n",
    "        self.default_mask = conf.default_mask\n",
    "\n",
    "        self.masked_activations = [tf.keras.layers.Softmax()]*len(conf.INPUT_RANGES)\n",
    "    \n",
    "        output_scores_dim = conf.SEQ_LEN-1\n",
    "        vectors = [[1]*(i+1) + [0]*(output_scores_dim-i-1) for i in range(output_scores_dim)]\n",
    "        self.triang_mask = tf.cast(tf.repeat(tf.expand_dims(np.asarray(np.stack(vectors)), axis=-1), repeats=[11], axis=-1), dtype=tf.dtypes.float32)\n",
    "\n",
    "    \n",
    "    def softargmax(x, beta=1e10):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float64)\n",
    "        x_range = tf.range(x.shape.as_list()[-1], dtype=x.dtype)\n",
    "        return tf.reduce_sum(tf.nn.softmax(x*beta) * x_range, axis=-1)\n",
    "\n",
    "    \n",
    "    def create_manual_mask(up_to, size):\n",
    "        \n",
    "        return \n",
    "\n",
    "\n",
    "    def get_mask(self, inputs):\n",
    "\n",
    "        chosen_type, song, scores, index_tensor = inputs\n",
    "    \n",
    "        chosen_type = tf.cast(chosen_type, dtype=tf.dtypes.int64)               # 1\n",
    "        song = tf.cast(song, dtype=tf.dtypes.int64)                             # (SEQ_LEN-1) * 11\n",
    "        scores = tf.cast(scores, dtype=tf.dtypes.int64)                         # (SEQ_LEN-1)\n",
    "        index_tensor = tf.squeeze(tf.cast(index_tensor, dtype=tf.dtypes.int64)) # 1\n",
    "\n",
    "        default_token_parts = [True, True, True, True, True, True, True, True, True, True, True]\n",
    "        default_flag = False\n",
    "\n",
    "        # DEFAULT CREATION (tensorflow requires the variable to be present in all possible branches when if/else are present)\n",
    "        min_measure =           tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        min_beat =              tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        min_position =          tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        note = False\n",
    "        allowed_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.dtypes.int64)\n",
    "        allowed_key_sign =      tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        allowed_time_sign =     tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        allowed_tempo =         tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        forbidden_instruments = tf.constant([0]*conf.INPUT_RANGES[\"instrument\"], dtype=tf.dtypes.int64)\n",
    "        forbidden_key_sign =    tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        forbidden_time_sign =   tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "        forbidden_tempo =       tf.constant(-1, dtype=tf.dtypes.int64)\n",
    "\n",
    "        forbidden_instruments_flag = False\n",
    "        \n",
    "        if chosen_type == 0: # TODO: change to 7 # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "            # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "            default_token_parts = [False, True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "\n",
    "        # instrument selection\n",
    "        elif chosen_type == 1: # false only for type and instrument type (the ones that you can choose)\n",
    "            if tf.cast(tf.gather_nd(song, indices=[[index_tensor,0]]), tf.dtypes.int64) == 0:\n",
    "                # first instrument chosen\n",
    "                default_token_parts = [False, True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "                \n",
    "            else:\n",
    "                # from second instrument chosen onwards this is right\n",
    "                forbidden_instruments, _ = tf.unique(tf.gather(\n",
    "                        tf.squeeze(tf.slice(song, begin=[0,6], size=[-1,1]), axis=-1), \n",
    "                        tf.squeeze(tf.where(tf.squeeze(tf.slice(song, begin=[0,0], size=[-1,1])) == 2))\n",
    "                ), out_idx=tf.dtypes.int64)\n",
    "\n",
    "                forbidden_instruments_flag = True\n",
    "            \n",
    "        \n",
    "        # start of events\n",
    "        elif chosen_type == 2: # false only for type (cannot choose anything in \"start of events\" token)\n",
    "            default_token_parts = [False, True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "        \n",
    "        # notes\n",
    "        elif chosen_type == 3: # note: has same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "            \n",
    "            min_measure = tf.cast(tf.gather_nd(song, indices=[[index_tensor,1]]), tf.dtypes.int64)   # it has to be >= than the last measure\n",
    "\n",
    "            # if in the MEASURE SCORES the MAX SCORE between all possible measures >= min_measure is the one == to min_measure\n",
    "            # it means that the model will choose the same measure as last event --> we need to make sure that beat >= last_beat\n",
    "            if tf.math.argmax(tf.slice(\n",
    "                    scores, \n",
    "                    begin=conf.INPUT_RANGES[\"type\"] + min_measure, \n",
    "                    size=conf.INPUT_RANGES[\"measure\"]-min_measure\n",
    "                )) == min_measure:\n",
    "                \n",
    "                min_beat = tf.squeeze(tf.cast(tf.gather_nd(song, indices=[[index_tensor,2]]), tf.dtypes.int64), axis=0)      # it has to be >= than the last beat (if measure is the same)\n",
    "\n",
    "                if tf.math.argmax(tf.slice(\n",
    "                        scores, \n",
    "                        begin=[conf.INPUT_RANGES[\"type\"]+conf.INPUT_RANGES[\"measure\"]+min_beat], \n",
    "                        size=[conf.INPUT_RANGES[\"beat\"]-min_beat]\n",
    "                    )) == min_beat:\n",
    "\n",
    "                    min_position = tf.squeeze(tf.cast(tf.gather_nd(song, indices=[[index_tensor,3]]), tf.dtypes.int64), axis=0)  # it has to be >= than the last position (if beat and measure are the same)\n",
    "                else:\n",
    "                    min_position = tf.constant(0, dtype=tf.dtypes.int64)\n",
    "            else:\n",
    "                min_beat = tf.constant(0, dtype=tf.dtypes.int64)\n",
    "                min_position = tf.constant(0, dtype=tf.dtypes.int64)\n",
    "            \n",
    "            note = True\n",
    "\n",
    "            # complicated but --> gather the values of token_part 6 corresponding to the token indices where token_part == 2 (+ unique for no repetition)\n",
    "\n",
    "            allowed_instruments, _ = tf.unique(tf.gather(\n",
    "                    tf.squeeze(tf.slice(song, begin=[0,6], size=[-1,1]), axis=-1), \n",
    "                    tf.squeeze(tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 2))\n",
    "            ), out_idx=tf.dtypes.int64)\n",
    "\n",
    "            allowed_key_sign = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,8], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 4)[-1] # if type == 4 --> read the LAST key_sign\n",
    "            ), dtype=tf.dtypes.int64)\n",
    "            allowed_time_sign = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,9], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 5)[-1] # if type == 5 --> read the LAST time_sign\n",
    "            ), dtype=tf.dtypes.int64)\n",
    "            allowed_tempo = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,10], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 6)[-1] # if type == 6 --> read the LAST tempo\n",
    "            ), dtype=tf.dtypes.int64)\n",
    "        \n",
    "        # key_sign, time_sign, tempo\n",
    "        elif chosen_type >= 4 and chosen_type <= 6:\n",
    "\n",
    "            # if last event is at the beginning of a measure, you can add an event at the same time\n",
    "            if tf.gather_nd(song, indices=[[index_tensor,3]]) == 0 and tf.gather_nd(song, indices=[[index_tensor,2]]) == 0:  # if beat and position == 0, can be this measure\n",
    "                min_measure = tf.squeeze(tf.cast(tf.gather_nd(song, indices=[[index_tensor,1]])   , tf.dtypes.int64), axis=0)\n",
    "            # otherwise it goes to the next measure\n",
    "            else:\n",
    "                min_measure = tf.squeeze(tf.cast(tf.gather_nd(song, indices=[[index_tensor,1]]) +1, tf.dtypes.int64), axis=0)\n",
    "            \n",
    "            if chosen_type == 4:\n",
    "                \n",
    "                forbidden_key_sign = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,8], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 4)[-1] # if type == 4 --> read the LAST key_sign\n",
    "                ), dtype=tf.dtypes.int64) # cannot put the same key_sign again\n",
    "\n",
    "            elif chosen_type == 5:\n",
    "\n",
    "                forbidden_time_sign = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,9], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 5)[-1] # if type == 5 --> read the LAST time_sign\n",
    "                ), dtype=tf.dtypes.int64) # cannot put the same time_sign again\n",
    "            \n",
    "            elif chosen_type == 6:\n",
    "\n",
    "                forbidden_tempo = tf.cast(tf.gather(\n",
    "                    tf.slice(song, begin=[0,10], size=[-1,1]), \n",
    "                    tf.where(tf.slice(song, begin=[0,0], size=[-1,1]) == 6)[-1] # if type == 6 --> read the LAST tempo\n",
    "                ), dtype=tf.dtypes.int64) # cannot put the same tempo again\n",
    "            \n",
    "            else:\n",
    "                # cannot RAISE inside tf graph, because it WILL pass from every path\n",
    "                default_token_parts = [True, True, True, True, True, True, True, True, True, True, True]\n",
    "                default_flag = True\n",
    "                # raise ValueError(\"Impossible that chosen type isn't in [4,6] inside here --> {}\".format(chosen_type))\n",
    "\n",
    "        elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "            default_token_parts = [False, True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "\n",
    "        else:\n",
    "            default_token_parts = [True, True, True, True, True, True, True, True, True, True, True]\n",
    "            default_flag = True\n",
    "            # raise ValueError(\"Impossible that chosen type isn't in [1,7] --> {}\".format(chosen_type))\n",
    "\n",
    "        measure_mask =      self.default_mask[1]\n",
    "        beat_mask =         self.default_mask[2]\n",
    "        position_mask =     self.default_mask[3]\n",
    "        duration_mask =     self.default_mask[4]\n",
    "        pitch_mask =        self.default_mask[5]\n",
    "        instruments_mask =  self.default_mask[6]\n",
    "        velocity_mask =     self.default_mask[7]\n",
    "        key_sign_mask =     self.default_mask[8]\n",
    "        time_sign_mask =    self.default_mask[9]\n",
    "        tempo_mask =        self.default_mask[10]\n",
    "\n",
    "            \n",
    "        if default_flag: # no manual masking, either \"can freely choose this part of the token\" or \"can only choose default for this part of the token\"\n",
    "\n",
    "            return tf.cast(tf.concat(\n",
    "                        [self.default_mask[i] if default_token_parts[i] else self.full_mask[i] for i in range(len(default_token_parts))],\n",
    "                        axis=-1\n",
    "                    ), dtype=tf.dtypes.float32)\n",
    "        \n",
    "        else: # manual masking\n",
    "\n",
    "            if not forbidden_instruments_flag:\n",
    "                # measure mask, beat and position go to default if type==2 and forbidden_instruments_flag == True\n",
    "                # so if forbidden_instruments_flag == False --> you can change it\n",
    "                measure_mask = tf.convert_to_tensor([[False]*min_measure + [True]*(conf.INPUT_RANGES[\"measure\"]-min_measure)], dtype=tf.dtypes.bool)\n",
    "\n",
    "                if min_beat != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                    # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                    max_beat = conf.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                    \n",
    "                    # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                    beat_mask = tf.convert_to_tensor([\n",
    "                        [False]*min_beat + \\\n",
    "                        [True]*(max_beat-min_beat) + \\\n",
    "                        [False]*(conf.INPUT_RANGES[\"beat\"]-max_beat)\n",
    "                    ], dtype=tf.dtypes.bool)\n",
    "\n",
    "                if min_position != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                    position_mask = tf.convert_to_tensor([[False]*min_position + [True]*(conf.INPUT_RANGES[\"position\"]-min_position)], dtype=tf.dtypes.bool)\n",
    "\n",
    "            else:\n",
    "                instruments_mask = tf.sparse.SparseTensor(#forbidden\n",
    "                    indices=tf.expand_dims(forbidden_instruments,axis=-1),\n",
    "                    values=tf.squeeze(tf.zeros_like(forbidden_instruments)),\n",
    "                    dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                )\n",
    "\n",
    "                instruments_mask = tf.cast(tf.sparse.to_dense(instruments_mask, default_value=1), dtype=tf.dtypes.bool)\n",
    "                # FORBIDDEN INSTRUMENTS is ONLY USED WHEN type==1 --> measure_mask, beat, position are all default\n",
    "\n",
    "            if chosen_type==3:\n",
    "\n",
    "                duration_mask = self.full_mask[4]\n",
    "                pitch_mask = self.full_mask[5]\n",
    "                velocity_mask = self.full_mask[7]\n",
    "\n",
    "                instruments_mask = tf.sparse.SparseTensor(#allowed\n",
    "                    indices=tf.stack([\n",
    "                        allowed_instruments,\n",
    "                        tf.zeros_like(allowed_instruments)\n",
    "                    ]),\n",
    "                    values=tf.ones_like(allowed_instruments),\n",
    "                    dense_shape=[conf.INPUT_RANGES[\"instrument\"]]\n",
    "                )\n",
    "\n",
    "                instruments_mask = tf.cast(tf.sparse.to_dense(instruments_mask, default_value=0), dtype=tf.dtypes.bool)\n",
    "\n",
    "                \n",
    "            if allowed_key_sign != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                key_sign_mask = tf.convert_to_tensor([[True if i == allowed_key_sign else False for i in range(conf.INPUT_RANGES[\"key_sign\"])]], dtype=tf.dtypes.bool)\n",
    "            else:\n",
    "                if forbidden_key_sign != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                    key_sign_mask = tf.convert_to_tensor([[False if i == forbidden_key_sign else True for i in range(conf.INPUT_RANGES[\"key_sign\"])]], dtype=tf.dtypes.bool)\n",
    "                else:\n",
    "                    pass\n",
    "                    # raise AssertionError(\"Cannot have both allowed and forbidden key_sign not instanciated\")\n",
    "\n",
    "            if allowed_time_sign != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                time_sign_mask = tf.convert_to_tensor([[True if i == allowed_time_sign else False for i in range(conf.INPUT_RANGES[\"time_sign\"])]], dtype=tf.dtypes.bool)\n",
    "            else:\n",
    "                if forbidden_time_sign != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                    time_sign_mask = tf.convert_to_tensor([[False if i == forbidden_time_sign else True for i in range(conf.INPUT_RANGES[\"time_sign\"])]], dtype=tf.dtypes.bool)\n",
    "                else:\n",
    "                    pass\n",
    "                    # raise AssertionError(\"Cannot have both allowed and forbidden time_sign not instanciated\")\n",
    "\n",
    "            if allowed_tempo != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                tempo_mask = tf.convert_to_tensor([[True if i == allowed_tempo else False for i in range(conf.INPUT_RANGES[\"tempo\"])]], dtype=tf.dtypes.bool)\n",
    "            else:\n",
    "                if forbidden_tempo != tf.constant(-1, dtype=tf.dtypes.int64):\n",
    "                    tempo_mask = tf.convert_to_tensor([[False if i == forbidden_tempo else True for i in range(conf.INPUT_RANGES[\"tempo\"])]], dtype=tf.dtypes.bool)\n",
    "                else:\n",
    "                    pass\n",
    "                    # raise AssertionError(\"Cannot have both allowed and forbidden tempo not instanciated\")\n",
    "\n",
    "            return tf.cast(tf.expand_dims(tf.concat([\n",
    "                tf.squeeze(self.full_mask[0]), # type is not masked\n",
    "                tf.squeeze(measure_mask),\n",
    "                tf.squeeze(beat_mask),\n",
    "                tf.squeeze(position_mask),\n",
    "                tf.squeeze(duration_mask),\n",
    "                tf.squeeze(pitch_mask),\n",
    "                tf.squeeze(instruments_mask),\n",
    "                tf.squeeze(velocity_mask),\n",
    "                tf.squeeze(key_sign_mask),\n",
    "                tf.squeeze(time_sign_mask),\n",
    "                tf.squeeze(tempo_mask)\n",
    "            ], axis=-1), axis=0), dtype=tf.dtypes.float32)\n",
    "            \n",
    "\n",
    "    def get_mask_for_all_tokens(self, inputs): \n",
    "\n",
    "        '''\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "\n",
    "        inputs are for a SINGLE ELEMENT OF A BATCH of size SEQ_LEN*(1+11+1399) where 1399 is the summed length of logits\n",
    "        '''\n",
    "        # defaults (tf graph needs them with if/elses)\n",
    "\n",
    "        chosen_type_each_token = tf.cast(tf.squeeze(tf.slice(inputs, begin=[0,0], size=[-1,1]), axis=-1), dtype=tf.dtypes.int64)\n",
    "        song = tf.cast(tf.slice(inputs, begin=[0,1], size=[-1,11]), dtype=tf.dtypes.float32)\n",
    "        scores = tf.slice(inputs, begin=[0,1+11], size=[-1,-1])\n",
    "\n",
    "        # result = 6143 matrices --> first one has only first token full (others are 0), second one has first two tokens full (others are 0) etc\n",
    "        triang_song = tf.math.multiply(\n",
    "            tf.repeat(tf.expand_dims(song, axis=0), repeats=[conf.SEQ_LEN-1], axis=0),\n",
    "            self.triang_mask\n",
    "        )\n",
    "\n",
    "        index_tensor = tf.expand_dims(tf.constant([i for i in range(conf.SEQ_LEN-1)], dtype=tf.dtypes.int64), axis=-1)\n",
    "        \n",
    "        # TODO: to speedup we could change it to vectorized_map, but we need to try it out\n",
    "        # map_fn is stupid and wants float32 (i think) both in input and output\n",
    "        final_masks = tf.map_fn(\n",
    "            fn=self.get_mask, \n",
    "            elems=(\n",
    "                tf.cast(chosen_type_each_token, dtype=tf.dtypes.float32),   # (SEQ_LEN-1)*1                 --> 1\n",
    "                triang_song,                                                # (SEQ_LEN-1)*(SEQ_LEN-1)*11    --> (SEQ_LEN-1)*11\n",
    "                scores,                                                     # (SEQ_LEN-1)*1399              --> 1399\n",
    "                tf.cast(index_tensor, dtype=tf.dtypes.float32)              # (SEQ_LEN-1)*1                 --> 1\n",
    "            ), \n",
    "            fn_output_signature=tf.dtypes.float32\n",
    "        ) # TODO: change it accordingly to the output signature\n",
    "\n",
    "        return final_masks\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, song, out_logits:list):\n",
    "        '''\n",
    "        Takes as input:\n",
    "            - out_logits: the scores outputted by the decoder + dense layers\n",
    "            - song: the input song, token by token\n",
    "\n",
    "        This function, based on the chosen token \"type\" given by the first dense layer,\n",
    "        masks all the different parts of the token accordingly, also taking into consideration\n",
    "        the previous tokens of the song\n",
    "\n",
    "        Output:\n",
    "            - probabilities for each different part of the predicted token (the following one in the song)\n",
    "        \n",
    "        '''\n",
    "        concat_logits = tf.concat(out_logits, axis = -1)\n",
    "\n",
    "        max_type = tf.math.reduce_max(song[:,0])\n",
    "\n",
    "        # do not have to be tensors because loos shouldn't flow through them\n",
    "        if max_type == 0: # only start of song token\n",
    "            # cannot be anything else than instrument choice (1)\n",
    "            type_mask = np.asarray([False, True, False, False, False, False, False, False], dtype=bool)\n",
    "        elif max_type == 1: # we reached instrument choice\n",
    "            # cannot be anything else than instrument choice (1) or start of events (2)\n",
    "            type_mask = np.asarray([False, True, True, False, False, False, False, False], dtype=bool)\n",
    "        elif max_type >= 2 and max_type < 7: # we reached start of events or notes\n",
    "            type_mask = np.asarray([False, False, False, True, True, True, True, True], dtype=bool)\n",
    "\n",
    "        elif max_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change to zero\n",
    "            type_mask = np.asarray([True, False, False, False, False, False, False, False], dtype=bool)\n",
    "\n",
    "        else:\n",
    "            type_mask = np.asarray([False, False, False, False, False, False, False, False], dtype=bool)\n",
    "            # raise ValueError(\"Impossible that max_type is not in [0,7]: {}\".format(max_type))\n",
    "\n",
    "        type_scores = self.masked_activations[0](out_logits[0], type_mask) # the first masked activation is for the type\n",
    "        \n",
    "        # needs to be differentiable (but the masks shouldn't need to be)\n",
    "        # chosen_type = self.softargmax(type_scores)\n",
    "        chosen_type = tf.expand_dims(tf.math.argmax(type_scores, axis=-1, output_type=tf.dtypes.uint16)[:,1:], axis=-1)\n",
    "\n",
    "        # could change == i with x<i+eps and x>i-eps because it's softargmax and not argmax\n",
    "\n",
    "        # map_fn always unpacks axis=0      \n",
    "        # TODO: COULD TUPLE INSTEAD OF CONCAT  \n",
    "        masks = tf.map_fn(self.get_mask_for_all_tokens, tf.concat([\n",
    "                tf.cast(chosen_type, tf.dtypes.float32),                # BATCH*(SEQ_LEN-1)\n",
    "                tf.cast(song, tf.dtypes.float32),                       # BATCH*(SEQ_LEN-1)*11\n",
    "                tf.slice(concat_logits, begin=[0,0,0], size=[-1,conf.SEQ_LEN-1,-1]) # BATCH*(SEQ_LEN-1)*1399\n",
    "            ], axis = -1))\n",
    "\n",
    "        return masks\n",
    "        return [masked_act(type_logit, type_mask) for masked_act, type_logit, type_mask in zip(self.masked_activations, out_logits, mask)]\n",
    "\n",
    "\n",
    "# do a simple model with \"out_logits\" dimension in input and see only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"masking_activation_layer_41\" (type MaskingActivationLayer).\n\nin user code:\n\n    File \"/tmp/ipykernel_113789/2581647075.py\", line 374, in call  *\n        masks = tf.map_fn(self.get_mask_for_all_tokens, tf.concat([\n    File \"/tmp/ipykernel_113789/2015448542.py\", line 313, in get_mask_for_all_tokens  *\n        final_masks = tf.map_fn(\n    File \"/tmp/ipykernel_113789/3558827725.py\", line 71, in get_mask  *\n        forbidden_instruments, _ = tf.unique(tf.gather_nd(\n\n    ValueError: Shape must be rank 1 but is rank 3 for '{{node masking_activation_layer_41/map/while/map/while/cond/cond/cond/Unique}} = Unique[T=DT_INT64, out_idx=DT_INT64](masking_activation_layer_41/map/while/map/while/cond/cond/cond/GatherNd)' with input shapes: [1,2,11].\n\n\nCall arguments received by layer \"masking_activation_layer_41\" (type MaskingActivationLayer):\n  • song=tf.Tensor(shape=(2, 1023, 11), dtype=uint8)\n  • out_logits=['tf.Tensor(shape=(2, 1024, 8), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 131), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 136), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 129), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 25), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 153), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 49), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [103], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m song_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(tensor\u001b[39m=\u001b[39msong)\n\u001b[1;32m      2\u001b[0m out_logits_input \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(tensor\u001b[39m=\u001b[39mout_logit_part) \u001b[39mfor\u001b[39;00m out_logit_part \u001b[39min\u001b[39;00m out_logits]\n\u001b[0;32m----> 4\u001b[0m y \u001b[39m=\u001b[39m MaskingActivationLayer(conf)(song_input, out_logits_input)\n\u001b[1;32m      6\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel([song_input, out_logits_input], y)\n",
      "File \u001b[0;32m~/github/MusicGeneration/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filerg_8b5zh.py:80\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, song, out_logits)\u001b[0m\n\u001b[1;32m     78\u001b[0m type_scores \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mmasked_activations[\u001b[39m0\u001b[39m], (ag__\u001b[39m.\u001b[39mld(out_logits)[\u001b[39m0\u001b[39m], ag__\u001b[39m.\u001b[39mld(type_mask)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     79\u001b[0m chosen_type \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39margmax, (ag__\u001b[39m.\u001b[39mld(type_scores),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), output_type\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39muint16), fscope)[:, \u001b[39m1\u001b[39m:],), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)), fscope)\n\u001b[0;32m---> 80\u001b[0m masks \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmap_fn, (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mget_mask_for_all_tokens, ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mconcat, ([ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(chosen_type), ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat32), \u001b[39mNone\u001b[39;00m, fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(song), ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat32), \u001b[39mNone\u001b[39;00m, fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mslice, (ag__\u001b[39m.\u001b[39mld(concat_logits),), \u001b[39mdict\u001b[39m(begin\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m], size\u001b[39m=\u001b[39m[(\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), (ag__\u001b[39m.\u001b[39mld(conf)\u001b[39m.\u001b[39mSEQ_LEN \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), (\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)]), fscope)],), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)), fscope)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     81\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filempkahcw_.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_mask_for_all_tokens\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     14\u001b[0m triang_song \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mmultiply, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mrepeat, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mld(song),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), fscope),), \u001b[39mdict\u001b[39m(repeats\u001b[39m=\u001b[39m[(ag__\u001b[39m.\u001b[39mld(conf)\u001b[39m.\u001b[39mSEQ_LEN \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), fscope), ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtriang_mask), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     15\u001b[0m index_tensor \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mexpand_dims, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mconstant, ([ag__\u001b[39m.\u001b[39mld(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mrange\u001b[39m), ((ag__\u001b[39m.\u001b[39mld(conf)\u001b[39m.\u001b[39mSEQ_LEN \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)],), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mint64), fscope),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)), fscope)\n\u001b[0;32m---> 16\u001b[0m final_masks \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mmap_fn, (), \u001b[39mdict\u001b[39m(fn\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mget_mask, elems\u001b[39m=\u001b[39m(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(chosen_type_each_token),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat32), fscope), ag__\u001b[39m.\u001b[39mld(triang_song), ag__\u001b[39m.\u001b[39mld(scores), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mcast, (ag__\u001b[39m.\u001b[39mld(index_tensor),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat32), fscope)), fn_output_signature\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39mfloat32), fscope)\n\u001b[1;32m     17\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileutjbaadp.py:246\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_mask\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     ag__\u001b[39m.\u001b[39mif_stmt((ag__\u001b[39m.\u001b[39mld(chosen_type) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m), if_body_11, else_body_11, get_state_11, set_state_11, (\u001b[39m'\u001b[39m\u001b[39mallowed_instruments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_flag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_token_parts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_instruments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_instruments_flag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_beat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_measure\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_position\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m14\u001b[39m)\n\u001b[1;32m    245\u001b[0m _ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 246\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt((ag__\u001b[39m.\u001b[39mld(chosen_type) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m), if_body_12, else_body_12, get_state_12, set_state_12, (\u001b[39m'\u001b[39m\u001b[39mallowed_instruments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_flag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_token_parts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_instruments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_instruments_flag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_beat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_measure\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_position\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m14\u001b[39m)\n\u001b[1;32m    247\u001b[0m measure_mask \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdefault_mask[\u001b[39m1\u001b[39m]\n\u001b[1;32m    248\u001b[0m beat_mask \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mdefault_mask[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileutjbaadp.py:244\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_mask.<locals>.else_body_12\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     ag__\u001b[39m.\u001b[39mif_stmt((ag__\u001b[39m.\u001b[39mld(chosen_type) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m), if_body_10, else_body_10, get_state_10, set_state_10, (\u001b[39m'\u001b[39m\u001b[39mallowed_instruments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mallowed_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_flag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault_token_parts\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_key_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_tempo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mforbidden_time_sign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_beat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_measure\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin_position\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m12\u001b[39m)\n\u001b[1;32m    243\u001b[0m _ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 244\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt((ag__\u001b[39m.\u001b[39;49mld(chosen_type) \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m), if_body_11, else_body_11, get_state_11, set_state_11, (\u001b[39m'\u001b[39;49m\u001b[39mallowed_instruments\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mallowed_key_sign\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mallowed_tempo\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mallowed_time_sign\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdefault_flag\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdefault_token_parts\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_instruments\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_instruments_flag\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_key_sign\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_tempo\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_time_sign\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmin_beat\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmin_measure\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmin_position\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m14\u001b[39;49m)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileutjbaadp.py:73\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_mask.<locals>.else_body_12.<locals>.if_body_11\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     forbidden_instruments_flag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     72\u001b[0m _ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt((ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mcast, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mgather_nd, (ag__\u001b[39m.\u001b[39;49mld(song),), \u001b[39mdict\u001b[39;49m(indices\u001b[39m=\u001b[39;49m[[ag__\u001b[39m.\u001b[39;49mld(index_tensor), \u001b[39m0\u001b[39;49m]]), fscope), ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mint64), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39;49m\u001b[39mdefault_flag\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdefault_token_parts\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_instruments\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mforbidden_instruments_flag\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m4\u001b[39;49m)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileutjbaadp.py:70\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__get_mask.<locals>.else_body_12.<locals>.if_body_11.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39melse_body\u001b[39m():\n\u001b[1;32m     69\u001b[0m     \u001b[39mnonlocal\u001b[39;00m default_token_parts, default_flag, forbidden_instruments_flag, forbidden_instruments\n\u001b[0;32m---> 70\u001b[0m     (forbidden_instruments, _) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49munique, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mgather_nd, (ag__\u001b[39m.\u001b[39;49mld(song),), \u001b[39mdict\u001b[39;49m(indices\u001b[39m=\u001b[39;49m[[ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49msqueeze, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mwhere, ((ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49msqueeze, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mslice, (ag__\u001b[39m.\u001b[39;49mld(song),), \u001b[39mdict\u001b[39;49m(begin\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], size\u001b[39m=\u001b[39;49m[(\u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m1\u001b[39;49m]), fscope),), \u001b[39mNone\u001b[39;49;00m, fscope) \u001b[39m==\u001b[39;49m \u001b[39m2\u001b[39;49m),), \u001b[39mNone\u001b[39;49;00m, fscope),), \u001b[39mNone\u001b[39;49;00m, fscope), ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mexpand_dims, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mconstant, (\u001b[39m6\u001b[39;49m,), \u001b[39mdict\u001b[39;49m(dtype\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mint64), fscope),), \u001b[39mdict\u001b[39;49m(axis\u001b[39m=\u001b[39;49m(\u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m)), fscope)]]), fscope),), \u001b[39mdict\u001b[39;49m(out_idx\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mint64), fscope)\n\u001b[1;32m     71\u001b[0m     forbidden_instruments_flag \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"masking_activation_layer_41\" (type MaskingActivationLayer).\n\nin user code:\n\n    File \"/tmp/ipykernel_113789/2581647075.py\", line 374, in call  *\n        masks = tf.map_fn(self.get_mask_for_all_tokens, tf.concat([\n    File \"/tmp/ipykernel_113789/2015448542.py\", line 313, in get_mask_for_all_tokens  *\n        final_masks = tf.map_fn(\n    File \"/tmp/ipykernel_113789/3558827725.py\", line 71, in get_mask  *\n        forbidden_instruments, _ = tf.unique(tf.gather_nd(\n\n    ValueError: Shape must be rank 1 but is rank 3 for '{{node masking_activation_layer_41/map/while/map/while/cond/cond/cond/Unique}} = Unique[T=DT_INT64, out_idx=DT_INT64](masking_activation_layer_41/map/while/map/while/cond/cond/cond/GatherNd)' with input shapes: [1,2,11].\n\n\nCall arguments received by layer \"masking_activation_layer_41\" (type MaskingActivationLayer):\n  • song=tf.Tensor(shape=(2, 1023, 11), dtype=uint8)\n  • out_logits=['tf.Tensor(shape=(2, 1024, 8), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 131), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 136), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 129), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 25), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 153), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 49), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "song_input = tf.keras.layers.Input(tensor=song)\n",
    "out_logits_input = [tf.keras.layers.Input(tensor=out_logit_part) for out_logit_part in out_logits]\n",
    "\n",
    "y = MaskingActivationLayer(conf)(song_input, out_logits_input)\n",
    "\n",
    "model = tf.keras.Model([song_input, out_logits_input], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'masking_activation_layer_40' (type MaskingActivationLayer).\n\nin user code:\n\n    File \"/tmp/ipykernel_113789/2015448542.py\", line 313, in get_mask_for_all_tokens  *\n        final_masks = tf.map_fn(\n    File \"/tmp/ipykernel_113789/2428752462.py\", line 71, in get_mask  *\n        forbidden_instruments, _ = tf.unique(tf.gather_nd(\n\n    InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [0] != values[1].shape = [] [Op:Pack] name: 0\n\n\nCall arguments received by layer 'masking_activation_layer_40' (type MaskingActivationLayer):\n  • song=tf.Tensor(shape=(2, 1023, 11), dtype=uint8)\n  • out_logits=['tf.Tensor(shape=(2, 1024, 8), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 131), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 136), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 129), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 25), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 153), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 49), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [101], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model([song, out_logits])\n",
      "File \u001b[0;32m~/github/MusicGeneration/env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn [99], line 374\u001b[0m, in \u001b[0;36mMaskingActivationLayer.call\u001b[0;34m(self, song, out_logits)\u001b[0m\n\u001b[1;32m    368\u001b[0m chosen_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39margmax(type_scores, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output_type\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39muint16)[:,\u001b[39m1\u001b[39m:], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    370\u001b[0m \u001b[39m# could change == i with x<i+eps and x>i-eps because it's softargmax and not argmax\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \n\u001b[1;32m    372\u001b[0m \u001b[39m# map_fn always unpacks axis=0      \u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[39m# TODO: COULD TUPLE INSTEAD OF CONCAT  \u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m masks \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmap_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_mask_for_all_tokens, tf\u001b[39m.\u001b[39;49mconcat([\n\u001b[1;32m    375\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(chosen_type, tf\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mfloat32),                \u001b[39m# BATCH*(SEQ_LEN-1)\u001b[39;49;00m\n\u001b[1;32m    376\u001b[0m         tf\u001b[39m.\u001b[39;49mcast(song, tf\u001b[39m.\u001b[39;49mdtypes\u001b[39m.\u001b[39;49mfloat32),                       \u001b[39m# BATCH*(SEQ_LEN-1)*11\u001b[39;49;00m\n\u001b[1;32m    377\u001b[0m         tf\u001b[39m.\u001b[39;49mslice(concat_logits, begin\u001b[39m=\u001b[39;49m[\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m], size\u001b[39m=\u001b[39;49m[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,conf\u001b[39m.\u001b[39;49mSEQ_LEN\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39m# BATCH*(SEQ_LEN-1)*1399\u001b[39;49;00m\n\u001b[1;32m    378\u001b[0m     ], axis \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m    380\u001b[0m \u001b[39mreturn\u001b[39;00m masks\n\u001b[1;32m    381\u001b[0m \u001b[39mreturn\u001b[39;00m [masked_act(type_logit, type_mask) \u001b[39mfor\u001b[39;00m masked_act, type_logit, type_mask \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasked_activations, out_logits, mask)]\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'masking_activation_layer_40' (type MaskingActivationLayer).\n\nin user code:\n\n    File \"/tmp/ipykernel_113789/2015448542.py\", line 313, in get_mask_for_all_tokens  *\n        final_masks = tf.map_fn(\n    File \"/tmp/ipykernel_113789/2428752462.py\", line 71, in get_mask  *\n        forbidden_instruments, _ = tf.unique(tf.gather_nd(\n\n    InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [0] != values[1].shape = [] [Op:Pack] name: 0\n\n\nCall arguments received by layer 'masking_activation_layer_40' (type MaskingActivationLayer):\n  • song=tf.Tensor(shape=(2, 1023, 11), dtype=uint8)\n  • out_logits=['tf.Tensor(shape=(2, 1024, 8), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 131), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 136), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 256), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 129), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 128), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 25), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 153), dtype=float32)', 'tf.Tensor(shape=(2, 1024, 49), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "model([song, out_logits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMusicGenerator\u001b[39;00m(tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel):\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, conf: config\u001b[39m.\u001b[39mConfig, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      4\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn [6], line 52\u001b[0m, in \u001b[0;36mMusicGenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_activations\u001b[39m(\u001b[39mself\u001b[39m, logits, masks):\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m [activation(elem, mask) \u001b[39mfor\u001b[39;00m elem, mask, activation \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(logits, masks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasked_activations)]\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_mask\u001b[39m(\u001b[39mself\u001b[39m, \n\u001b[1;32m     40\u001b[0m         default \u001b[39m=\u001b[39m [], \n\u001b[1;32m     41\u001b[0m         min_measure \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     42\u001b[0m         min_beat \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \n\u001b[1;32m     43\u001b[0m         min_position \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m         note \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m         allowed_instruments \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m         allowed_key_sign \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m         allowed_time_sign \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m         allowed_tempo \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m         forbidden_key_sign \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m         forbidden_time_sign \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     51\u001b[0m         forbidden_tempo \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     )\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39;49m[np\u001b[39m.\u001b[39;49mndarray]: \n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(default) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     55\u001b[0m         \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mask[i] \u001b[39mif\u001b[39;00m default[i] \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_mask[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(default))]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "class MusicGenerator(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, conf: config.Config, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.conf = conf\n",
    "        self.SEQ_LEN = conf.SEQ_LEN\n",
    "        self.TOKEN_DIM = conf.TOKEN_DIM\n",
    "        self.INPUT_RANGES = conf.INPUT_RANGES\n",
    "\n",
    "        self.dense_genre_emb = tf.keras.layers.Dense(self.TOKEN_DIM)\n",
    "        self.embeddings = conf.embedding_layers\n",
    "        self.concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "\n",
    "        self.pos_embedding_matrix = conf.get_positional_embedding_matrix()\n",
    "        self.positional_embeddings = tf.stack([self.pos_embedding_matrix]*conf.BATCH_SIZE)\n",
    "        self.sum_layer = tf.keras.layers.Add()\n",
    "\n",
    "        # TODO: add dense layer from embeddings to input decoder\n",
    "\n",
    "        self.decoder = conf.get_decoder()\n",
    "\n",
    "        self.output_dense_layers = conf.output_dense_layers\n",
    "\n",
    "        self.full_mask = conf.full_mask\n",
    "        self.default_mask = conf.default_mask\n",
    "\n",
    "        self.masked_activations = [tf.keras.layers.Softmax()]*len(self.embeddings)\n",
    "\n",
    "\n",
    "    def softargmax(x, beta=1e10):\n",
    "        x = tf.convert_to_tensor(x, dtype=tf.float64)\n",
    "        x_range = tf.range(x.shape.as_list()[-1], dtype=x.dtype)\n",
    "        return tf.reduce_sum(tf.nn.softmax(x*beta) * x_range, axis=-1)\n",
    "\n",
    "\n",
    "    def apply_activations(self, logits, masks):\n",
    "        return [activation(elem, mask) for elem, mask, activation in zip(logits, masks, self.masked_activations)]\n",
    "\n",
    "\n",
    "    def get_mask(self, \n",
    "            default = [], \n",
    "            min_measure = None, \n",
    "            min_beat = None, \n",
    "            min_position = None,\n",
    "            note = False,\n",
    "            allowed_instruments = None,\n",
    "            allowed_key_sign = None,\n",
    "            allowed_time_sign = None,\n",
    "            allowed_tempo = None,\n",
    "            forbidden_key_sign = None,\n",
    "            forbidden_time_sign = None,\n",
    "            forbidden_tempo = None\n",
    "        ): \n",
    "\n",
    "        '''\n",
    "        Returns a list of ndarrays of bool type used for masking\n",
    "        '''\n",
    "        if len(default) > 0: # no manual masking, either \"can freely choose this part of the token\" or \"can only choose default for this part of the token\"\n",
    "            return [self.default_mask[i] if default[i] else self.full_mask[i] for i in range(len(default))]\n",
    "        \n",
    "        else: # manual masking\n",
    "\n",
    "            measure_mask = np.asarray([False]*min_measure + [True]*(self.INPUT_RANGES[\"measure\"]-min_measure), dtype=bool)\n",
    "            # TODO: Implement BEAT MASK only if measure == last_measure\n",
    "            # TODO: Implement POSITION MASK only if measure == last_measure AND beat == last_beat\n",
    "\n",
    "            if min_beat == None:\n",
    "                beat_mask = self.default_mask[2]\n",
    "            else: # oss: allowed_time_sign is always != None if min_beat != None\n",
    "                max_beat = conf.get_max_beat_from_time_sign(allowed_time_sign)\n",
    "                # allowed beats are only AFTER previous beat and BEFORE max_beat from the numerator of the time_sign\n",
    "                beat_mask = np.asarray(\n",
    "                    [False]*min_beat + \\\n",
    "                    [True]*(max_beat-min_beat) + \\\n",
    "                    [False]*(self.INPUT_RANGES[\"beat\"]-max_beat)\n",
    "                , dtype=bool)\n",
    "            \n",
    "\n",
    "            if min_position == None:\n",
    "                position_mask = self.default_mask[3]\n",
    "            else:\n",
    "                position_mask = np.asarray([False]*min_position + [True]*(self.INPUT_RANGES[\"position\"]-min_position), dtype=bool)\n",
    "\n",
    "            if note:\n",
    "                duration_mask = self.full_mask[4]\n",
    "                pitch_mask = self.full_mask[5]\n",
    "                velocity_mask = self.full_mask[7]\n",
    "            else:\n",
    "                duration_mask = self.default_mask[4]\n",
    "                pitch_mask = self.default_mask[5]\n",
    "                velocity_mask = self.default_mask[7]\n",
    "\n",
    "            if allowed_instruments == None:\n",
    "                instruments_mask = self.default_mask[6]\n",
    "            else:\n",
    "                instruments_mask = np.asarray([True if i in allowed_instruments else False for i in range(self.INPUT_RANGES[\"instrument\"])], dtype=bool)\n",
    "\n",
    "            if allowed_key_sign == None:\n",
    "                if forbidden_key_sign == None:\n",
    "                    raise AssertionError(\"Cannot have both allowed and forbidden key_sign not instanciated\")\n",
    "                else:\n",
    "                    key_sign_mask = np.asarray([False if i == forbidden_key_sign else True for i in range(self.INPUT_RANGES[\"key_sign\"])], dtype=bool)\n",
    "            else:\n",
    "                key_sign_mask = np.asarray([True if i == allowed_key_sign else False for i in range(self.INPUT_RANGES[\"key_sign\"])], dtype=bool)\n",
    "\n",
    "            if allowed_time_sign == None:\n",
    "                if forbidden_time_sign == None:\n",
    "                    raise AssertionError(\"Cannot have both allowed and forbidden time_sign not instanciated\")\n",
    "                else:\n",
    "                    time_sign_mask = np.asarray([False if i == forbidden_time_sign else True for i in range(self.INPUT_RANGES[\"time_sign\"])], dtype=bool)\n",
    "            else:\n",
    "                time_sign_mask = np.asarray([True if i == allowed_time_sign else False for i in range(self.INPUT_RANGES[\"time_sign\"])], dtype=bool)\n",
    "\n",
    "            if allowed_tempo == None:\n",
    "                if forbidden_tempo == None:\n",
    "                    raise AssertionError(\"Cannot have both allowed and forbidden tempo not instanciated\")\n",
    "                else:\n",
    "                    tempo_mask = np.asarray([False if i == forbidden_tempo else True for i in range(self.INPUT_RANGES[\"tempo\"])], dtype=bool)\n",
    "            else:\n",
    "                tempo_mask = np.asarray([True if i == allowed_tempo else False for i in range(self.INPUT_RANGES[\"tempo\"])], dtype=bool)\n",
    "\n",
    "\n",
    "            return [\n",
    "                self.full_mask[0], # type is not masked\n",
    "                measure_mask,\n",
    "                beat_mask,\n",
    "                position_mask,\n",
    "                duration_mask,\n",
    "                pitch_mask,\n",
    "                instruments_mask,\n",
    "                velocity_mask,\n",
    "                key_sign_mask,\n",
    "                time_sign_mask,\n",
    "                tempo_mask\n",
    "            ]\n",
    "\n",
    "\n",
    "    def mask_and_activate_outputs(self, out_logits, song):\n",
    "        '''\n",
    "        Takes as input:\n",
    "            - out_logits: the scores outputted by the decoder + dense layers\n",
    "            - song: the input song, token by token\n",
    "\n",
    "        This function, based on the chosen token \"type\" given by the first dense layer,\n",
    "        masks all the different parts of the token accordingly, also taking into consideration\n",
    "        the previous tokens of the song\n",
    "\n",
    "        Output:\n",
    "            - probabilities for each different part of the predicted token (the following one in the song)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        max_type = tf.math.reduce_max(song[:,0])\n",
    "\n",
    "        # do not have to be tensors because loos shouldn't flow through them\n",
    "        if max_type == 0: # only start of song token\n",
    "            # cannot be anything else than instrument choice (1)\n",
    "            type_mask = np.asarray([False, True, False, False, False, False, False, False], dtype=bool)\n",
    "        elif max_type == 1: # we reached instrument choice\n",
    "            # cannot be anything else than instrument choice (1) or start of events (2)\n",
    "            type_mask = np.asarray([False, True, True, False, False, False, False, False], dtype=bool)\n",
    "        elif max_type >= 2 and max_type < 7: # we reached start of events or notes\n",
    "            type_mask = np.asarray([False, False, False, True, True, True, True, True], dtype=bool)\n",
    "\n",
    "        elif max_type == 7: # at the end of the song we can ONLY GUESS \"000000000\" TODO: change to zero\n",
    "            type_mask = np.asarray([True, False, False, False, False, False, False, False], dtype=bool)\n",
    "\n",
    "        type_scores = self.masked_activations[0](out_logits[0], type_mask) # the first masked activation is for the type\n",
    "        \n",
    "        # needs to be differentiable (but the masks shouldn't need to be)\n",
    "        chosen_type = self.softargmax(type_scores)\n",
    "\n",
    "        # could change == i with x<i+eps and x>i-eps because it's softargmax and not argmax\n",
    "        if chosen_type == 0: # TODO: change to 7 # only way it chooses 0 is that max_type==7 --> AFTER END OF SONG --> only thing the model can do is guess all zeros\n",
    "            # \"does not have to learn nothing\" --> it's all zeros just like the padding tensors\n",
    "            mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "        # instrument selection\n",
    "        if chosen_type == 1: # false only for type and instrument type (the ones that you can choose)\n",
    "            mask = self.get_mask(default = [False, True, True, True, True, True, False, True, True, True, True])\n",
    "        # start of events\n",
    "        elif chosen_type == 2: # false only for type (cannot choose anything in \"start of events\" token)\n",
    "            mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "        # notes\n",
    "        elif chosen_type == 3: # note: has same key_sign, time_sign and tempo as last previous event, everything has to be manually decided\n",
    "            \n",
    "            mask = self.get_mask(\n",
    "                min_measure = song[-1,1],   # it has to be >= than the last measure\n",
    "                min_beat = song[-1,2],      # it has to be >= than the last beat (if measure is the same)\n",
    "                min_position = song[-1,3],  # it has to be >= than the last position (if beat and measure are the same)\n",
    "                note = True,\n",
    "                allowed_instruments = np.unique(song[np.where(song[:,0] == 2),6]), # if type == 2 --> read the instruments (unique = set)\n",
    "                allowed_key_sign =  song[np.where(song[:,0] == 4), 8][0][-1], # if type == 4 --> read the LAST key_sign\n",
    "                allowed_time_sign = song[np.where(song[:,0] == 5), 9][0][-1], # if type == 5 --> read the LAST time_sign\n",
    "                allowed_tempo =     song[np.where(song[:,0] == 6),10][0][-1]  # if type == 6 --> read the LAST tempo\n",
    "            )\n",
    "\n",
    "        # key_sign, time_sign, tempo\n",
    "        elif chosen_type == 4 or chosen_type == 5 or chosen_type == 6:\n",
    "            # if last event is at the beginning of a measure, you can add an event at the same time\n",
    "            if song[-1,3] == 0 and song[-1,2] == 0:  # if beat and position == 0, can be this measure\n",
    "                min_measure = song[-1,1]\n",
    "            # otherwise it goes to the next measure\n",
    "            else:\n",
    "                min_measure = song[-1,1] + 1\n",
    "            \n",
    "            if chosen_type == 4:\n",
    "                mask = self.get_mask(\n",
    "                    min_measure = min_measure,\n",
    "                    forbidden_key_sign = song[np.where(song[:,0] == 4), 8][0][-1] # cannot put the same key_sign again\n",
    "                )\n",
    "\n",
    "            if chosen_type == 5:\n",
    "                mask = self.get_mask(\n",
    "                    min_measure = min_measure,\n",
    "                    forbidden_time_sign = song[np.where(song[:,0] == 5), 9][0][-1] # cannot put the same time_sign again\n",
    "                )\n",
    "            \n",
    "            if chosen_type == 6:\n",
    "                mask = self.get_mask(\n",
    "                    min_measure = min_measure,\n",
    "                    forbidden_tempo = song[np.where(song[:,0] == 6),10][0][-1] # cannot put the same tempo again\n",
    "                )\n",
    "        \n",
    "        elif chosen_type == 7: # end of song --> only type can be chosen, all the others are default\n",
    "            mask = self.get_mask(default = [False, True, True, True, True, True, True, True, True, True, True])\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Impossible that chosen type isn't in [1,7] --> {}\".format(chosen_type))\n",
    "\n",
    "        # TODO: check if it works for every type!\n",
    "        return [masked_act(type_logit, type_mask) for masked_act, type_logit, type_mask in zip(self.masked_activations, out_logits, mask)]\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        # to train you need to add a \"end_song\" input --> in this way you create the attention mask\n",
    "        # for the decoder\n",
    "\n",
    "        if type(inputs) == dict:\n",
    "            song = inputs[\"song\"]\n",
    "            genre = inputs[\"genre\"]\n",
    "            attention_mask = inputs[\"attention_mask\"] # TODO: remove if decoder outputs sequences\n",
    "\n",
    "        elif type(inputs) == tuple:\n",
    "            song = inputs[0]\n",
    "            genre = inputs[1]\n",
    "            attention_mask = inputs[2] # TODO: remove if decoder outputs sequences\n",
    "            \n",
    "        # EMBEDDING GENERATION for decoder\n",
    "        genre_embedding = self.dense_genre_emb(genre)\n",
    "\n",
    "        # TODO: check how they come out (should be 11*64 numbers for each line, and 6143 lines for each song in batch)\n",
    "        # TODO: batch?\n",
    "        token_embeddings = [self.embeddings[i](song[:,i]) for i in range(len(self.embeddings))]\n",
    "\n",
    "        final_embeddings = self.concat_layer([genre_embedding, token_embeddings])\n",
    "\n",
    "        decoder_output = self.decoder(\n",
    "            input_embeds = final_embeddings,\n",
    "            attention_mask = attention_mask, # TODO: remove if decoder outputs sequences\n",
    "            position_ids = self.positional_embeddings\n",
    "        )\n",
    "\n",
    "        out_logits = [layer(decoder_output[\"last_hidden_state\"]) for layer in self.output_dense_layers]\n",
    "        \n",
    "        # insert for if decoder outputs sequences\n",
    "\n",
    "        out_scores = self.mask_and_activate_outputs(out_logits, song)\n",
    "        \n",
    "        # return genre_embedding, token_embeddings, final_embeddings, attention_mask, out_logits, out_scores\n",
    "        return out_scores\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        song, genre = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # TODO: how to do it for batches?\n",
    "            trainable_vars = self.trainable_variables\n",
    "            # we only want to predict up to the real finish of the song\n",
    "            # but they are padded --> for each song we stop at the token BEFORE the \"end_song\" token\n",
    "            # we predict as last token the \"end_song\" one\n",
    "\n",
    "            # pass through the network THE ENTIRE SONG (even the last PADDED TOKENS! so the batch flows together)\n",
    "            # OR we could stop on the biggest last token in batch\n",
    "            for i, y in enumerate(song[1:]):\n",
    "                # TODO: check and simplify if decoder output is already sequence\n",
    "\n",
    "                # y is the current token\n",
    "                y_pred = self((\n",
    "                    song,\n",
    "                    genre,\n",
    "                    np.asarray([1]*(i+1) + [0]*(self.SEQ_LEN-1-(i+1))) # attention mask\n",
    "                ))\n",
    "\n",
    "                loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "                gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "                self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "                self.compiled_metrics.update_state(y, y_pred)\n",
    "        \n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 18:59:03.635505: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Slice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[2] in [0, 5], but got 6 [Op:Slice]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m MusicGenerator(conf)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m song_batch, genre_batch \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     notes \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mslice(song_batch, [\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, i], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m8192\u001b[39m)]\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(notes[\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn [14], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m MusicGenerator(conf)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m song_batch, genre_batch \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     notes \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39;49mslice(song_batch, [\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, i], [\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m, i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m8192\u001b[39m)]\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(notes[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/github/MusicGeneration/env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/github/MusicGeneration/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Slice_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected size[2] in [0, 5], but got 6 [Op:Slice]"
     ]
    }
   ],
   "source": [
    "model = MusicGenerator(conf)\n",
    "\n",
    "for song_batch, genre_batch in dataset.take(1):\n",
    "    tf.gather(song_batch)\n",
    "    notes = [tf.slice(song_batch, [0, 0, i], [-1, 0, i]) for i in range(8192)]\n",
    "    print(notes[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
