{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import config\n",
    "import utils\n",
    "import music_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'tf_data7dict'\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "\n",
    "def get_model_name(use_mask: bool, use_reg: bool, use_mse_for_velocity:bool):\n",
    "    if use_mask and not use_reg:\n",
    "        model_name = 'mask_only'\n",
    "    elif use_reg and not use_mask:\n",
    "        model_name = 'reg_only'\n",
    "    elif use_reg and use_mask:\n",
    "        model_name = 'reg_and_mask'\n",
    "    else:\n",
    "        model_name = 'baseline'\n",
    "    if use_mse_for_velocity:\n",
    "        model_name += '_with_mse_vel'\n",
    "    return model_name\n",
    "\n",
    "def run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                 use_mask=True, use_reg=True, use_mse_for_velocity=True,\n",
    "                 use_wandb=True, use_one_gpu=True, verbose=True):\n",
    "    \n",
    "    if verbose: print(\"Running setup...\")\n",
    "    model_name = get_model_name(use_mask, use_reg, use_mse_for_velocity)\n",
    "    \n",
    "    if verbose: print(\"\\tInstantiating and personalizing Config object...\")\n",
    "    conf = config.Config(config_string=\"single_instruments_type\", \n",
    "                         root_path=ROOT_PATH, \n",
    "                         model_type=model_type,\n",
    "                         model_name=f'model_{model_type}_{model_name + additional_model_name}')\n",
    "\n",
    "    # Config object has by default the full list of accepted subgenres and works on multi-gpus\n",
    "    # If we use the small dataset\n",
    "    if USE_SMALL_GENRE_SET:\n",
    "        conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "\n",
    "    # If we need to use only the first GPU\n",
    "    if use_one_gpu:\n",
    "        conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "        conf.BATCH_SIZE = 4\n",
    "        conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "        conf.num_devices = 1\n",
    "    \n",
    "    if verbose: print(\"\\tCreating model...\")\n",
    "    if conf.num_devices > 1:\n",
    "        print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "        with conf.training_strategy.scope():\n",
    "            model = music_model.create_model(conf, \n",
    "                                             use_masking_layers=use_mask,\n",
    "                                             use_regularization=use_reg,\n",
    "                                             use_mse_for_velocity=use_mse_for_velocity)\n",
    "    else:\n",
    "        print(\"Using single GPU/CPU device\")\n",
    "        model = music_model.create_model(conf, \n",
    "                                         use_masking_layers=use_mask,\n",
    "                                         use_regularization=use_reg,\n",
    "                                         use_mse_for_velocity=use_mse_for_velocity)\n",
    "    \n",
    "    if verbose: print(\"\\tSetupping Wandb logger...\")\n",
    "    if use_wandb:\n",
    "        wandb_config = {\n",
    "            'gpus': conf.num_devices,\n",
    "            'dataset': DATASET_NAME,\n",
    "            'genres': conf.accepted_subgenres,\n",
    "            'embedding_size': conf.SINGLE_EMB_SIZE,\n",
    "            'batch_size': conf.BATCH_SIZE,\n",
    "            'global_batch_size': conf.GLOBAL_BATCH_SIZE,\n",
    "            'mse_for_velocity': use_mse_for_velocity,\n",
    "            'reg_loss_scale': conf.REG_LOSS_SCALE,\n",
    "            'masking': conf.USE_MASKING,\n",
    "            'dropout_prob': conf.DROPOUT_VALUE,\n",
    "            'seq_len': conf.SEQ_LEN,\n",
    "            'token_dim': conf.TOKEN_DIM,\n",
    "            'genre_dim': conf.GENRE_DIM,\n",
    "            'attn_heads': conf.ATTENTION_HEADS,\n",
    "            'attn_blocks': conf.ATTENTION_BLOCKS,\n",
    "        }\n",
    "\n",
    "        if model_type == 'GPT':\n",
    "            wandb_config['activation_func'] = conf.DECODER_ACTIVATION_FUNCTION\n",
    "        elif model_type == 'XL':\n",
    "            wandb_config['sequence_blocks'] = conf.DIV_VAL\n",
    "            wandb_config['head_dim']  = conf.HEAD_DIM\n",
    "            wandb_config['inner_dim'] = conf.INNER_DIM\n",
    "            wandb_config['memory_length'] = conf.MEMORY_LEN\n",
    "\n",
    "        run = wandb.init(project=\"Music Generation\", entity=\"marcello-e-federico\",\n",
    "                         group=model_name, job_type='train', config=wandb_config,\n",
    "                         name=log_name if log_name != '' else None)\n",
    "    \n",
    "    if verbose: print(\"\\tObtaining dataset...\")\n",
    "    dataset_path = conf.dataset_paths[DATASET_NAME]\n",
    "    train_dataset, val_dataset, test_dataset = utils.get_dataset_splits(dataset_path, conf)\n",
    "    \n",
    "    if verbose: print(\"\\tSetupping callbacks...\")\n",
    "    callbacks = conf.MODEL_CALLBACKS\n",
    "    if use_wandb:\n",
    "        callbacks.append(WandbCallback(\n",
    "            save_model=False, save_graph=False,\n",
    "            log_weights=True\n",
    "        ))\n",
    "    \n",
    "    if verbose: print(\"Training start\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs = 100,\n",
    "        callbacks = callbacks,\n",
    "        validation_data = val_dataset,\n",
    "        # initial_epoch = initial_epoch # change if resuming from previous checkpoint\n",
    "    )\n",
    "    if verbose: print(\"Training finished\")\n",
    "    \n",
    "    if use_wandb:\n",
    "        if verbose: print(\"\\tClosing Wandb logger...\")\n",
    "        run.finish()\n",
    "        \n",
    "    if verbose: print(\"\\tClearing session...\")\n",
    "    K.clear_session()\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING BASELINE MODEL\n",
      "\n",
      "\n",
      "Running setup...\n",
      "\tInstantiating and personalizing Config object...\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 16:47:32.246099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 16:47:33.399983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30503 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2023-01-05 16:47:33.400564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 646 MB memory:  -> device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating model...\n",
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSetupping Wandb logger...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvolpepe\u001b[0m (\u001b[33mmarcello-e-federico\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aborghesi/persistent/MusicGeneration/src/wandb/run-20230105_164741-dq2fm8zi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation/runs/dq2fm8zi\" target=\"_blank\">whole-planet-39</a></strong> to <a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tObtaining dataset...\n",
      "\tSetupping callbacks...\n",
      "Training start\n",
      "Epoch 1/100\n",
      "   6/1394 [..............................] - ETA: 25:47 - loss: 6.6713 - type_loss: 0.1677 - measure_loss: 1.3223 - beat_loss: 0.9920 - position_loss: 0.3969 - duration_loss: 0.4877 - pitch_loss: 1.4238 - instrument_loss: 0.9901 - velocity_loss: 0.0015 - key_sign_loss: 0.1526 - time_sign_loss: 0.4560 - tempo_loss: 0.2808WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4779s vs `on_train_batch_end` time: 0.5313s). Check your callbacks.\n",
      "1394/1394 [==============================] - 1712s 1s/step - loss: 2.2530 - type_loss: 0.0136 - measure_loss: 0.4262 - beat_loss: 0.1783 - position_loss: 0.0244 - duration_loss: 0.1537 - pitch_loss: 1.0220 - instrument_loss: 0.3388 - velocity_loss: 1.4290e-04 - key_sign_loss: 0.0437 - time_sign_loss: 0.0429 - tempo_loss: 0.0092 - val_loss: 3.2336 - val_type_loss: 0.0047 - val_measure_loss: 0.7850 - val_beat_loss: 0.2281 - val_position_loss: 0.0845 - val_duration_loss: 0.4821 - val_pitch_loss: 0.8823 - val_instrument_loss: 0.3535 - val_velocity_loss: 7.3254e-05 - val_key_sign_loss: 0.2494 - val_time_sign_loss: 0.1599 - val_tempo_loss: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "  14/1394 [..............................] - ETA: 25:45 - loss: 1.7026 - type_loss: 0.0071 - measure_loss: 0.0941 - beat_loss: 0.0938 - position_loss: 0.0083 - duration_loss: 0.1440 - pitch_loss: 1.0056 - instrument_loss: 0.3372 - velocity_loss: 7.5959e-05 - key_sign_loss: 4.1823e-04 - time_sign_loss: 0.0071 - tempo_loss: 0.0048"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING BASELINE MODEL\\n\\n\")\n",
    "model_baseline_mse_vel, history_baseline_mse_vel = run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                                                                use_mask=False, use_reg=False, use_mse_for_velocity=True,\n",
    "                                                                use_wandb=True, use_one_gpu=True, verbose=True)\n",
    "print(\"=================================\\n\")\n",
    "print(\"TRAINING MASK AND REG MODEL\\n\\n\")\n",
    "model_mask_reg_mse_vel, history_mask_reg_mse_vel = run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                                                                use_mask=True, use_reg=True, use_mse_for_velocity=True,\n",
    "                                                                use_wandb=True, use_one_gpu=True, verbose=True)\n",
    "print(\"=================================\\n\")\n",
    "print(\"TRAINING MASK ONLY MODEL\\n\\n\")\n",
    "model_mask_mse_vel, history_mask_mse_vel = run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                                                        use_mask=True, use_reg=False, use_mse_for_velocity=True,\n",
    "                                                        use_wandb=True, use_one_gpu=True, verbose=True)\n",
    "print(\"=================================\\n\")\n",
    "print(\"TRAINING REG ONLY MODEL\\n\\n\")    \n",
    "model_reg_mse_vel, history_reg_mse_vel = run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                                                        use_mask=False, use_reg=True, use_mse_for_velocity=True,\n",
    "                                                        use_wandb=True, use_one_gpu=True, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "17321a188135f2c2c768fa02a53ff8b7818a96a6473bfad36c60a386ff86beab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
