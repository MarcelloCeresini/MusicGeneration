{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcelloceresini/miniconda/envs/env-MusicGeneration/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import muspy\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import config\n",
    "import utils\n",
    "\n",
    "config_string = \"single_instruments_type\"\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "conf = config.Config(config_string, ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115190"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(conf.dataset_paths[\"lmd_matched\"], \"lakh_matched_genre_vectors.pickle\"), \"rb\") as f:\n",
    "    genre_vectors = pickle.load(f)\n",
    "\n",
    "dataset = utils.get_dataset(\"lmd_matched\", conf)\n",
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study to choose final length of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Long dataset matched: : 69031it [43:55, 22.51it/s] "
     ]
    }
   ],
   "source": [
    "lengths = np.zeros(10000000)\n",
    "\n",
    "discarded_samples = {\n",
    "    0:0, # empty song\n",
    "    1:0, # time_signatures not all acceptable\n",
    "    2:0, # n_measures too big\n",
    "    3:0, # too many notes\n",
    "    4:0, # no genre\n",
    "}\n",
    "\n",
    "for song, genre in (pbar := tqdm(zip(dataset, genre_vectors), total=len(dataset))):\n",
    "    pbar.set_description(\"Long dataset matched\")\n",
    "    if type(genre) == type(None):\n",
    "        discarded_samples[4] += 1\n",
    "\n",
    "    else:\n",
    "        converted_song = utils.transform_representation(song, conf)\n",
    "\n",
    "        lengths[len(converted_song)] += 1\n",
    "\n",
    "        if len(converted_song) <= 1:\n",
    "            discarded_samples[converted_song[0]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "for i in range(len(lengths)):\n",
    "    if lengths[i]>0:\n",
    "        max = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = lengths[:max+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(lengths)), lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_len=1024 \n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))\n",
    "chosen_len=2048 \n",
    "print(\"Percentage of song kept if discarding every song longer than {}: {}\".format(chosen_len, np.sum(lengths[:chosen_len])/np.sum(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighed_lenghts = lengths.astype(np.uint256)*np.arange(len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_len=1024\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))\n",
    "chosen_len=2048\n",
    "print(\"Percentage of dataset information by cutting every song to {} tokens: {}\".format(chosen_len, (np.sum(weighed_lenghts[:chosen_len]) + np.sum(lengths[chosen_len:])*chosen_len) / np.sum(weighed_lenghts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_LEN = 2048\n",
    "\n",
    "samples = []\n",
    "genres = []\n",
    "labels = {key:[] for key in conf.INPUT_RANGES.keys()}\n",
    "\n",
    "lengths = np.zeros(10000000)\n",
    "\n",
    "discarded_samples = {\n",
    "    0:0, # empty song\n",
    "    1:0, # time_signatures not all acceptable\n",
    "    2:0, # n_measures too big\n",
    "    3:0, # too many notes\n",
    "    4:0, # no genre\n",
    "}\n",
    "\n",
    "for song, genre in (pbar := tqdm(zip(dataset, genre_vectors), total=len(dataset))):\n",
    "    pbar.set_description(\"Long dataset matched\")\n",
    "    if type(genre) == type(None):\n",
    "        discarded_samples[4] += 1\n",
    "\n",
    "    else:\n",
    "        converted_song = utils.transform_representation(song, conf)\n",
    "\n",
    "        lengths[len(converted_song)] += 1\n",
    "\n",
    "        if len(converted_song) <= 1:\n",
    "            discarded_samples[converted_song[0]] += 1\n",
    "\n",
    "        elif len(converted_song) > CHOSEN_LEN:\n",
    "            discarded_samples[3] += 1\n",
    "        \n",
    "        elif len(converted_song) == CHOSEN_LEN:\n",
    "            samples.append(converted_song, dtype=np.uint8)\n",
    "            labels.append(genre)       \n",
    "            \n",
    "        else:\n",
    "            padding = tf.cast(np.stack([[7]+[0]*10]*(CHOSEN_LEN-len(converted_song)), axis=0), dtype=np.uint8)\n",
    "            \n",
    "            sample = np.concatenate((\n",
    "                    converted_song,\n",
    "                    tf.identity(padding)\n",
    "                ), dtype=np.uint8\n",
    "            )\n",
    "\n",
    "            samples.append(sample)\n",
    "            genres.append(genre)\n",
    "\n",
    "            for i, key in enumerate(labels.keys()):\n",
    "                labels[key].append(song[:,i])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((samples, genres), labels))\n",
    "dataset.save(conf.lmd_matched_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_discarded = sum(discarded_samples.values())\n",
    "print(\"Kept {}% of the songs\".format(len(dataset)/len(samples)*100))\n",
    "print(\"Of the discarded: \")\n",
    "print(\"- {:.2f}% were empty\".format(discarded_samples[0]/tot_discarded*100))\n",
    "print(\"- {:.2f}% contained not accepted time signatures\".format(discarded_samples[1]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had too many measures\".format(discarded_samples[2]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had too many events/notes\".format(discarded_samples[3]/tot_discarded*100))\n",
    "print(\"- {:.2f}% had no accepted genre\".format(discarded_samples[4]/tot_discarded*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-MusicGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
