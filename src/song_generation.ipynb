{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "import config, music_model, utils\n",
    "\n",
    "### CONFIGURATION ###\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'tf_data7dict'\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "USE_ONE_GPU = True\n",
    "\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1\n",
    "\n",
    "### MODEL CREATION ###\n",
    "\n",
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf,\n",
    "                                         num_genres=len(conf.accepted_subgenres),\n",
    "                                         use_regularization=False,\n",
    "                                         use_masking_layers=False)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf,\n",
    "                                     num_genres=len(conf.accepted_subgenres),\n",
    "                                     use_regularization=False,\n",
    "                                     use_masking_layers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2047, 11) (4, 3)\n",
      "dict_keys(['duration', 'type', 'tempo', 'measure', 'instrument', 'pitch', 'position', 'beat', 'time_sign', 'velocity', 'key_sign'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 14:21:30.420590: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "## Load the dataset\n",
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "\n",
    "## Take the first batch of the dataset and trim its sequence length to 2047\n",
    "X, y = next(dataset.take(1).as_numpy_iterator())\n",
    "X = (X[0][:,:conf.SEQ_LEN-1,:], X[1])\n",
    "y = {k: y[k][:,:conf.SEQ_LEN-1] for k in y}\n",
    "\n",
    "print(X[0].shape, X[1].shape)\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Function to choose a style for the song\n",
    "def encode_styles(styles_array):\n",
    "    return np.stack([\n",
    "        utils.one_hot_encode_labels_nmf(style)\n",
    "        for style in styles_array\n",
    "    ], axis=0).astype(np.int8)\n",
    "\n",
    "# Example:\n",
    "styles = encode_styles(['folk', 'nes', 'maestro', 'nes'])\n",
    "print(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 14:21:31.094699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "transformer = model.get_layer('tfgpt2_model')\n",
    "output_layers = [\n",
    "    model.get_layer('type_scores'),\n",
    "    model.get_layer('measure_scores'),\n",
    "    model.get_layer('beat_scores'),\n",
    "    model.get_layer('position_scores'),\n",
    "    model.get_layer('duration_scores'),\n",
    "    model.get_layer('pitch_scores'),\n",
    "    model.get_layer('instrument_scores'),\n",
    "    model.get_layer('velocity_values'),\n",
    "    model.get_layer('keysign_scores'),\n",
    "    model.get_layer('timesign_scores'),\n",
    "    model.get_layer('tempo_scores')\n",
    "]\n",
    "activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "\n",
    "## Test this pipeline\n",
    "# Let's assume we need to only send the first 2 token.\n",
    "# Therefore we will build an attention mask where only the first 2 values are 1 and the others are 0\n",
    "CUR_IDX = 2\n",
    "GEN_BATCH_SIZE = 4\n",
    "attention_mask = np.ones((GEN_BATCH_SIZE, 1+CUR_IDX), dtype=np.int8)\n",
    "padding_attention_mask = np.zeros((GEN_BATCH_SIZE, conf.SEQ_LEN-1-CUR_IDX), dtype=np.int8)\n",
    "attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "preprocessed_tensors = preprocessing_model(X)\n",
    "out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                                   attention_mask=attention_mask)['last_hidden_state']\n",
    "out_scores           = [output_layers[i](out_transformer)[:,:-1,:] \n",
    "                        for i in range(len(output_layers))]\n",
    "out_probs            = [np.array(activations[i](out_scores[i])) \n",
    "                        for i in range(len(activations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4, 112,  56, 117,  52,  23,  38,   1,  20, 126,  15],\n",
       "       [  4, 118,  70,  64, 101,  18,  38,   1,   7, 130,  42],\n",
       "       [  6,   3,  10,  78, 118, 187,   9,   1,  15,  21,  47],\n",
       "       [  4,  63,  96, 105,  36,  23,   7,   1,  20,  46,   7]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the token components\n",
    "generation_mode = 'top_p_sampling'\n",
    "\n",
    "if generation_mode == 'top_p_sampling':\n",
    "    # Compute the dynamic top-p thresholds\n",
    "    top_p_sequence = np.linspace(0.9, 0.6, conf.SEQ_LEN-1)  # Generate max_length-1 evenly spaced values\n",
    "\n",
    "token_components = []\n",
    "for head_idx in range(len(out_probs)):\n",
    "    # Velocity is just a number, not a probability distribution\n",
    "    if head_idx == 7: token_components.append(\n",
    "        np.asarray(out_probs[7][:, CUR_IDX, :], dtype=np.int32))\n",
    "    else:\n",
    "    # Sample the next token from the output probabilities using the desired sampling mode\n",
    "\n",
    "        ## 1. Top-k sampling: sample from the top-k most probable tokens.\n",
    "        ## k is expressed as a ratio of the number of possibilities, because each component has different ranges.\n",
    "        if generation_mode == 'top_k_sampling':\n",
    "            k = int(out_probs[head_idx].shape[-1] * 0.3)\n",
    "            top_k_indices = np.argsort(-np.asarray(out_probs[head_idx][:, CUR_IDX, :]))[:, :k]\n",
    "            for song in range(GEN_BATCH_SIZE):\n",
    "                redistrib_mass = sum(np.take(out_probs[head_idx][song, CUR_IDX, :], top_k_indices[song]))\n",
    "                # redistrib_mass : 1 = prob[i] : x --> x = prob[i] / redistrib_mass\n",
    "                for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                    out_probs[head_idx][song, CUR_IDX, idx] = \\\n",
    "                        (out_probs[head_idx][song, CUR_IDX, idx] / redistrib_mass) if idx in top_k_indices[song] else 0\n",
    "\n",
    "        ## 2. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "        elif generation_mode == 'top_p_sampling':\n",
    "            best_indices = np.argsort(-np.asarray(out_probs[head_idx][:, CUR_IDX, :]))\n",
    "            for song in range(GEN_BATCH_SIZE):\n",
    "                # Take elements until the cumulative probability exceeds the threshold (always at least one element)\n",
    "                cum_prob = 0; k = 0\n",
    "                while cum_prob < top_p_sequence[CUR_IDX]:\n",
    "                    cum_prob += out_probs[head_idx][song, CUR_IDX, best_indices[song, k]]\n",
    "                    k += 1\n",
    "                # Directly modify the probability array\n",
    "                # cum_prob : 1 = prob[i] : x --> x = prob[i] / cum_prob\n",
    "                # For the other elements, the probability is 0\n",
    "                for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                    out_probs[head_idx][song, CUR_IDX, idx] = \\\n",
    "                        (out_probs[head_idx][song, CUR_IDX, idx] / cum_prob) if idx in best_indices[song, :k] else 0\n",
    "        \n",
    "        ## 3. Standard mapping: simply sample from the probability distributions with no additional frills.\n",
    "        batch = [[np.random.choice(\n",
    "            np.arange(out_probs[head_idx].shape[-1]),\n",
    "            p=out_probs[head_idx][song, CUR_IDX, :]\n",
    "            )] for song in range(GEN_BATCH_SIZE)]\n",
    "        token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "\n",
    "# Create the tokens concatenating the sampled components\n",
    "new_tokens = np.concatenate(token_components, axis=1)\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Song generation function\n",
    "def generate_songs(model, style_list:List[str], max_length:int=conf.SEQ_LEN-1, \n",
    "                   terminator_type:int=7, generation_mode:str='standard_sampling', \n",
    "                   temperature:float=1.0, top_k_ratio=0.3, top_p_start:float=0.9, \n",
    "                   top_p_min=0.9):\n",
    "    \n",
    "    # Check the validity of the parameters\n",
    "    assert temperature > 0, \"Temperature must be greater than 0\"\n",
    "    assert max_length <= conf.SEQ_LEN-1, f\"The maximum length of the generated song must be less than {conf.SEQ_LEN-1}\"\n",
    "    assert generation_mode in ['standard_sampling', 'top_k_sampling', 'top_p_sampling'], \\\n",
    "        f\"Parameter 'generation_mode' must be one of the following: 'standard_sampling', 'top_k_sampling', 'top_p_sampling'\"\n",
    "\n",
    "    # Collect explicitly the number of songs to generate\n",
    "    num_songs = len(style_list)\n",
    "\n",
    "    # Separate preprocessing model, transformer and output layers in order to be able to\n",
    "    # inject the attention masks into the transformer and still use the loaded weights\n",
    "    preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "    transformer = model.get_layer('tfgpt2_model')\n",
    "    output_layers = [\n",
    "        model.get_layer('type_scores'), model.get_layer('measure_scores'), model.get_layer('beat_scores'),\n",
    "        model.get_layer('position_scores'), model.get_layer('duration_scores'), model.get_layer('pitch_scores'),\n",
    "        model.get_layer('instrument_scores'), model.get_layer('velocity_values'), model.get_layer('keysign_scores'),\n",
    "        model.get_layer('timesign_scores'), model.get_layer('tempo_scores')\n",
    "    ]\n",
    "    activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "    \n",
    "    # Create the empty song array.\n",
    "    # The first token of the songs is always the start token (0,...,0)\n",
    "    # The rest of the tensor is filled with padding of zeroes, which will be masked by the attention masks\n",
    "    generated_songs = np.zeros((num_songs, conf.SEQ_LEN-1, 11), dtype=np.int32)\n",
    "\n",
    "    if generation_mode == 'top_p_sampling':\n",
    "        # Compute the dynamic top-p thresholds\n",
    "        top_p_sequence = np.linspace(top_p_start, top_p_min, max_length-1)  # Generate max_length-1 evenly spaced values\n",
    "    \n",
    "    # Generate the one-hot encodings of the genres\n",
    "    styles = encode_styles(style_list)\n",
    "\n",
    "    # Start to generate the songs token by token\n",
    "    for i in trange(1, max_length):\n",
    "\n",
    "        # Create the attention mask (the first 2 tokens are always attended: genre and starting token)\n",
    "        attention_mask = np.ones((num_songs, 1+i), dtype=np.int8)\n",
    "        padding_attention_mask = np.zeros((num_songs, conf.SEQ_LEN-1-i), dtype=np.int8)\n",
    "        attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "        # Preprocess the songs and pass them through the transformer\n",
    "        preprocessed_tensors = preprocessing_model((generated_songs, styles))\n",
    "        out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                               attention_mask=attention_mask)['last_hidden_state']\n",
    "        # Use the output layers to generate the probabilities for the next token\n",
    "        # Output from transformer has SEQ_LEN tokens, so we trim it by removing the last one,\n",
    "        # since it's the probability of a token that's out of our bounds.\n",
    "        out_scores           = [output_layers[i](out_transformer)[:,:-1,:]\n",
    "                                for i in range(len(output_layers))]\n",
    "        # Apply temperature to the scores but mind the velocity scores which is a scalar\n",
    "        out_scores_tempered  = [out_scores[i] / temperature for i in range(7)] + \\\n",
    "            [out_scores[7]]  + [out_scores[i] / temperature for i in range(8, 11)]\n",
    "        out_probs            = [np.array(activations[i](out_scores_tempered[i]))\n",
    "                                for i in range(len(activations))]\n",
    "        \n",
    "        # Create the token components\n",
    "        token_components = []\n",
    "        for head_idx in range(len(out_probs)):\n",
    "            # Velocity is just a number, not a probability distribution\n",
    "            if head_idx == 7: token_components.append(\n",
    "                    np.asarray(out_probs[7][:, i, :], dtype=np.int32))\n",
    "            else:\n",
    "                # Sample the next token from the output probabilities using the desired sampling mode\n",
    "                if generation_mode != 'standard_sampling':\n",
    "                    # Use some method to modify the probabilities, such as top-k or top-p sampling\n",
    "\n",
    "                    ## 1. Top-k sampling: sample from the top-k most probable tokens.\n",
    "                    ## k is expressed as a ratio of the number of possibilities, because each component has different ranges.\n",
    "                    if generation_mode == 'top_k_sampling':\n",
    "                        # Compute the top-k indices in the probability array\n",
    "                        k = np.ceil(out_probs[head_idx].shape[-1] * top_k_ratio)\n",
    "                        top_k_indices = np.argsort(-np.asarray(out_probs[head_idx][:, i, :]))[:, :k]\n",
    "                        for song in range(num_songs):\n",
    "                            # For each song, compute the mass of probability to be redistributed between the top-k elements\n",
    "                            redistrib_mass = sum(np.take(out_probs[head_idx][song, i, :], top_k_indices[song]))\n",
    "                            # Directly modify the probability array \n",
    "                            # redistrib_mass : 1 = prob[i] : x --> x = prob[i] / redistrib_mass\n",
    "                            # For the non-top-k elements, the probability is 0\n",
    "                            for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                                out_probs[head_idx][song, i, idx] = \\\n",
    "                                    (out_probs[head_idx][song, i, idx] / redistrib_mass) if idx in top_k_indices[song] else 0\n",
    "\n",
    "                    ## 2. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "                    elif generation_mode == 'top_p_sampling':\n",
    "                        best_indices = np.argsort(-np.asarray(out_probs[head_idx][:, i, :]))\n",
    "                        for song in range(num_songs):\n",
    "                            # Take elements until the cumulative probability exceeds the threshold (always at least one element)\n",
    "                            cum_prob = 0; k = 0\n",
    "                            while cum_prob < top_p_sequence[i-1]:\n",
    "                                cum_prob += out_probs[head_idx][song, i, best_indices[song, k]]\n",
    "                                k += 1\n",
    "                            # Directly modify the probability array\n",
    "                            # cum_prob : 1 = prob[i] : x --> x = prob[i] / cum_prob\n",
    "                            # For the other elements, the probability is 0\n",
    "                            for idx in range(out_probs[head_idx].shape[-1]):\n",
    "                                out_probs[head_idx][song, i, idx] = \\\n",
    "                                    (out_probs[head_idx][song, i, idx] / cum_prob) if idx in best_indices[song, :k] else 0\n",
    "                \n",
    "                ## Use standard mapping to sample from the (potentially modified) probability distributions\n",
    "                batch = [[np.random.choice(\n",
    "                    np.arange(out_probs[head_idx].shape[-1]),\n",
    "                    p=out_probs[head_idx][song, i, :]\n",
    "                    )] for song in range(num_songs)]\n",
    "                token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "                \n",
    "        # Create the tokens concatenating the sampled components\n",
    "        new_tokens = np.concatenate(token_components, axis=1)\n",
    "        # Add the new tokens to the songs\n",
    "        generated_songs[:, i] = new_tokens\n",
    "\n",
    "    # If a token in a song has type of terminator, simply overwrite the rest of the song with end tokens\n",
    "    for song in range(num_songs):\n",
    "        terminator_indices = np.argwhere(generated_songs[song, :, 0] == terminator_type)\n",
    "        if len(terminator_indices) > 0:\n",
    "            first_terminator_index = terminator_indices[0,0]\n",
    "            generated_songs[song, first_terminator_index:, :] = [7] + [0]*10\n",
    "        \n",
    "    # Internally, the generated song is always SEQ_LEN - 1 long, so we cut it before returning it.\n",
    "    return generated_songs[:, :max_length, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:11<00:00, 10.90it/s]\n"
     ]
    }
   ],
   "source": [
    "out_songs = generate_songs(model, ['folk', 'nes'], max_length=128, temperature=0.9, generation_mode='top_p_sampling', top_p_start=0.9, top_p_min=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 128, 11),\n",
       " array([[[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  4, 118,  22, ...,  20,  57,  47],\n",
       "         [  4,  85,  98, ...,  20, 122,  47],\n",
       "         ...,\n",
       "         [  7,   0,   0, ...,   0,   0,   0],\n",
       "         [  7,   0,   0, ...,   0,   0,   0],\n",
       "         [  7,   0,   0, ...,   0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  6,   3,  87, ...,  10, 120,  39],\n",
       "         [  4,  79, 125, ...,   6,  44,  47],\n",
       "         ...,\n",
       "         [  7,   0,   0, ...,   0,   0,   0],\n",
       "         [  7,   0,   0, ...,   0,   0,   0],\n",
       "         [  7,   0,   0, ...,   0,   0,   0]]], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_songs.shape, out_songs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0ed98097e12b2e5cb24acca5eaecb045ae6fa1f3d168a26bde2bb15ec97be77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
