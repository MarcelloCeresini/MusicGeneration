{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:09:03.145083: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-21 01:09:03.691556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-21 01:09:05.061436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.077293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.077462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:09:05.153180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.153353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.153470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.558845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.559004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.559124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-21 01:09:05.559222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5472 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "2023-04-21 01:09:08.462617: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?,2047,11]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.492516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.492572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.546284: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.546362: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.601194: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.601259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.653031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.653093: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.703869: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.703931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.753451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.753514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.802755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.802815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.909770: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.909830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.960565: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:08.960625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:09.010557: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2023-04-21 01:09:09.010618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype int32 and shape [?]\n",
      "\t [[{{node Placeholder}}]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "import config, music_model, utils\n",
    "\n",
    "### CONFIGURATION ###\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'tf_data7dict'\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "USE_ONE_GPU = True\n",
    "\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1\n",
    "\n",
    "### MODEL CREATION ###\n",
    "\n",
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf,\n",
    "                                         num_genres=len(conf.accepted_subgenres),\n",
    "                                         use_regularization=False,\n",
    "                                         use_masking_layers=False)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf,\n",
    "                                     num_genres=len(conf.accepted_subgenres),\n",
    "                                     use_regularization=False,\n",
    "                                     use_masking_layers=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2047, 11) (4, 3)\n",
      "dict_keys(['duration', 'type', 'tempo', 'measure', 'instrument', 'pitch', 'position', 'beat', 'time_sign', 'velocity', 'key_sign'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:09:09.239455: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "## Load the dataset\n",
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7dict')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "\n",
    "## Take the first batch of the dataset and trim its sequence length to 2047\n",
    "X, y = next(dataset.take(1).as_numpy_iterator())\n",
    "X = (X[0][:,:conf.SEQ_LEN-1,:], X[1])\n",
    "y = {k: y[k][:,:conf.SEQ_LEN-1] for k in y}\n",
    "\n",
    "print(X[0].shape, X[1].shape)\n",
    "print(y.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Function to choose a style for the song\n",
    "def encode_styles(styles_array):\n",
    "    return np.stack([\n",
    "        utils.one_hot_encode_labels_nmf(style)\n",
    "        for style in styles_array\n",
    "    ], axis=0).astype(np.int8)\n",
    "\n",
    "# Example:\n",
    "styles = encode_styles(['folk', 'nes', 'maestro', 'nes'])\n",
    "print(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:09:09.922914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "transformer = model.get_layer('tfgpt2_model')\n",
    "output_layers = [\n",
    "    model.get_layer('type_scores'),\n",
    "    model.get_layer('measure_scores'),\n",
    "    model.get_layer('beat_scores'),\n",
    "    model.get_layer('position_scores'),\n",
    "    model.get_layer('duration_scores'),\n",
    "    model.get_layer('pitch_scores'),\n",
    "    model.get_layer('instrument_scores'),\n",
    "    model.get_layer('velocity_values'),\n",
    "    model.get_layer('keysign_scores'),\n",
    "    model.get_layer('timesign_scores'),\n",
    "    model.get_layer('tempo_scores')\n",
    "]\n",
    "activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "\n",
    "## Test this pipeline\n",
    "# Let's assume we need to only send the first 2 token.\n",
    "# Therefore we will build an attention mask where only the first 2 values are 1 and the others are 0\n",
    "CUR_IDX = 2\n",
    "attention_mask = np.ones((conf.GEN_BATCH_SIZE, 1+CUR_IDX), dtype=np.int8)\n",
    "padding_attention_mask = np.zeros((conf.GEN_BATCH_SIZE, conf.SEQ_LEN-1-CUR_IDX), dtype=np.int8)\n",
    "attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "preprocessed_tensors = preprocessing_model(X)\n",
    "out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                                   attention_mask=attention_mask)['last_hidden_state']\n",
    "out_scores           = [output_layers[i](out_transformer)[:,:-1,:] \n",
    "                        for i in range(len(output_layers))]\n",
    "out_probs            = [activations[i](out_scores[i]) \n",
    "                        for i in range(len(activations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5, 177, 104, 114,   5, 250,  23,   1,   2,  36,  29],\n",
       "       [  5, 158,  32,  22,  67, 149,  69,   1,   8, 138,  46],\n",
       "       [  1, 129,  12,  65,  26,  94, 109,   1,   8, 132,  31],\n",
       "       [  5, 105,  95,  15,  25, 134, 128,   1,  14,  11,  41]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample indices from the output probabilities\n",
    "token_components = []\n",
    "for head_idx in range(len(out_probs)):\n",
    "    if head_idx == 7: token_components.append(\n",
    "            np.asarray(out_probs[7][:, CUR_IDX+1, :], dtype=np.int32))\n",
    "    else:\n",
    "        batch = [[np.random.choice(\n",
    "                    np.arange(out_probs[head_idx].shape[-1]), \n",
    "                    p=np.array(out_probs[head_idx][song, CUR_IDX+1, :])\n",
    "                )] for song in range(conf.GEN_BATCH_SIZE)]\n",
    "        token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "np.concatenate(token_components, axis=1)\n",
    "\n",
    "# 2. Top-k sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Song generation function\n",
    "def generate_songs(model, style_list:List[str], max_length:int=conf.SEQ_LEN-1, \n",
    "                   terminator_type:int=7, generation_mode:str='standard_sampling', \n",
    "                   temperature:float=1.0, top_k:int=10, top_p:float=0.9):\n",
    "    \n",
    "    # Check the validity of the parameters\n",
    "    assert temperature > 0, \"Temperature must be greater than 0\"\n",
    "    assert max_length <= conf.SEQ_LEN-1, f\"The maximum length of the generated song must be less than {conf.SEQ_LEN-1}\"\n",
    "    assert generation_mode in ['standard_sampling', 'top_k_sampling', 'top_p_sampling'], \\\n",
    "        f\"Parameter 'generation_mode' must be one of the following: 'standard_sampling', 'top_k_sampling', 'top_p_sampling'\"\n",
    "\n",
    "    # Collect explicitly the number of songs to generate\n",
    "    num_songs = len(style_list)\n",
    "\n",
    "    # Separate preprocessing model, transformer and output layers in order to be able to\n",
    "    # inject the attention masks into the transformer and still use the loaded weights\n",
    "    preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "    transformer = model.get_layer('tfgpt2_model')\n",
    "    output_layers = [\n",
    "        model.get_layer('type_scores'), model.get_layer('measure_scores'), model.get_layer('beat_scores'),\n",
    "        model.get_layer('position_scores'), model.get_layer('duration_scores'), model.get_layer('pitch_scores'),\n",
    "        model.get_layer('instrument_scores'), model.get_layer('velocity_values'), model.get_layer('keysign_scores'),\n",
    "        model.get_layer('timesign_scores'), model.get_layer('tempo_scores')\n",
    "    ]\n",
    "    activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "    \n",
    "    # Create the empty song array.\n",
    "    # The first token of the songs is always the start token (0,...,0)\n",
    "    # The rest of the tensor is filled with padding of zeroes, which will be masked by the attention masks\n",
    "    generated_songs = np.zeros((num_songs, conf.SEQ_LEN-1, 11), dtype=np.int32)\n",
    "    \n",
    "    # Generate the one-hot encodings of the genres\n",
    "    styles = encode_styles(style_list)\n",
    "\n",
    "    # Start to generate the songs token by token\n",
    "    for i in trange(1, max_length-1):\n",
    "\n",
    "        # Create the attention mask (the first 2 tokens are always attended: genre and starting token)\n",
    "        attention_mask = np.ones((num_songs, 1+i), dtype=np.int8)\n",
    "        padding_attention_mask = np.zeros((num_songs, conf.SEQ_LEN-1-i), dtype=np.int8)\n",
    "        attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "        # Preprocess the songs and pass them through the transformer\n",
    "        preprocessed_tensors = preprocessing_model((generated_songs, styles))\n",
    "        out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                               attention_mask=attention_mask)['last_hidden_state']\n",
    "        # Use the output layers to generate the probabilities for the next token\n",
    "        # Output from transformer has SEQ_LEN tokens, so we trim it by removing the last one,\n",
    "        # since it's the probability of a token that's out of our bounds.\n",
    "        out_scores           = [output_layers[i](out_transformer)[:,:-1,:] / temperature\n",
    "                                for i in range(len(output_layers))]\n",
    "        out_probs            = [activations[i](out_scores[i]) \n",
    "                                for i in range(len(activations))]\n",
    "        \n",
    "        # Sample the next token from the output probabilities using the desired sampling mode:\n",
    "\n",
    "        ## 1. Standard mapping: simply sample from the probability distributions with no additional frills.\n",
    "        if generation_mode == 'standard_sampling':\n",
    "            # Sample indices from the output probabilities\n",
    "            token_components = []\n",
    "            for head_idx in range(len(out_probs)):\n",
    "                # Velocity is just a number, not a probability distribution\n",
    "                if head_idx == 7: token_components.append(\n",
    "                        np.asarray(out_probs[7][:, i+1, :], dtype=np.int32))\n",
    "                else:\n",
    "                    # For the other elements, sample an index using the prob distribution\n",
    "                    batch = [[np.random.choice(\n",
    "                                np.arange(out_probs[head_idx].shape[-1]), \n",
    "                                p=np.array(out_probs[head_idx][song, i+1, :])\n",
    "                            )] for song in range(num_songs)]\n",
    "                    token_components.append(np.asarray(batch, dtype=np.int32))\n",
    "            new_tokens = np.concatenate(token_components, axis=1)\n",
    "\n",
    "        ## 2. Top-k sampling: sample from the top-k most probable tokens\n",
    "        elif generation_mode == 'top_k_sampling':\n",
    "            raise NotImplementedError\n",
    "\n",
    "        ## 3. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "        elif generation_mode == 'top_p_sampling':\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        # Add the new tokens to the songs\n",
    "        generated_songs[:, i] = new_tokens\n",
    "\n",
    "        ## TODO: if token has type of terminator, stop sampling and simply fill the rest of the song with end tokens \n",
    "        \n",
    "    # Internally, the generated song is always SEQ_LEN - 1 long, so we cut it before returning it.\n",
    "    return generated_songs[:, :max_length, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 510/510 [00:39<00:00, 12.90it/s]\n"
     ]
    }
   ],
   "source": [
    "out_songs = generate_songs(model, ['folk'], max_length=512, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 512, 11),\n",
       " array([[[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  5, 123,  53, ...,   9, 123,  37],\n",
       "         ...,\n",
       "         [  6, 200,  85, ...,  13,  39,  34],\n",
       "         [  3, 158,  30, ...,  23,  46,  37],\n",
       "         [  2, 113,  99, ...,   8,   4,  10]]], dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_songs.shape, out_songs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ed98097e12b2e5cb24acca5eaecb045ae6fa1f3d168a26bde2bb15ec97be77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
