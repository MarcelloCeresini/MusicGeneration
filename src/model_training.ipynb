{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:46:35.724456: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 09:46:36.024806: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-11 09:46:36.058464: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-11 09:46:36.770205: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 09:46:36.770277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-11 09:46:36.770284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# MASK GPUS\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import config\n",
    "import utils\n",
    "import music_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'lmd_matched_final_2048_cut'\n",
    "\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "\n",
    "def get_model_name(use_mask: bool, use_reg: bool, use_mse_for_velocity:bool):\n",
    "    if use_mask and not use_reg:\n",
    "        model_name = 'mask_only'\n",
    "    elif use_reg and not use_mask:\n",
    "        model_name = 'reg_only'\n",
    "    elif use_reg and use_mask:\n",
    "        model_name = 'reg_and_mask'\n",
    "    else:\n",
    "        model_name = 'baseline'\n",
    "    if use_mse_for_velocity:\n",
    "        model_name += '_with_mse_vel'\n",
    "    return model_name\n",
    "\n",
    "def run_training(additional_model_name='', log_name='', model_type='GPT', \n",
    "                 use_mask=True, use_reg=True, use_mse_for_velocity=True,\n",
    "                 use_wandb=True, use_one_gpu=False, seq_len=2048, verbose=True,\n",
    "                 double_head=False):\n",
    "    \n",
    "    if verbose: print(\"Running setup...\")\n",
    "    model_name = get_model_name(use_mask, use_reg, use_mse_for_velocity)\n",
    "    \n",
    "    if verbose: print(\"\\tInstantiating and personalizing Config object...\")\n",
    "    conf = config.Config(config_string=\"single_instruments_type\", \n",
    "                         sequence_length=seq_len,\n",
    "                         root_path=ROOT_PATH, \n",
    "                         model_type=model_type,\n",
    "                         model_name=f'model_{model_type}_{model_name + additional_model_name}')\n",
    "\n",
    "    # Config object has by default the full list of accepted subgenres and works on multi-gpus\n",
    "    # If we use the small dataset\n",
    "    if USE_SMALL_GENRE_SET:\n",
    "        conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "\n",
    "    # If we need to use only the first GPU\n",
    "    if use_one_gpu:\n",
    "        conf.GPUS = tf.config.list_physical_devices('GPU')[0]\n",
    "        conf.BATCH_SIZE = 24\n",
    "        conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "        conf.num_devices = 1\n",
    "        print(f\"Using only GPU: {conf.GPUS}\")\n",
    "    \n",
    "    if verbose: print(\"\\tCreating model...\")\n",
    "    if conf.num_devices > 1:\n",
    "        print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "        with conf.training_strategy.scope():\n",
    "            model = music_model.create_model(conf, \n",
    "                                             use_masking_layers=use_mask,\n",
    "                                             use_regularization=use_reg,\n",
    "                                             use_mse_for_velocity=use_mse_for_velocity,\n",
    "                                             double_head=double_head)\n",
    "    else:\n",
    "        print(\"Using single GPU/CPU device\")\n",
    "        model = music_model.create_model(conf, \n",
    "                                         use_masking_layers=use_mask,\n",
    "                                         use_regularization=use_reg,\n",
    "                                         use_mse_for_velocity=use_mse_for_velocity,\n",
    "                                         double_head=double_head)\n",
    "    \n",
    "    if verbose: print(\"\\tSetupping Wandb logger...\")\n",
    "    if use_wandb:\n",
    "        wandb_config = {\n",
    "            'gpus': conf.num_devices,\n",
    "            'dataset': DATASET_NAME,\n",
    "            'genres': conf.accepted_subgenres,\n",
    "            'embedding_size': conf.SINGLE_EMB_SIZE,\n",
    "            'batch_size': conf.BATCH_SIZE,\n",
    "            'global_batch_size': conf.GLOBAL_BATCH_SIZE,\n",
    "            'mse_for_velocity': use_mse_for_velocity,\n",
    "            'reg_loss_scale': conf.REG_LOSS_SCALE,\n",
    "            'masking': conf.USE_MASKING,\n",
    "            'dropout_prob': conf.DROPOUT_VALUE,\n",
    "            'seq_len': conf.SEQ_LEN,\n",
    "            'token_dim': conf.TOKEN_DIM,\n",
    "            'genre_dim': conf.GENRE_DIM,\n",
    "            'attn_heads': conf.ATTENTION_HEADS,\n",
    "            'attn_blocks': conf.ATTENTION_BLOCKS,\n",
    "        }\n",
    "\n",
    "        if model_type == 'GPT':\n",
    "            wandb_config['activation_func'] = conf.DECODER_ACTIVATION_FUNCTION\n",
    "        elif model_type == 'XL':\n",
    "            wandb_config['sequence_blocks'] = conf.DIV_VAL\n",
    "            wandb_config['head_dim']  = conf.HEAD_DIM\n",
    "            wandb_config['inner_dim'] = conf.INNER_DIM\n",
    "            wandb_config['memory_length'] = conf.MEMORY_LEN\n",
    "\n",
    "        run = wandb.init(project=\"Music Generation\", entity=\"marcello-e-federico\",\n",
    "                         group=model_name, job_type='train', config=wandb_config,\n",
    "                         name=log_name if log_name != '' else None)\n",
    "    \n",
    "    if verbose: print(\"\\tObtaining dataset...\")\n",
    "    dataset_path = conf.dataset_paths[DATASET_NAME]\n",
    "    train_dataset, val_dataset, test_dataset = utils.get_dataset_splits(dataset_path, conf)\n",
    "    \n",
    "    if verbose: print(\"\\tSetupping callbacks...\")\n",
    "    callbacks = conf.MODEL_CALLBACKS\n",
    "    if use_wandb:\n",
    "        callbacks.append(WandbCallback(\n",
    "            save_model=False, save_graph=False,\n",
    "            log_weights=False\n",
    "        ))\n",
    "    \n",
    "    if verbose: print(\"Training start\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs = 100,\n",
    "        callbacks = callbacks,\n",
    "        validation_data = val_dataset,\n",
    "        # initial_epoch = initial_epoch # change if resuming from previous checkpoint\n",
    "    )\n",
    "    if verbose: print(\"Training finished\")\n",
    "    \n",
    "    if use_wandb:\n",
    "        if verbose: print(\"\\tClosing Wandb logger...\")\n",
    "        run.finish()\n",
    "        \n",
    "    if verbose: print(\"\\tClearing session...\")\n",
    "    K.clear_session()\n",
    "        \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "\n",
      "TRAINING MASK ONLY MODEL\n",
      "\n",
      "\n",
      "Running setup...\n",
      "\tInstantiating and personalizing Config object...\n",
      "Using only GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "\tCreating model...\n",
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 09:47:06.046164: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 09:47:06.721337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30970 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice cause Input \"input\" of op 'StridedSlice' expected to be not loop invariant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSetupping Wandb logger...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvolpepe\u001b[0m (\u001b[33mmarcello-e-federico\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aborghesi/persistent/MusicGeneration/src/wandb/run-20230511_094716-3gtsu5o5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation/runs/3gtsu5o5\" target=\"_blank\">revived-salad-59</a></strong> to <a href=\"https://wandb.ai/marcello-e-federico/Music%20Generation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tObtaining dataset...\n",
      "\tSetupping callbacks...\n",
      "Training start\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice cause Input \"input\" of op 'StridedSlice' expected to be not loop invariant.\n",
      "WARNING:tensorflow:Using a while_loop for converting StridedSlice cause Input \"input\" of op 'StridedSlice' expected to be not loop invariant.\n",
      " 839/2317 [=========>....................] - ETA: 1:12:02 - loss: 0.9148 - type_loss: 0.0022 - measure_loss: 0.1422 - beat_loss: 0.0371 - position_loss: 0.1142 - duration_loss: 0.1667 - pitch_loss: 0.1633 - instrument_loss: 0.1358 - velocity_loss: 1.0083e-06 - key_sign_loss: 0.0333 - time_sign_loss: 0.0158 - tempo_loss: 0.1042"
     ]
    }
   ],
   "source": [
    "# print(\"TRAINING BASELINE MODEL\\n\\n\")\n",
    "# model_baseline_mse_vel, history_baseline_mse_vel = run_training(additional_model_name='lmd_matched_2048', log_name='', model_type='GPT', \n",
    "#                                                         use_mask=False, use_reg=False, use_mse_for_velocity=True, use_wandb=True, \n",
    "#                                                         use_one_gpu=True, seq_len=2048, verbose=True)\n",
    "\n",
    "# print(\"=================================\\n\")\n",
    "# print(\"TRAINING REG ONLY MODEL\\n\\n\")    \n",
    "# model_reg_mse_vel, history_reg_mse_vel = run_training(additional_model_name='lmd_matched_2048', log_name='', model_type='GPT', \n",
    "#                                                         use_mask=False, use_reg=True, use_mse_for_velocity=True, use_wandb=True, \n",
    "#                                                         use_one_gpu=True, seq_len=2048, verbose=True)\n",
    "\n",
    "print(\"=================================\\n\")\n",
    "print(\"TRAINING MASK ONLY MODEL\\n\\n\")\n",
    "model_mask_mse_vel, history_mask_mse_vel = run_training(additional_model_name='lmd_matched_2048', log_name='', model_type='GPT', \n",
    "                                                        use_mask=True, use_reg=False, use_mse_for_velocity=True, use_wandb=True, \n",
    "                                                        use_one_gpu=True, seq_len=2048, verbose=True, double_head=False)\n",
    "\n",
    "# print(\"=================================\\n\")\n",
    "# print(\"TRAINING MASK AND REG MODEL\\n\\n\")\n",
    "# model_mask_reg_mse_vel, history_mask_reg_mse_vel = run_training(additional_model_name='lmd_matched_2048', log_name='', model_type='GPT', \n",
    "#                                                         use_mask=True, use_reg=True, use_mse_for_velocity=True, use_wandb=True, \n",
    "#                                                         use_one_gpu=True, seq_len=2048, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"TRAINING BASELINE MODEL\\n\\n\")\n",
    "# model_baseline_mse_vel, history_baseline_mse_vel = run_training(additional_model_name='_lmd_matched_2048_double_head', log_name='', model_type='GPT', \n",
    "#                                                         use_mask=False, use_reg=False, use_mse_for_velocity=True, use_wandb=True, \n",
    "#                                                         use_one_gpu=True, seq_len=2048, verbose=True, double_head=True)\n",
    "\n",
    "# print(\"=================================\\n\")\n",
    "# print(\"TRAINING REG ONLY MODEL\\n\\n\")    \n",
    "# model_reg_mse_vel, history_reg_mse_vel = run_training(additional_model_name='_lmd_matched_2048_double_head', log_name='', model_type='GPT', \n",
    "#                                                         use_mask=False, use_reg=True, use_mse_for_velocity=True, use_wandb=True, \n",
    "#                                                         use_one_gpu=True, seq_len=2048, verbose=True, double_head=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "17321a188135f2c2c768fa02a53ff8b7818a96a6473bfad36c60a386ff86beab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
