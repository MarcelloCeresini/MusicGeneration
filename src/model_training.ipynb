{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import config\n",
    "import music_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the following variables before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_MODEL_NAME = ''\n",
    "LOG_NAME = ''                 # A log name for visualization on Wandb (if left empty it will be a random name)\n",
    "\n",
    "MODEL_TYPE  = 'XL'            # or \"GPT\"\n",
    "USE_MASK    = False\n",
    "USE_REG     = True\n",
    "\n",
    "USE_WANDB   = False\n",
    "USE_ONE_GPU = False           # or False if another GPU is available\n",
    "\n",
    "USE_SMALL_GENRE_SET = True    # or False if we want to use the dataset with the full genre subset list\n",
    "DATASET_NAME = 'tf_data7dict' # or whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_MASK and not USE_REG:\n",
    "    MODEL_NAME = 'mask_only'\n",
    "elif USE_REG and not USE_MASK:\n",
    "    MODEL_NAME = 'reg_only'\n",
    "elif USE_REG and USE_MASK:\n",
    "    MODEL_NAME = 'reg_and_mask'\n",
    "else:\n",
    "    MODEL_NAME = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = config.Config(config_string=\"single_instruments_type\", \n",
    "                     root_path=ROOT_PATH, \n",
    "                     model_type=MODEL_TYPE,\n",
    "                     model_name=f'model_{MODEL_TYPE}_{MODEL_NAME + ADDITIONAL_MODEL_NAME}')\n",
    "\n",
    "# Config object has by default the full list of accepted subgenres and works on multi-gpus\n",
    "# If we use the small dataset\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = 4 if MODEL_TYPE == 'GPT' else 8\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multiple GPUs with Mirrored Strategy\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf, \n",
    "                                         use_masking_layers=USE_MASK,\n",
    "                                         use_regularization=USE_REG)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf, \n",
    "                                     use_masking_layers=USE_MASK,\n",
    "                                     use_regularization=USE_REG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wandb setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    wandb_config = {\n",
    "        'gpus': conf.num_devices,\n",
    "        'dataset': DATASET_NAME,\n",
    "        'genres': conf.accepted_subgenres,\n",
    "        'embedding_size': conf.SINGLE_EMB_SIZE,\n",
    "        'batch_size': conf.BATCH_SIZE,\n",
    "        'global_batch_size': conf.GLOBAL_BATCH_SIZE,\n",
    "        'reg_loss_scale': conf.REG_LOSS_SCALE,\n",
    "        'masking': conf.USE_MASKING,\n",
    "        'dropout_prob': conf.DROPOUT_VALUE,\n",
    "        'seq_len': conf.SEQ_LEN,\n",
    "        'token_dim': conf.TOKEN_DIM,\n",
    "        'genre_dim': conf.GENRE_DIM,\n",
    "        'attn_heads': conf.ATTENTION_HEADS,\n",
    "        'attn_blocks': conf.ATTENTION_BLOCKS,\n",
    "    }\n",
    "\n",
    "    if MODEL_TYPE == 'GPT':\n",
    "        wandb_config['activation_func'] = conf.DECODER_ACTIVATION_FUNCTION\n",
    "    elif MODEL_TYPE == 'XL':\n",
    "        wandb_config['sequence_blocks'] = conf.DIV_VAL\n",
    "        wandb_config['head_dim']  = conf.HEAD_DIM\n",
    "        wandb_config['inner_dim'] = conf.INNER_DIM\n",
    "        wandb_config['memory_length'] = conf.MEMORY_LEN\n",
    "\n",
    "    run = wandb.init(project=\"Music Generation\", entity=\"marcello-e-federico\",\n",
    "                     group=MODEL_NAME, job_type='train', config=wandb_config,\n",
    "                     name=LOG_NAME if LOG_NAME != '' else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.load(conf.tf_data7dict_path).\\\n",
    "            batch(conf.GLOBAL_BATCH_SIZE).\\\n",
    "            cache().\\\n",
    "            shuffle(conf.SHUFFLE_SIZE).\\\n",
    "            prefetch(conf.PREFETCH_SIZE)\n",
    "\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "dataset = dataset.with_options(options)\n",
    "\n",
    "# TODO: Create a separate, fixed validation and test set\n",
    "train_dataset = dataset.skip(int(len(dataset)/5))\n",
    "val_dataset   = dataset.take(int(len(dataset)/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = conf.MODEL_CALLBACKS\n",
    "if USE_WANDB:\n",
    "    callbacks.append(WandbCallback(\n",
    "        save_model=False, save_graph=False,\n",
    "        log_weights=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 500,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = val_dataset,\n",
    "    # initial_epoch = initial_epoch # change if resuming from previous checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_WANDB:\n",
    "    run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai3i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "17321a188135f2c2c768fa02a53ff8b7818a96a6473bfad36c60a386ff86beab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
