{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QFJBJsxdptr0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import muspy\n",
        "from tqdm import tqdm\n",
        "import config\n",
        "import utils\n",
        "\n",
        "config_string = \"standard\"\n",
        "\n",
        "conf = config.Config(config_string)\n",
        "\n",
        "# muspy.download_musescore_soundfont()\n",
        "\n",
        "\n",
        "N_CPUS = os.cpu_count()\n",
        "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVGWCb8ptr5"
      },
      "source": [
        "# Warning, ~ 10 hours required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pFO8spMhptr9",
        "outputId": "5b0bc28b-4d90-4c97-df85-068266d081ef"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = os.path.join(ROOT_PATH, \"data/lmd/\")\n",
        "\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    os.mkdir(DATASET_PATH)\n",
        "    \n",
        "if len(os.listdir(DATASET_PATH)) == 0:\n",
        "    lmd = muspy.LakhMIDIDataset(DATASET_PATH, download_and_extract=True, convert=True, n_jobs=N_CPUS)\n",
        "else:\n",
        "    lmd = muspy.LakhMIDIDataset(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPWbZwBgptr-",
        "outputId": "52a2978a-b9dc-4e2f-efc6-f211d835c5a7"
      },
      "outputs": [],
      "source": [
        "# print(len(lmd[1]))\n",
        "# print(np.unique(list(track.program for track in lmd[1].tracks)))\n",
        "for i in range(10000):\n",
        "    if len(k_sings := lmd[i].key_signatures) > 1: \n",
        "        print(k_sings)\n",
        "\n",
        "# print(i)\n",
        "# print(lmd[i])\n",
        "\n",
        "# muspy.write_audio(os.path.join(ROOT_PATH, \"data/songs\"), lmd[19])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug_q_wM_ptsA",
        "outputId": "3f3de27a-03fc-438a-fc76-0457926e0e20"
      },
      "outputs": [],
      "source": [
        "((time_s.numerator, time_s.denominator) for time_s in lmd[7].time_signatures)\n",
        "\n",
        "for i in range(100):\n",
        "    print(\"----\")\n",
        "    for tims_s in lmd[i].time_signatures:\n",
        "        print((tims_s.numerator, tims_s.denominator))\n",
        "    \n",
        "# time_signatures = np.unique(((time_s.numerator, time_s.denominator) for time_s in lmd[7].time_signatures)) \n",
        "# time_signatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Music(metadata=Metadata(schema_version='0.2', title='Perspection (Solar Scape Remix)', source_filename='00000ec8a66b6bd2ef809b0443eeae41.mid', source_format='midi'), resolution=480, tempos=[Tempo(time=0, qpm=148.000148000148)], key_signatures=[KeySignature(time=0, root=0, mode='major')], time_signatures=[TimeSignature(time=0, numerator=4, denominator=4)], tracks=[Track(program=0, is_drum=False, notes=[Note(time=0, pitch=78, duration=120, velocity=127), Note(time=120, pitch=66, duration=120, velocity=127), Note(time=240, pitch=82, duration=120, velocity=127), ...])])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lmd[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QigYOSOuptsC",
        "outputId": "2b797967-cdd5-4300-bca7-d1f267174f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Tempo(time=0, qpm=148.000148000148)]\n",
            "[KeySignature(time=0, root=0, mode='major')]\n",
            "[TimeSignature(time=0, numerator=4, denominator=4)]\n"
          ]
        }
      ],
      "source": [
        "print(lmd[0].tempos)\n",
        "print(lmd[0].key_signatures)\n",
        "print(lmd[0].time_signatures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What are annotations???\n",
        "https://salu133445.github.io/muspy/doc/muspy.html#muspy.Annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Annotation(time=482, annotation={'number': 121, 'value': 0}, group='control_change'),\n",
              " Annotation(time=486, annotation={'number': 10, 'value': 64}, group='control_change'),\n",
              " Annotation(time=490, annotation={'number': 93, 'value': 56}, group='control_change'),\n",
              " Annotation(time=493, annotation={'number': 91, 'value': 0}, group='control_change'),\n",
              " Annotation(time=497, annotation={'number': 11, 'value': 127}, group='control_change'),\n",
              " Annotation(time=502, annotation={'number': 7, 'value': 100}, group='control_change'),\n",
              " Annotation(time=510, annotation={'number': 0, 'value': 0}, group='control_change')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lmd[3].tracks[0].annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 9\n",
            "4 4\n",
            "6 8\n",
            "8 8\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    for j, track in enumerate(lmd[i].tracks):\n",
        "        if track.is_drum:\n",
        "            print(i, j)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Track(program=0, is_drum=True, notes=[Note(time=18480, pitch=40, duration=1, velocity=119), Note(time=18700, pitch=30, duration=156, velocity=93), Note(time=18720, pitch=40, duration=1, velocity=127), ...], annotations=[Annotation(time=806, annotation={'number': 121, 'value': 0}, group='control_change'), Annotation(time=810, annotation={'number': 93, 'value': 10}, group='control_change'), Annotation(time=813, annotation={'number': 91, 'value': 82}, group='control_change'), ...])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lmd[3].tracks[9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{3, 36, 40, 41, 42, 45, 46, 47, 48, 49}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(note.pitch for note in lmd[4].tracks[4].notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Note(time=18480, pitch=40, duration=1, velocity=119)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lmd[3].tracks[9].notes[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2.64000e+03 8.80000e+01 1.19200e+03 6.50000e+01]\n",
            " [3.84000e+03 6.70000e+01 1.91600e+03 9.30000e+01]\n",
            " [3.84000e+03 6.30000e+01 5.96000e+02 1.20000e+02]\n",
            " ...\n",
            " [1.57443e+05 5.50000e+01 1.91600e+03 8.10000e+01]\n",
            " [1.57463e+05 5.80000e+01 1.91600e+03 7.60000e+01]\n",
            " [1.57483e+05 6.30000e+01 1.91600e+03 1.11000e+02]]\n"
          ]
        }
      ],
      "source": [
        "song = lmd[3]\n",
        "notes = np.zeros((\n",
        "    np.sum([len(track) for track in song.tracks]), \n",
        "    4\n",
        "))\n",
        "\n",
        "i = 0\n",
        "for track in song.tracks:\n",
        "    if track.is_drum:\n",
        "        for note in track.notes:\n",
        "            notes[i, 0] = note.time\n",
        "            notes[i, 1] = note.pitch + 128\n",
        "            notes[i, 2] = note.duration\n",
        "            notes[i, 3] = note.velocity\n",
        "            i+=1\n",
        "    else:\n",
        "        for note in track.notes:\n",
        "            notes[i, 0] = note.time\n",
        "            notes[i, 1] = note.pitch\n",
        "            notes[i, 2] = note.duration\n",
        "            notes[i, 3] = note.velocity\n",
        "            i+=1\n",
        "\n",
        "# notes = sorted(notes, key = lambda x: x[0])\n",
        "notes = notes[notes[:,0].argsort()]\n",
        "print(notes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw-8FZCBqH-W"
      },
      "outputs": [],
      "source": [
        "def transform_representation(song: muspy.music.Music, config: config.Config, verbose=0):\n",
        "\n",
        "    '''\n",
        "    This function accepts as input a song in the muspy format and transforms it in a series of tuples written in the following way\n",
        "\n",
        "                            Description                                                     Interval                                                Possible values\n",
        "    (\n",
        "        type,               # see below -->                                                 [0, 7] -->                                              8\n",
        "        measure,            # index of the measure inside the song in interval -->          [0, last_measure] -->                                   512?\n",
        "        beat,               # index of beat inside measure -->                              [0, numerator of time_signature] -->                    ??\n",
        "        position,           # index with 1/64 beat length granularity -->                   [0, 63/64] -->                                          64\n",
        "        duration,           # hierarchical structure? -->                                   ??? better to specify after dataset exploration                                  \n",
        "        pitch,              # height of pitch (128) + drums (another 128) -->               [0, 255] -->                                            256\n",
        "        instrument_type,    # 128 instrument types + 1 for drums -->                        [0, 128] -->                                            129\n",
        "        n_instrument,       # same instrument twice in the song for multiple voices -->     [0, 7??] -->                                            8\n",
        "        velocity,           # amplitude of note, strength of play -->                       [0, 127] -->                                            128\n",
        "        key_sign,           # [0,11] (all possible notes) and [maj,min] -->                 [0, 23] -->                                             24\n",
        "        time_sign,          # denominator pow(2) in [1,64] and numerator int in [0,128] --> ??? better to specify after dataset exploration\n",
        "        tempo,              # qpm, geometric progression from 16 to 256 -->                 [0, 48] -->                                             49\n",
        "    )\n",
        "\n",
        "    type:\n",
        "        0: start of song\n",
        "        1: new instrument\n",
        "        2: start of events\n",
        "        3: note\n",
        "        4: key_signature change event\n",
        "        5: time_signature change event\n",
        "        6: tempo change event\n",
        "        7: end of song\n",
        "\n",
        "\n",
        "    if type = 0 --> all values 0\n",
        "    if type = 1 --> only instrument_type must be specified (and n_instrument is 1 bigger than the previous identical instrument defined) (other values are 0)\n",
        "    if type = 2 --> all values 0\n",
        "\n",
        "    then, before ANY type = 3, MUST FOLLOW at least one of each:\n",
        "        type = 4 --> only key_sign (other values are 0 except measure)\n",
        "        type = 5 --> only time_sign (other values are 0 except measure)\n",
        "        type = 6 --> only tempo (other values are 0 except measure)\n",
        "\n",
        "    if type = 3 --> all values are full, and key_sign, time_sign and tempo are identical to the last 4, 5 or 6 respectively\n",
        "    if type = 7 --> all values 0, end of the representation\n",
        "\n",
        "\n",
        "    '''\n",
        "    \n",
        "    # list of all notes/events\n",
        "    final_song = []\n",
        "\n",
        "    events = []\n",
        "\n",
        "    # record time signatures (the first is the \"current\" and influences notes immediately following, the others will influence \n",
        "    # the song later and are appended into \"events\", where time_sign, key_sign and tempo changes are all stored)\n",
        "\n",
        "    for i, key_sign in enumerate(song.key_signatures):\n",
        "        if i == 0:\n",
        "            current_key_sign = (key_sign.key, key_sign.major_minor)\n",
        "            final_song.append(utils.key_sign_repr(current_key_sign, measure = 0, config = conf))\n",
        "        else:\n",
        "            events.append((key_sign.time, \"key_sign\", key_sign.key, key_sign.major_minor))\n",
        "\n",
        "    for i, time_sign in enumerate(song.time_signatures):\n",
        "        if i == 0:\n",
        "            current_time_sign = (time_sign.numerator, time_sign.denominator)\n",
        "            final_song.append(utils.time_sign_repr(current_time_sign, measure = 0, config = conf))\n",
        "        else:\n",
        "            events.append((time_sign.time, \"time_sign\", time_sign.numerator, time_sign.denominator))\n",
        "\n",
        "    for i, tempo in enumerate(song.beats):\n",
        "        if i == 0:\n",
        "            current_tempo = tempo.qpm\n",
        "            final_song.append(utils.tempo_repr(current_tempo, measure = 0, config = conf))\n",
        "        else:\n",
        "            events.append((tempo.time, \"tempo\", tempo.qpm))\n",
        "\n",
        "    # sort events by timestep\n",
        "    events.sort(key = lambda x: x[0])\n",
        "\n",
        "    # get all the notes from the song\n",
        "    notes = np.zeros((\n",
        "        np.sum([len(track) for track in song.tracks]), \n",
        "        4\n",
        "    ))\n",
        "    \n",
        "    i = 0\n",
        "    for track in song.tracks:\n",
        "        if track.is_drum:\n",
        "            for note in track.notes:\n",
        "                notes[i, 0] = note.time\n",
        "                notes[i, 1] = note.pitch + 128\n",
        "                notes[i, 2] = note.duration\n",
        "                notes[i, 3] = note.velocity\n",
        "                i+=1\n",
        "        else:\n",
        "            for note in track.notes:\n",
        "                notes[i, 0] = note.time\n",
        "                notes[i, 1] = note.pitch\n",
        "                notes[i, 2] = note.duration\n",
        "                notes[i, 3] = note.velocity\n",
        "                i+=1\n",
        "\n",
        "    # sort them by the 0th column, the time\n",
        "    notes = notes[notes[:,0].argsort()]\n",
        "\n",
        "    resolution = song.resolution\n",
        "\n",
        "    # n° of timesteps for each measure = resolution * denominator of time_sign\n",
        "    current_measure_length = current_time_sign[1] * resolution                      \n",
        "    \n",
        "    assert current_measure_length % current_time_sign[0] == 0, \"It doesn't work --> the resolution means something else\"\n",
        "\n",
        "    # n° of timesteps for each beat = measure / numerator of time_sign\n",
        "    current_beat_length = current_measure_length / current_time_sign[0]                     \n",
        "\n",
        "    current_settings = {\n",
        "        \"key_sign\": current_key_sign,       # tuple with (key, major/minor)\n",
        "        \"time_sign\": current_time_sign,     # tuple (nominator, denominator)\n",
        "        \"tempo\": current_tempo,             # float\n",
        "        \"resolution\": resolution,           # float\n",
        "        \"measure\": current_measure_length,  # float\n",
        "        \"beat\": current_beat_length         # float\n",
        "    }\n",
        "\n",
        "\n",
        "    # remember at which note we stopped changing representation\n",
        "    current_note_idx = 0\n",
        "\n",
        "    # also remember the number of the measure\n",
        "    current_measure_index = 0\n",
        "\n",
        "    # t = timestep --> differs for each song based on the resolution\n",
        "    # remember also the timestep at which we stopped\n",
        "    current_time = 0\n",
        "\n",
        "    while i < len(events):\n",
        "        # add notes in between events --> the current configuration is important to define to which measure/beat they belong to\n",
        "        event = events[i]\n",
        "        # the dataset is not clean, sometimes it happens that the same event is repeated twice or more --> we want to make changes only when a NEW event occurs\n",
        "        flag_new_event = False\n",
        "        new_settings = current_settings\n",
        "        \n",
        "        if event[1] == \"key_sign\":\n",
        "            if event[2] != current_settings[\"key_sign\"][0] and event[3] != current_settings[\"key_sign\"][1]:\n",
        "                new_settings[\"key_sign\"] = (event[2], event[3]) # numerator, denominator\n",
        "                new_settings[\"measure\"] = event[3] * resolution\n",
        "                new_settings[\"beat\"] = new_settings[\"measure\"] / event[2]\n",
        "\n",
        "                tmp = utils.key_sign_repr(new_settings[\"key_sign\"])\n",
        "                flag_new_event = True\n",
        "\n",
        "        if event[1] == \"time_sign\":\n",
        "            if event[2] != current_settings[\"time_sign\"][0] and event[3] != current_settings[\"time_sign\"][1]:\n",
        "                new_settings[\"time_sign\"] = (event[2], event[3]) # note, major/minor\n",
        "                tmp = utils.time_sign_repr(new_settings[\"time_sign\"])\n",
        "                flag_new_event = True\n",
        "        \n",
        "        if event[1] == \"tempo\":\n",
        "            if event[2] != current_settings[\"tempo\"]:\n",
        "                new_settings[\"time_sign\"] = event[2] # qpm\n",
        "                tmp = utils.tempo_repr(new_settings[\"time_sign\"])\n",
        "                flag_new_event = True\n",
        "\n",
        "\n",
        "        if flag_new_event:\n",
        "            \n",
        "            assert (delta_t := (event[0]-t) % current_measure_length) == 0, \"The MIDI or the algorithm are wrong, events should happen only at the beginning of measures\"\n",
        "\n",
        "            # if the event happens in the middle of a beat because midi is \"wrong\" --> move the event to the beginning of THAT measure (not the following one)\n",
        "            time_interval = current_time - (event[0] - delta_t)\n",
        "\n",
        "            # shouldn't do anything if there are no notes between current time and t+delta_t\n",
        "            final_song, current_measure_index = utils.add_notes( \n",
        "                final_song,\n",
        "                current_settings, \n",
        "                current_time,\n",
        "                current_measure_index,\n",
        "                time_interval,\n",
        "                [notes],\n",
        "                conf\n",
        "            )\n",
        "\n",
        "            t = t + \n",
        "            \n",
        "            current_settings = new_settings\n",
        "\n",
        "        final_song.append(tmp)\n",
        "\n",
        "        i+=1\n",
        "\n",
        "\n",
        "    final_song, _ = add_notes(current_settings, current_note_idx, song_finish) # should append every note between current note and note with timestep \"song_finish\", should return index of last note added \n",
        "\n",
        "\n",
        "    next_event = \n",
        "\n",
        "    current_measure_length = resolution * \n",
        "\n",
        "\n",
        "    time_signatures = np.unique(list((time_s.numerator, time_s.denominator) for time_s in lmd[i].time_signatures)) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u277Y0l4ptsC",
        "outputId": "998cc900-df89-4e92-c2d6-aa4c0c9b4583"
      },
      "outputs": [],
      "source": [
        "stats = {\n",
        "    \"n_tracks\" : np.zeros(1000),            # how many instruments are playing in a song (can also be 2 of the same instrument)\n",
        "    \"programs\" : np.zeros(128),             # which type of instrument\n",
        "    \"velocity\" : np.zeros(128),             # how loud (0-127)\n",
        "    \"durations\": np.zeros(100000),          # how many quarters does the note last(?)\n",
        "    \"tempos\": {},                           # how fast is the song in qpm (quarters per minute) --> can be non integer\n",
        "    \"time_signatures\": {},                  # 4/4 or 3/4 etc... store it as a dict\n",
        "    \"key_signatures\": np.zeros(100),        # which is the main key\n",
        "    \"key_mode\": {\"major\": 0 , \"minor\":0}    # if main key is major or minor\n",
        "}\n",
        "\n",
        "for song in tqdm(lmd):\n",
        "    stats[\"n_tracks\"][len(song)] += 1                                                   # how many tracks are in the song (tracks = different \"instrument voices\" but could be 4 pianos)\n",
        "    \n",
        "    programs = np.unique(list(track.program for track in song.tracks))                  # how many different instruments and which\n",
        "    for program in programs:\n",
        "        stats[\"programs\"][program] += 1\n",
        "\n",
        "             \n",
        "    tempos = np.unique(list(tempo.qpm for tempo in lmd[i].tempos))                      # stats on tempos (maybe not useful, but what do we do if tempo changes mid song?)\n",
        "\n",
        "    for tempo in tempos:\n",
        "        if tempo in stats[\"tempos\"].keys():\n",
        "            stats[\"tempos\"][tempo] += 1\n",
        "        else:\n",
        "            stats[\"tempos\"][tempo] = 1\n",
        "\n",
        "\n",
        "                                                                                        # stats on time_signatures --> need to know which exist / are used to create possible tokens\n",
        "    time_signatures = np.unique(list((time_s.numerator, time_s.denominator) for time_s in lmd[i].time_signatures)) \n",
        "\n",
        "    for time_s in time_signatures:\n",
        "        if time_s in stats[\"time_signatures\"].keys():\n",
        "            stats[\"time_signatures\"][time_s] += 1\n",
        "        else:\n",
        "            stats[\"time_signatures\"][time_s] = 1\n",
        "\n",
        "\n",
        "    key_signatures = song.key_signatures\n",
        "\n",
        "\n",
        "    notes = np.concatenate([track.notes for track in song.tracks if len(track) > 0])    # stats on notes\n",
        "    \n",
        "    for duration in np.unique(list(note.duration for note in notes)):\n",
        "        stats[\"durations\"][duration] += 1\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b467f7883de7543dc02b11b94c328ac6855d20cf7509fc2662733d93501208eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
