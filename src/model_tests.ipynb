{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PjBIrC7GaASB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:23.734772: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 18:14:23.851201: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-26 18:14:23.882939: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 18:14:24.447294: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:14:24.447350: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:14:24.447357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsKMkpyqiQH"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:25.498247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:14:26.588167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30970 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-11-26 18:14:26.588759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30970 MB memory:  -> device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urmU6Nwaq9_H"
   },
   "source": [
    "Decoder creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "35ZXAZOJZ21a"
   },
   "outputs": [],
   "source": [
    "decoder = conf.get_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LF5x9H8qlI3"
   },
   "source": [
    "Testing the decoder on random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj4Yk5fmkxl8",
    "outputId": "0ba9446e-9c3e-46ac-c1ca-e93a662f306b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': tf.ones((conf.BATCH_SIZE, conf.SEQ_LEN, conf.TOKEN_DIM))})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edh1BIX-qv4c"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from disk and process it (batching, shuffling, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IygWWia1t67e",
    "outputId": "b9cd2ffd-644b-4669-9d60-3436f10a1b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 6143, 11), dtype=tf.uint8, name=None), TensorSpec(shape=(None, 3), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGi_Mo6rjXuC",
    "outputId": "89e8ab0a-3567-4007-ceb9-fdc41bbebc67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6143, 11) (12, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:31:55.627353: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.as_numpy_iterator())\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DFjF1yHq7nk"
   },
   "source": [
    "# Embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs need to be encoded by some embedding layer (a specific embedding layer for each token type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Uzpl4levsL71"
   },
   "outputs": [],
   "source": [
    "embedding_layers = [\n",
    "    # Type embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['type'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Measure embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Beat embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Position embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['position'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Duration embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Pitch embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Instrument embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Velocity embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Key sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Time sign embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN),\n",
    "    # Tempo embedding\n",
    "    tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the embedding layers on our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pdHuYpJ76lrL"
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in tf.range(X.shape[2]):\n",
    "    outputs.append(embedding_layers[i](X[:, : ,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to encode the genre using some layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_embedding_module = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(conf.SINGLE_EMB_SIZE, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(conf.GENRE_DIM, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_embedding = genre_embedding_module(y)\n",
    "genre_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJHY9TrIrJZw"
   },
   "source": [
    "## Embedding concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate the output embeddings into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciA8DOxC62Gh",
    "outputId": "8f8e81db-9e93-4f29-f7c7-07fdb249e81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6143, 704])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types_concat_layer = tf.keras.layers.Concatenate(axis=2)\n",
    "concat_outputs = types_concat_layer(outputs)\n",
    "concat_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to resize them into a known dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmamU5FRYXj",
    "outputId": "3a77a77d-c7fa-4acb-e34c-ad6118389bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6143, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer = tf.keras.layers.Dense(conf.TOKEN_DIM)\n",
    "encoding = dense_layer(concat_outputs)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to preprend the genre embedding token to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_concat_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "final_sequence = sequence_concat_layer([genre_embedding[:, np.newaxis, :], encoding])\n",
    "final_sequence.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rnls1ffVrRED"
   },
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add positional encodings to encode which is the position of each token in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "E3J8TF6kuPL3"
   },
   "outputs": [],
   "source": [
    "positional_encoding_matrix = conf.get_positional_embedding_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9gJp6amvZNw"
   },
   "source": [
    "In transformers, it is common to add the positional embedding to the elements embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb9HQ-0BSKGq",
    "outputId": "99e733a6-6334-47eb-b67b-2a35068c54dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_layer = tf.keras.layers.Add()\n",
    "positional_encoding = tf.repeat(positional_encoding_matrix[np.newaxis, :, :], tf.constant(conf.BATCH_SIZE), axis=0)\n",
    "final_encoding = sum_layer([final_sequence, positional_encoding])\n",
    "final_encoding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AFqwicyt7o"
   },
   "source": [
    "# Output management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPx3E2fhTVZz",
    "outputId": "a84ef775-9fab-497d-8460-ef97e1c63681"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12, 6144, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = decoder({'inputs_embeds': final_encoding})\n",
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HblbvOUy_RT"
   },
   "source": [
    "We need a dense + softmax layer for each of the tokens for trying to reconstruct the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QNCtfIZAy0oE"
   },
   "outputs": [],
   "source": [
    "output_dense_layers = [\n",
    "    # Type\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['type'], activation='softmax'),\n",
    "    # Measure\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['measure'], activation='softmax'),\n",
    "    # Beat\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['beat'], activation='softmax'),\n",
    "    # Position\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['position'], activation='softmax'),\n",
    "    # Duration\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['duration'], activation='softmax'),\n",
    "    # Pitch\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'], activation='softmax'),\n",
    "    # Instrument\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], activation='softmax'),\n",
    "    # Velocity\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'], activation='softmax'),\n",
    "    # Key sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'], activation='softmax'),\n",
    "    # Time sign\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'], activation='softmax'),\n",
    "    # Tempo\n",
    "    tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'], activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4yR5-mn0RKj",
    "outputId": "1111ef2f-150d-4422-a7b3-364ac8ffa2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6144, 8)\n",
      "(12, 6144, 256)\n",
      "(12, 6144, 131)\n",
      "(12, 6144, 128)\n",
      "(12, 6144, 136)\n",
      "(12, 6144, 256)\n",
      "(12, 6144, 129)\n",
      "(12, 6144, 128)\n",
      "(12, 6144, 25)\n",
      "(12, 6144, 153)\n",
      "(12, 6144, 49)\n"
     ]
    }
   ],
   "source": [
    "out_scores = [output_dense_layers[i](output['last_hidden_state']) \n",
    "              for i in range(len(output_dense_layers))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(out_scores[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eP3itCXL2usl"
   },
   "source": [
    "## Groundtruth vectors definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VKq9Gw71Pph",
    "outputId": "a37be808-9177-4a44-c7d6-378daae758ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n",
      "(12, 6143)\n"
     ]
    }
   ],
   "source": [
    "gt_vectors = [X[:,:,i] for i in range(len(out_scores))]\n",
    "\n",
    "for i in range(len(out_scores)):\n",
    "    print(gt_vectors[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0ed_yLa21HU"
   },
   "source": [
    " ## Loss definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple sparse categorical crossentropy loss function. The two distributions we are comparing are the input sequence (so we ignore the genre embedding token representation) and the output sequence up to the last token representation (`output[:-1]`)\n",
    "- Note: can we use regularizers or other kinds of constraint enforcing methods for some of the fields? Like, we know that regarding the type field of events there is a strict order to follow (start of song, start of events, ..., notes and end of song). Can we enforce this structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ExZcplE2t2N",
    "outputId": "3cebe8e0-87bb-49d4-bb36-3c0281ea8980"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=3.624619>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1048756>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.639281>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.1507883>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.737446>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3642745>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.920309>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.8808045>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4.109704>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.3772664>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.1257977>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "losses = []\n",
    "for i in range(len(out_scores)):\n",
    "    losses.append(loss_function(gt_vectors[i], out_scores[i][:, :-1, :]))\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To these loss terms we can add some regularization terms that can help the model produce a grammatically correct sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "types = gt_vectors[0]\n",
    "max_pred_types = tf.argmax(out_scores[0], axis=2) # 6, 6144\n",
    "# Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "keys_tensor = tf.range(TYPE_RANGE, dtype=tf.int32)\n",
    "vals_tensor = tf.constant([0,1,2,3,3,3,3,4], dtype=tf.int32)\n",
    "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor), default_value=-1)\n",
    "consecutive_gt_types   = table.lookup(tf.cast(types, tf.int32))\n",
    "consecutive_pred_types = table.lookup(tf.cast(max_pred_types, tf.int32))\n",
    "# Note: we assume that after token token type 7 all following token types are 7s\n",
    "differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=5554>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1567>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some constraint to pose for regularization\n",
    "reg_term_1 = tf.reduce_sum(tf.math.maximum(0, -differences))                           # Difference between one element's type and the next is >= 0\n",
    "reg_term_2 = tf.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))    # Difference between one element's type and the next is < 1\n",
    "\n",
    "reg_term_1, reg_term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=67.156166>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REG_SCALER = 0.001\n",
    "\n",
    "total_loss = tf.reduce_sum(losses) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_1, tf.float32) + \\\n",
    "             REG_SCALER * tf.cast(reg_term_2, tf.float32)\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahyobawI6NNd"
   },
   "source": [
    "When defining the whole Keras model for training, we can set up multiple outputs and give different weights for the multiple losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and define everything that this model does into a complete callable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 19:01:56.645948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 19:01:56.793264: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-26 19:01:56.826518: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 19:01:57.426598: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 19:01:57.426679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 19:01:57.426688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/aborghesi/persistent/MusicGeneration/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 19:01:58.457744: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 19:01:59.532320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30487 MB memory:  -> device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-11-26 19:01:59.532862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30487 MB memory:  -> device: 1, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Config, TFGPT2Model\n",
    "\n",
    "from config import Config\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "# Custom intermediate layer for allowing types transformation (no parameters to be learnt)\n",
    "class SubsequentTypeTransformationLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SubsequentTypeTransformationLayer, self).__init__()\n",
    "        # Use a StaticHashTable to map values to their consecutive version within Tensorflow\n",
    "        self.keys_tensor = tf.range(conf.INPUT_RANGES['type'])\n",
    "        self.vals_tensor = tf.constant([0,1,2,3,3,3,3,4])\n",
    "        self.table = tf.lookup.StaticHashTable(\n",
    "            tf.lookup.KeyValueTensorInitializer(self.keys_tensor, self.vals_tensor), \n",
    "            default_value=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.table.lookup(inputs)\n",
    "\n",
    "# Model creation function (to be called within a scope in case of MultiGPU training)\n",
    "def create_model(input_shape=(conf.SEQ_LEN-1, len(conf.INPUT_RANGES)), num_genres=len(conf.accepted_subgenres), \n",
    "                 use_regularization=True, reg_loss_scale=conf.REG_LOSS_SCALE):\n",
    "    \n",
    "    # Get input shapes\n",
    "    seq_len = input_shape[0]\n",
    "    events_elements = input_shape[1]\n",
    "    \n",
    "    # Instantiate transformer decoder (n_emb % n_head must be 0)\n",
    "    decoder = conf.get_decoder()\n",
    "    \n",
    "    # Define inputs\n",
    "    songs  = tf.keras.Input(shape=input_shape, name='songs',  dtype=tf.int32)\n",
    "    genres = tf.keras.Input(shape=num_genres , name='genres', dtype=tf.float32)\n",
    "    \n",
    "    # Define loss\n",
    "    loss_function = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    subsequent_type_transform_layer = SubsequentTypeTransformationLayer()\n",
    "    reg_scaler = tf.constant(reg_loss_scale, dtype=tf.float32)\n",
    "    \n",
    "    # Embedding layers\n",
    "    embedding_layers = [\n",
    "        # Type embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['type'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='type_embeddings'),\n",
    "        # Measure embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['measure'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='measure_embeddings'),\n",
    "        # Beat embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['beat'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='beat_embeddings'),\n",
    "        # Position embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['position'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='position_embeddings'),\n",
    "        # Duration embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['duration'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='duration_embeddings'),\n",
    "        # Pitch embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['pitch'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='pitch_embeddings'),\n",
    "        # Instrument embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['instrument'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='instrument_embeddings'),\n",
    "        # Velocity embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['velocity'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='velocity_embeddings'),\n",
    "        # Key sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['key_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='key_sign_embeddings'),\n",
    "        # Time sign embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['time_sign'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='time_sign_embeddings'),\n",
    "        # Tempo embedding\n",
    "        tf.keras.layers.Embedding(conf.INPUT_RANGES['tempo'], conf.SINGLE_EMB_SIZE, input_length=conf.SEQ_LEN, name='tempo_embeddings')\n",
    "    ]\n",
    "    \n",
    "    genre_embedding_layer = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(conf.GENRE_DIM)\n",
    "    ], name='genre_embedding')\n",
    "    \n",
    "    # Input processing layers\n",
    "    input_concat_layer         = tf.keras.layers.Concatenate(axis=2)\n",
    "    sequence_concat_layer      = tf.keras.layers.Concatenate(axis=1)\n",
    "    encoding_processing_layer  = tf.keras.layers.Dense(conf.TOKEN_DIM, name='encoding_processing')\n",
    "    \n",
    "    # Positional encoding\n",
    "    positional_encoding_matrix = conf.get_positional_embedding_matrix()\n",
    "    positional_encoding        = tf.repeat(positional_encoding_matrix[tf.newaxis, :, :], tf.shape(songs)[0], axis=0)\n",
    "    sum_layer                  = tf.keras.layers.Add(name='final_encoding')\n",
    "\n",
    "    # Output layers\n",
    "    output_dense_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['type'], name='type_scores'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['measure'], name='measure_scores'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['beat'], name='beat_scores'),\n",
    "        # Position\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['position'], name='position_scores'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['duration'], name='duration_scores'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['pitch'], name='pitch_scores'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['instrument'], name='instrument_scores'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['velocity'], name='velocity_scores'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['key_sign'], name='keysign_scores'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['time_sign'], name='timesign_scores'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Dense(conf.INPUT_RANGES['tempo'], name='tempo_scores')\n",
    "    ]\n",
    "    \n",
    "    output_probs_layers = [\n",
    "        # Type\n",
    "        tf.keras.layers.Softmax(name='type_probabilities'),\n",
    "        # Measure\n",
    "        tf.keras.layers.Softmax(name='measure_probabilities'),\n",
    "        # Beat\n",
    "        tf.keras.layers.Softmax(name='beat_probabilities'),\n",
    "        # Position\n",
    "        tf.keras.layers.Softmax(name='position_probabilities'),\n",
    "        # Duration\n",
    "        tf.keras.layers.Softmax(name='duration_probabilities'),\n",
    "        # Pitch\n",
    "        tf.keras.layers.Softmax(name='pitch_probabilities'),\n",
    "        # Instrument\n",
    "        tf.keras.layers.Softmax(name='instrument_probabilities'),\n",
    "        # Velocity\n",
    "        tf.keras.layers.Softmax(name='velocity_probabilities'),\n",
    "        # Key sign\n",
    "        tf.keras.layers.Softmax(name='keysign_probabilities'),\n",
    "        # Time sign\n",
    "        tf.keras.layers.Softmax(name='timesign_probabilities'),\n",
    "        # Tempo\n",
    "        tf.keras.layers.Softmax(name='tempo_probabilities')\n",
    "    ]\n",
    "    \n",
    "    # Model dynamics\n",
    "    embeddings        = [embedding_layers[i](songs[:,:,i]) for i in range(events_elements)]\n",
    "    genre_embedding   = genre_embedding_layer(genres)\n",
    "    input_embedding   = input_concat_layer(embeddings)\n",
    "    input_embedding   = encoding_processing_layer(input_embedding)\n",
    "    input_embedding   = sequence_concat_layer([genre_embedding[:, np.newaxis, :], input_embedding])\n",
    "    input_embedding   = sum_layer([input_embedding, positional_encoding])\n",
    "    model_output      = decoder({'inputs_embeds': input_embedding})['last_hidden_state']\n",
    "    out_scores        = [output_dense_layers[i](model_output) for i in range(len(output_dense_layers))]\n",
    "    # TODO: Here we should add the masking layer\n",
    "    out_probabilities = [output_probs_layers[i](out_scores[i]) for i in range(len(output_dense_layers))]\n",
    "    # TODO: In the line above we should add the masks computed in the masking layer\n",
    "\n",
    "    # Create model\n",
    "    model = tf.keras.Model(inputs=[songs, genres], outputs=out_probabilities, name='music_generation_model')\n",
    "    \n",
    "    # Define loss\n",
    "    def custom_loss(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(len(conf.INPUT_RANGES))]\n",
    "        # Base loss term\n",
    "        losses = []\n",
    "        for i in range(len(y_pred)):\n",
    "            losses.append(tf.reduce_sum(\n",
    "                tf.cast(loss_function(gt_vectors[i], y_pred[i][:, :-1, :]), tf.float32) * \\\n",
    "                (1. / conf.GLOBAL_BATCH_SIZE)))\n",
    "        return tf.math.reduce_sum(losses)\n",
    "    \n",
    "    # Define regularizers\n",
    "    def custom_regularizers(songs, y_pred):\n",
    "        gt_vectors = [songs[:,:,i] for i in range(len(conf.INPUT_RANGES))]\n",
    "        # Regularization loss: transform the actual vectors into consecutive-type representation\n",
    "        types = gt_vectors[0]\n",
    "        max_pred_types = tf.argmax(y_pred[0], axis=2, output_type=tf.int32)\n",
    "        consecutive_gt_types   = subsequent_type_transform_layer(types)\n",
    "        consecutive_pred_types = subsequent_type_transform_layer(max_pred_types)\n",
    "        # Compute difference\n",
    "        differences = consecutive_pred_types[:, 1:] - consecutive_pred_types[:, :-1]\n",
    "        # Compute regularization terms\n",
    "        # Difference between one element's type and the next is >= 0\n",
    "        reg_term_1 = tf.math.reduce_sum(tf.math.maximum(0, -differences))\n",
    "        # Difference between one element's type and the next is < 1\n",
    "        reg_term_2 = tf.math.reduce_sum(tf.math.maximum(0, tf.math.maximum(1, differences) - 1))\n",
    "        return reg_scaler * tf.cast(reg_term_1, tf.float32) + reg_scaler * tf.cast(reg_term_2, tf.float32)\n",
    "    \n",
    "    # Add losses\n",
    "    model.add_loss(custom_loss(songs, out_scores))\n",
    "    if use_regularization:\n",
    "        model.add_loss(custom_regularizers(songs, out_scores))\n",
    "    \n",
    "    # Compile and return\n",
    "    model.compile(optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using multiple GPUs with Mirrored Strategy\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = create_model()\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_generation_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " songs (InputLayer)             [(None, 6143, 11)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_8 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_9 (Sl  (None, 6143)        0           ['songs[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " genres (InputLayer)            [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " type_embeddings (Embedding)    (None, 6143, 64)     512         ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " measure_embeddings (Embedding)  (None, 6143, 64)    16384       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " beat_embeddings (Embedding)    (None, 6143, 64)     8384        ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " position_embeddings (Embedding  (None, 6143, 64)    8192        ['tf.__operators__.getitem_4[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " duration_embeddings (Embedding  (None, 6143, 64)    8704        ['tf.__operators__.getitem_5[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " pitch_embeddings (Embedding)   (None, 6143, 64)     16384       ['tf.__operators__.getitem_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " instrument_embeddings (Embeddi  (None, 6143, 64)    8256        ['tf.__operators__.getitem_7[0][0\n",
      " ng)                                                             ]']                              \n",
      "                                                                                                  \n",
      " velocity_embeddings (Embedding  (None, 6143, 64)    8192        ['tf.__operators__.getitem_8[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " key_sign_embeddings (Embedding  (None, 6143, 64)    1600        ['tf.__operators__.getitem_9[0][0\n",
      " )                                                               ]']                              \n",
      "                                                                                                  \n",
      " time_sign_embeddings (Embeddin  (None, 6143, 64)    9792        ['tf.__operators__.getitem_10[0][\n",
      " g)                                                              0]']                             \n",
      "                                                                                                  \n",
      " tempo_embeddings (Embedding)   (None, 6143, 64)     3136        ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " genre_embedding (Sequential)   (None, 512)          33536       ['genres[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6143, 704)    0           ['type_embeddings[0][0]',        \n",
      "                                                                  'measure_embeddings[0][0]',     \n",
      "                                                                  'beat_embeddings[0][0]',        \n",
      "                                                                  'position_embeddings[0][0]',    \n",
      "                                                                  'duration_embeddings[0][0]',    \n",
      "                                                                  'pitch_embeddings[0][0]',       \n",
      "                                                                  'instrument_embeddings[0][0]',  \n",
      "                                                                  'velocity_embeddings[0][0]',    \n",
      "                                                                  'key_sign_embeddings[0][0]',    \n",
      "                                                                  'time_sign_embeddings[0][0]',   \n",
      "                                                                  'tempo_embeddings[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['songs[0][0]']                  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_12 (S  (None, 1, 512)      0           ['genre_embedding[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " encoding_processing (Dense)    (None, 6143, 512)    360960      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 6144, 512)    0           ['tf.__operators__.getitem_12[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'encoding_processing[0][0]']    \n",
      "                                                                                                  \n",
      " tf.repeat (TFOpLambda)         (None, 6144, 512)    0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " final_encoding (Add)           (None, 6144, 512)    0           ['concatenate_1[0][0]',          \n",
      "                                                                  'tf.repeat[0][0]']              \n",
      "                                                                                                  \n",
      " tfgpt2_model (TFGPT2Model)     TFBaseModelOutputWi  22061056    ['final_encoding[0][0]']         \n",
      "                                thPastAndCrossAtten                                               \n",
      "                                tions(last_hidden_s                                               \n",
      "                                tate=(None, 6144, 5                                               \n",
      "                                12),                                                              \n",
      "                                 past_key_values=((                                               \n",
      "                                2, None, 2, 6144, 2                                               \n",
      "                                56),                                                              \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256),                                                            \n",
      "                                 (2, None, 2, 6144,                                               \n",
      "                                 256)),                                                           \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None,                                                \n",
      "                                cross_attentions=No                                               \n",
      "                                ne)                                                               \n",
      "                                                                                                  \n",
      " type_scores (Dense)            (None, 6144, 8)      4104        ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " measure_scores (Dense)         (None, 6144, 256)    131328      ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " beat_scores (Dense)            (None, 6144, 131)    67203       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " position_scores (Dense)        (None, 6144, 128)    65664       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " duration_scores (Dense)        (None, 6144, 136)    69768       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " pitch_scores (Dense)           (None, 6144, 256)    131328      ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " instrument_scores (Dense)      (None, 6144, 129)    66177       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " velocity_scores (Dense)        (None, 6144, 128)    65664       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " keysign_scores (Dense)         (None, 6144, 25)     12825       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " timesign_scores (Dense)        (None, 6144, 153)    78489       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " tempo_scores (Dense)           (None, 6144, 49)     25137       ['tfgpt2_model[0][0]']           \n",
      "                                                                                                  \n",
      " type_probabilities (Softmax)   (None, 6144, 8)      0           ['type_scores[0][0]']            \n",
      "                                                                                                  \n",
      " measure_probabilities (Softmax  (None, 6144, 256)   0           ['measure_scores[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " beat_probabilities (Softmax)   (None, 6144, 131)    0           ['beat_scores[0][0]']            \n",
      "                                                                                                  \n",
      " position_probabilities (Softma  (None, 6144, 128)   0           ['position_scores[0][0]']        \n",
      " x)                                                                                               \n",
      "                                                                                                  \n",
      " duration_probabilities (Softma  (None, 6144, 136)   0           ['duration_scores[0][0]']        \n",
      " x)                                                                                               \n",
      "                                                                                                  \n",
      " pitch_probabilities (Softmax)  (None, 6144, 256)    0           ['pitch_scores[0][0]']           \n",
      "                                                                                                  \n",
      " instrument_probabilities (Soft  (None, 6144, 129)   0           ['instrument_scores[0][0]']      \n",
      " max)                                                                                             \n",
      "                                                                                                  \n",
      " velocity_probabilities (Softma  (None, 6144, 128)   0           ['velocity_scores[0][0]']        \n",
      " x)                                                                                               \n",
      "                                                                                                  \n",
      " keysign_probabilities (Softmax  (None, 6144, 25)    0           ['keysign_scores[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " timesign_probabilities (Softma  (None, 6144, 153)   0           ['timesign_scores[0][0]']        \n",
      " x)                                                                                               \n",
      "                                                                                                  \n",
      " tempo_probabilities (Softmax)  (None, 6144, 49)     0           ['tempo_scores[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_13 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_24 (S  (None, 6143, 8)     0           ['type_scores[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_14 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_25 (S  (None, 6143, 256)   0           ['measure_scores[0][0]']         \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_15 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_26 (S  (None, 6143, 131)   0           ['beat_scores[0][0]']            \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_16 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_27 (S  (None, 6143, 128)   0           ['position_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_17 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_28 (S  (None, 6143, 136)   0           ['duration_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_18 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_29 (S  (None, 6143, 256)   0           ['pitch_scores[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_19 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_30 (S  (None, 6143, 129)   0           ['instrument_scores[0][0]']      \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_20 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_31 (S  (None, 6143, 128)   0           ['velocity_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_21 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_32 (S  (None, 6143, 25)    0           ['keysign_scores[0][0]']         \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_22 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_33 (S  (None, 6143, 153)   0           ['timesign_scores[0][0]']        \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_23 (S  (None, 6143)        0           ['songs[0][0]']                  \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_34 (S  (None, 6143, 49)    0           ['tempo_scores[0][0]']           \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_13[0][\n",
      " rical_crossentropy (TFOpLambda                                  0]',                             \n",
      " )                                                                'tf.__operators__.getitem_24[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_14[0][\n",
      " rical_crossentropy_1 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_15[0][\n",
      " rical_crossentropy_2 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_26[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_16[0][\n",
      " rical_crossentropy_3 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_17[0][\n",
      " rical_crossentropy_4 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_28[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_18[0][\n",
      " rical_crossentropy_5 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_19[0][\n",
      " rical_crossentropy_6 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_30[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_20[0][\n",
      " rical_crossentropy_7 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_21[0][\n",
      " rical_crossentropy_8 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_32[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_22[0][\n",
      " rical_crossentropy_9 (TFOpLamb                                  0]',                             \n",
      " da)                                                              'tf.__operators__.getitem_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.keras.backend.sparse_catego  (None, 6143)        0           ['tf.__operators__.getitem_23[0][\n",
      " rical_crossentropy_10 (TFOpLam                                  0]',                             \n",
      " bda)                                                             'tf.__operators__.getitem_34[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 6143)         0           ['tf.keras.backend.sparse_categor\n",
      "                                                                 ical_crossentropy[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " )                                                               ical_crossentropy_4[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_5[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_6[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_7[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_8[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_9[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpLambd  (None, 6143)        0           ['tf.keras.backend.sparse_categor\n",
      " a)                                                              ical_crossentropy_10[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_5 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_4[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_7 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_6[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_9 (TFOpLambda)         (None, 6143)         0           ['tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.cast_11 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_10[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_13 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_15 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_14[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_17 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_16[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_19 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_18[0][0]']    \n",
      "                                                                                                  \n",
      " tf.cast_21 (TFOpLambda)        (None, 6143)         0           ['tf.math.multiply_20[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 6143)        0           ['tf.cast_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  (None, 6143)        0           ['tf.cast_3[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None, 6143)        0           ['tf.cast_5[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None, 6143)        0           ['tf.cast_7[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 6143)        0           ['tf.cast_9[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpLambd  (None, 6143)        0           ['tf.cast_11[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpLambd  (None, 6143)        0           ['tf.cast_13[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpLambd  (None, 6143)        0           ['tf.cast_15[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpLambd  (None, 6143)        0           ['tf.cast_17[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpLambd  (None, 6143)        0           ['tf.cast_19[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpLambd  (None, 6143)        0           ['tf.cast_21[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  ()                  0           ['tf.math.multiply_1[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  ()                  0           ['tf.math.multiply_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_2 (TFOpLamb  ()                  0           ['tf.math.multiply_5[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_3 (TFOpLamb  ()                  0           ['tf.math.multiply_7[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_4 (TFOpLamb  ()                  0           ['tf.math.multiply_9[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOpLamb  ()                  0           ['tf.math.multiply_11[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_6 (TFOpLamb  ()                  0           ['tf.math.multiply_13[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_7 (TFOpLamb  ()                  0           ['tf.math.multiply_15[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_8 (TFOpLamb  ()                  0           ['tf.math.multiply_17[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_9 (TFOpLamb  ()                  0           ['tf.math.multiply_19[0][0]']    \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_10 (TFOpLam  ()                  0           ['tf.math.multiply_21[0][0]']    \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_11 (TFOpLam  ()                  0           ['tf.math.reduce_sum[0][0]',     \n",
      " bda)                                                             'tf.math.reduce_sum_1[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_2[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_3[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_4[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_5[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_6[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_7[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_8[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_9[0][0]',   \n",
      "                                                                  'tf.math.reduce_sum_10[0][0]']  \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             ()                   0           ['tf.math.reduce_sum_11[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.argmax (TFOpLambda)    (None, 6144)         0           ['type_scores[0][0]']            \n",
      "                                                                                                  \n",
      " subsequent_type_transformation  multiple            0           ['tf.math.argmax[0][0]']         \n",
      " _layer (SubsequentTypeTransfor                                                                   \n",
      " mationLayer)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_46 (S  (None, 6143)        0           ['subsequent_type_transformation_\n",
      " licingOpLambda)                                                 layer[1][0]']                    \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_47 (S  (None, 6143)        0           ['subsequent_type_transformation_\n",
      " licingOpLambda)                                                 layer[1][0]']                    \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 6143)         0           ['tf.__operators__.getitem_46[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.math.maximum_1 (TFOpLambda)  (None, 6143)        0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.negative (TFOpLambda)  (None, 6143)         0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 6143)        0           ['tf.math.maximum_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambda)   (None, 6143)         0           ['tf.math.negative[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.maximum_2 (TFOpLambda)  (None, 6143)        0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_12 (TFOpLam  ()                  0           ['tf.math.maximum[0][0]']        \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_13 (TFOpLam  ()                  0           ['tf.math.maximum_2[0][0]']      \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.cast_22 (TFOpLambda)        ()                   0           ['tf.math.reduce_sum_12[0][0]']  \n",
      "                                                                                                  \n",
      " tf.cast_23 (TFOpLambda)        ()                   0           ['tf.math.reduce_sum_13[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpLambd  ()                  0           ['tf.cast_22[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpLambd  ()                  0           ['tf.cast_23[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.multiply_22[0][0]',    \n",
      " da)                                                              'tf.math.multiply_23[0][0]']    \n",
      "                                                                                                  \n",
      " add_loss_1 (AddLoss)           ()                   0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,262,775\n",
      "Trainable params: 23,262,775\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the model with some inputs from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('..', 'data', 'tf_data7')\n",
    "dataset = tf.data.Dataset.load(DATASET_PATH).batch(conf.BATCH_SIZE).cache().shuffle(conf.SHUFFLE_SIZE).prefetch(conf.PREFETCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 19:02:06.349462: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "X, y = next(dataset.take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TensorShape([12, 6144, 8]), TensorShape([12, 6144, 256]), TensorShape([12, 6144, 131]), TensorShape([12, 6144, 128]), TensorShape([12, 6144, 136]), TensorShape([12, 6144, 256]), TensorShape([12, 6144, 129]), TensorShape([12, 6144, 128]), TensorShape([12, 6144, 25]), TensorShape([12, 6144, 153]), TensorShape([12, 6144, 49])]\n"
     ]
    }
   ],
   "source": [
    "output = model([X, y])\n",
    "print([x.shape for x in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=389425.3>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=14.207001>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: There is something weird with the multi-GPU loss. I bet I have to divide for the global batch size or something."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fd096c0f68c234ce42f352405a374f9608d011e25b44ffd11646331457b1b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
