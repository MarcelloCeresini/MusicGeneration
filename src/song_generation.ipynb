{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 16:20:02.514837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-23 16:20:02.633653: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-23 16:20:03.095613: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/volpepe/miniconda3/envs/music_gen/lib/:/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-05-23 16:20:03.095715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/volpepe/miniconda3/envs/music_gen/lib/:/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/nvidia/cudnn/lib\n",
      "2023-05-23 16:20:03.095722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/volpepe/miniconda3/envs/music_gen/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-23 16:20:04.584940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:04.604079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:04.604243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:04.690115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using single GPU/CPU device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 16:20:04.690897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:04.691066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:04.691221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:05.250702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:05.250848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:05.250959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-23 16:20:05.251045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2940 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import trange\n",
    "\n",
    "import config, music_model, utils\n",
    "\n",
    "### CONFIGURATION ###\n",
    "\n",
    "USE_DOUBLE_HEAD = True\n",
    "USE_ONE_GPU = True\n",
    "\n",
    "### CONSTANTS ###\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATASET_NAME = 'lmd_matched_final_2048_cut'\n",
    "MODEL_NAME = 'model_GPT_baseline_with_mse_vellmd_matched_2048' if not USE_DOUBLE_HEAD else \\\n",
    "             'model_GPT_baseline_with_mse_vel_lmd_matched_2048_double_head'\n",
    "WEIGHTS_PATH = os.path.join(ROOT_PATH, 'training', 'checkpoints', MODEL_NAME, MODEL_NAME)\n",
    "USE_SMALL_GENRE_SET = DATASET_NAME == 'tf_data7dict'\n",
    "\n",
    "conf = config.Config(\"single_instruments_type\", ROOT_PATH)\n",
    "\n",
    "if USE_SMALL_GENRE_SET:\n",
    "    conf.accepted_subgenres = ['folk', 'nes', 'maestro']\n",
    "# If we need to use only the first GPU\n",
    "if USE_ONE_GPU:\n",
    "    conf.GPUS = tf.config.experimental.list_physical_devices('GPU')[0]\n",
    "    conf.BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.GLOBAL_BATCH_SIZE = conf.BATCH_SIZE\n",
    "    conf.num_devices = 1\n",
    "\n",
    "### MODEL CREATION ###\n",
    "\n",
    "if conf.num_devices > 1:\n",
    "    print(\"Using multiple GPUs with Mirrored Strategy\")\n",
    "    with conf.training_strategy.scope():\n",
    "        model = music_model.create_model(conf,\n",
    "                                         num_genres=len(conf.accepted_subgenres),\n",
    "                                         use_regularization=False,\n",
    "                                         use_masking_layers=False, \n",
    "                                         double_head=USE_DOUBLE_HEAD)\n",
    "else:\n",
    "    print(\"Using single GPU/CPU device\")\n",
    "    model = music_model.create_model(conf,\n",
    "                                     num_genres=len(conf.accepted_subgenres),\n",
    "                                     use_regularization=False,\n",
    "                                     use_masking_layers=False,\n",
    "                                     double_head=USE_DOUBLE_HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4b4c973df0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(WEIGHTS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Function to choose a style for the song\n",
    "def encode_styles(styles_array):\n",
    "    one_hot_enc = np.zeros((len(styles_array), len(conf.accepted_subgenres)), dtype=np.int8)\n",
    "    for i, style in enumerate(styles_array):\n",
    "        one_hot_enc[i, conf.accepted_subgenres.index(style)] = 1\n",
    "    return one_hot_enc\n",
    "\n",
    "# Example:\n",
    "styles = encode_styles(['rock', 'pop', 'dance', 'electronic'])\n",
    "print(styles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = {\n",
    "    'prob': {\n",
    "        'type': 0, 'measure': 1, 'beat': 2, 'position': 3, 'duration': 4, 'pitch': 5, \n",
    "        'instrument': 6, 'velocity': 7, 'key_sign': 8, 'time_sign': 9, 'tempo': 10,\n",
    "    }, \n",
    "    'mask': {\n",
    "        'measure': 0, 'beat': 1, 'position': 2, 'duration': 3, 'pitch': 4,\n",
    "        'instrument': 5, 'velocity': 6, 'key_sign': 7, 'time_sign': 8, 'tempo': 9\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def apply_sampling_strategy(probs: np.ndarray, sampling_settings: Dict) -> np.ndarray:\n",
    "    # Sample the next token from the output probabilities using the desired sampling mode\n",
    "    # Use some method to modify the probabilities, such as top-k or top-p sampling\n",
    "    generation_mode = sampling_settings['generation_mode']\n",
    "\n",
    "    ## 1. Top-k sampling: sample from the top-k most probable tokens.\n",
    "    ## k is expressed as a ratio of the number of possibilities, because each component has different ranges.\n",
    "    if generation_mode == 'top_k_sampling':\n",
    "        # Compute the top-k indices in the probability array\n",
    "        k = int(np.ceil(len(probs) * sampling_settings['top_k_ratio']))\n",
    "        top_k_indices = np.argsort(-np.asarray(probs))[:k]\n",
    "        # Compute the mass of probability to be redistributed between the top-k elements\n",
    "        redistrib_mass = sum(np.take(probs, top_k_indices))\n",
    "        # Directly modify the probability array \n",
    "        # redistrib_mass : 1 = prob[i] : x --> x = prob[i] / redistrib_mass\n",
    "        # For the non-top-k elements, the probability is 0\n",
    "        for idx in range(len(probs)):\n",
    "            probs[idx] = (probs[idx] / redistrib_mass) if idx in top_k_indices else 0\n",
    "\n",
    "    ## 2. Top-p sampling: sample from the most probable tokens until the cumulative probability exceeds p\n",
    "    elif generation_mode == 'top_p_sampling':\n",
    "        best_indices = np.argsort(-np.asarray(probs))\n",
    "        # Take elements until the cumulative probability exceeds the threshold (always at least one element)\n",
    "        cum_prob = 0; k = 0\n",
    "        while cum_prob < sampling_settings['current_top_p_ratio'] and k < len(best_indices):\n",
    "            cum_prob += probs[best_indices[k]]\n",
    "            k += 1\n",
    "        # Directly modify the probability array\n",
    "        # cum_prob : 1 = prob[i] : x --> x = prob[i] / cum_prob\n",
    "        # For the other elements, the probability is 0\n",
    "        for idx in range(len(probs)):\n",
    "            probs[idx] = (probs[idx] / cum_prob) if idx in best_indices[:k] else 0\n",
    "\n",
    "    elif generation_mode == 'standard_sampling':\n",
    "        pass    # Maintain probabilities as they are\n",
    "    else:\n",
    "        raise ValueError(\"Unknown generation mode: {}\".format(generation_mode))\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def sample_from(p: np.ndarray, mask: np.ndarray=None, sampling_settings: Dict={\n",
    "    'generation_mode': 'standard_sampling'}) -> int:\n",
    "    # Sometimes the mask is completely zero: in those cases, we return index 0 and\n",
    "    # setup the rest of the generation function to deterministically choose end tokens\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0\n",
    "    # Otherwise, mask the probability array\n",
    "    if mask is not None: \n",
    "        p = p * mask\n",
    "    # Then modify the remaining probabilities according to the sampling strategy\n",
    "    p = apply_sampling_strategy(p, sampling_settings)\n",
    "    # Sample using the probability distribution\n",
    "    idx = np.random.choice(\n",
    "        np.arange(len(p)),\n",
    "        p=p\n",
    "    )\n",
    "    return idx\n",
    "\n",
    "\n",
    "def sample_type(song: np.ndarray, current_token_idx: int, \n",
    "                current_token_probabilities: np.ndarray, \n",
    "                use_masking:bool=True, sampling_settings: Dict={\n",
    "                    'generation_mode': 'standard_sampling'}) -> int:\n",
    "    type_probabilities = current_token_probabilities[INDEX['prob']['type']]\n",
    "    type_mask = None\n",
    "    if use_masking:\n",
    "        previous_token = song[current_token_idx-1, :]\n",
    "        type_mask = np.ones(conf.INPUT_RANGES['type'], dtype=np.int8)\n",
    "        if previous_token[INDEX['prob']['type']] == 0: # only type 1 is acceptable\n",
    "            type_mask[0] = 0; type_mask[2:] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 1: # only type 1 and 2 are acceptable\n",
    "            type_mask[0] = 0; type_mask[3:] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 2: # only type 4 is acceptable\n",
    "            type_mask[0:4] = 0; type_mask[5:] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 3: # only type 3-4-5-6-7 are acceptable\n",
    "            type_mask[0:3] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 4: # cannot write type 0-1-2\n",
    "            type_mask[0:3] = 0\n",
    "            if np.sum(song[:,0] == 5) == 0: # if no time_sign has been defined, you must define it\n",
    "                type_mask[3:5] = 0; type_mask[6:] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 5: # cannot write type 0-1-2\n",
    "            type_mask[0:3] = 0\n",
    "            if np.sum(song[:,0] == 6) == 0: # if no tempo has been defined, you must define it\n",
    "                    type_mask[3:6] = 0; type_mask[7] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 6: # cannot write type 0-1-2\n",
    "            type_mask[0:3] = 0\n",
    "        elif previous_token[INDEX['prob']['type']] == 7: # can only write type 7\n",
    "            type_mask[0:7] = 0\n",
    "    # Sample the type\n",
    "    sampled_type = sample_from(type_probabilities, type_mask, sampling_settings)\n",
    "    return sampled_type    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_current_token(song: np.ndarray, current_token_idx: int, \n",
    "                         current_token_probabilities: List[np.ndarray], \n",
    "                         current_settings: Dict, use_masking:bool = True,\n",
    "                         sampling_settings: Dict={'generation_mode': 'standard_sampling'}) -> Tuple[np.ndarray, Dict]:\n",
    "    # Create token parts\n",
    "    token_components = {k: None for k in conf.INPUT_RANGES.keys()}\n",
    "    \n",
    "    # Sample the type\n",
    "    token_components['type'] = sample_type(song, current_token_idx, current_token_probabilities, use_masking, sampling_settings)\n",
    "    # Depending on the sampled type, sample the other tokens using customized masks\n",
    "    if use_masking:\n",
    "        mask_from_current_token = deepcopy(conf.full_mask)\n",
    "        \n",
    "        # Decide what to mask based on the sampled type\n",
    "        if token_components['type'] == 1:\n",
    "            # The other token parts (except instruments) must have index 0\n",
    "            mask_from_current_token = deepcopy(conf.default_mask[:INDEX['mask']['instrument']]) + \\\n",
    "                                      [conf.full_mask[INDEX['mask']['instrument']].copy()]      + \\\n",
    "                                      deepcopy(conf.default_mask[INDEX['mask']['instrument']+1:])\n",
    "            # Mask to not allow duplicate instruments\n",
    "            for instrument_idx in current_settings[\"instruments\"]:\n",
    "                mask_from_current_token[INDEX['mask']['instrument']][instrument_idx] = 0\n",
    "            # Sample the instrument and append it to current settings\n",
    "            token_components['instrument'] = sample_from(current_token_probabilities[INDEX['prob']['instrument']], \n",
    "                                                         mask_from_current_token[INDEX['mask']['instrument']],\n",
    "                                                         sampling_settings)\n",
    "            current_settings['instruments'].append(token_components['instrument'])\n",
    "        \n",
    "        elif token_components['type'] == 2:\n",
    "            mask_from_current_token = deepcopy(conf.default_mask) # only index zero on the other parts of the token\n",
    "\n",
    "        elif token_components['type'] == 3:\n",
    "            # Mask the previous measures\n",
    "            m = current_settings['measure']\n",
    "            mask_from_current_token[INDEX['mask']['measure']][:m] = [0]*m\n",
    "            token_components['measure'] = sample_from(current_token_probabilities[INDEX['prob']['measure']], \n",
    "                                                      mask_from_current_token[INDEX['mask']['measure']], \n",
    "                                                      sampling_settings)\n",
    "\n",
    "            # Adjust and sample beat and position\n",
    "            if token_components['measure'] == m:\n",
    "                b = current_settings['beat']\n",
    "                mask_from_current_token[INDEX['mask']['beat']][:b] = [0]*b\n",
    "\n",
    "                numerator = utils.time_sign_inverse_map(current_settings[\"time_sign\"], conf)[0]\n",
    "                mask_from_current_token[INDEX['mask']['beat']][numerator:] = [0]*(conf.INPUT_RANGES['beat']-numerator)\n",
    "\n",
    "                token_components['beat'] = sample_from(current_token_probabilities[INDEX['prob']['beat']], \n",
    "                                                       mask_from_current_token[INDEX['mask']['beat']],\n",
    "                                                       sampling_settings)\n",
    "\n",
    "                if token_components['beat'] == b:\n",
    "                    p = current_settings[\"position\"]\n",
    "                    mask_from_current_token[INDEX['mask']['position']][:p] = [0]*p\n",
    "                    token_components['position'] = sample_from(current_token_probabilities[INDEX['prob']['position']], \n",
    "                                                               mask_from_current_token[INDEX['mask']['position']],\n",
    "                                                               sampling_settings)\n",
    "\n",
    "            # Otherwise sample beat and position without masking them\n",
    "            if token_components['beat'] is None:\n",
    "                token_components['beat'] = sample_from(current_token_probabilities[INDEX['prob']['beat']], \n",
    "                                                       mask_from_current_token[INDEX['mask']['beat']],\n",
    "                                                       sampling_settings)\n",
    "            if token_components['position'] is None:\n",
    "                token_components['position'] = sample_from(current_token_probabilities[INDEX['prob']['position']], \n",
    "                                                           mask_from_current_token[INDEX['mask']['position']],\n",
    "                                                           sampling_settings)\n",
    "\n",
    "            # Mask instruments to only accept defined ones\n",
    "            for instrument_idx in current_settings['instruments']:\n",
    "                mask_from_current_token[INDEX['mask']['instrument']][instrument_idx] = 0\n",
    "            mask_from_current_token[INDEX['mask']['instrument']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['instrument']])\n",
    "\n",
    "            # only accept previous key_sign, time_sign and tempo\n",
    "            mask_from_current_token[INDEX['mask']['key_sign']][current_settings['key_sign']] = 0\n",
    "            mask_from_current_token[INDEX['mask']['key_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['key_sign']])\n",
    "\n",
    "            mask_from_current_token[INDEX['mask']['time_sign']][current_settings['time_sign']] = 0\n",
    "            mask_from_current_token[INDEX['mask']['time_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['time_sign']])\n",
    "\n",
    "            mask_from_current_token[INDEX['mask']['tempo']][current_settings['tempo']] = 0\n",
    "            mask_from_current_token[INDEX['mask']['tempo']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['tempo']])\n",
    "\n",
    "            current_settings['measure']  = token_components['measure']\n",
    "            current_settings['beat']     = token_components['beat']\n",
    "            current_settings['position'] = token_components['position']\n",
    "\n",
    "        elif token_components['type'] in [4,5,6]:\n",
    "            # We allow the measure, key sign, time sign and tempo to change\n",
    "            mask_from_current_token = [conf.full_mask[INDEX['mask']['measure']].copy()]                                 + \\\n",
    "                                      deepcopy(conf.default_mask[INDEX['mask']['measure']+1:INDEX['mask']['key_sign']]) + \\\n",
    "                                      deepcopy(conf.full_mask[INDEX['mask']['key_sign']:])\n",
    "            # Mask the previous measures\n",
    "            if current_settings[\"beat\"] == 0 and current_settings[\"position\"] == 0:\n",
    "                m = current_settings[\"measure\"]\n",
    "            else:\n",
    "                m = current_settings[\"measure\"] + 1\n",
    "            mask_from_current_token[0][:m] = [0]*m\n",
    "            token_components['measure'] = sample_from(current_token_probabilities[INDEX['prob']['measure']], \n",
    "                                                      mask_from_current_token[INDEX['mask']['measure']],\n",
    "                                                      sampling_settings)\n",
    "\n",
    "            if token_components['type'] == 4:\n",
    "                mask_from_current_token[INDEX['mask']['key_sign']][current_settings[\"key_sign\"]] = 0 # cannot choose the same key_sign as the current\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['time_sign']][current_settings[\"time_sign\"]] = 0 # can only choose the current time sign\n",
    "                mask_from_current_token[INDEX['mask']['time_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['time_sign']])\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['tempo']][current_settings[\"tempo\"]] = 0 # can only choose the current tempo\n",
    "                mask_from_current_token[INDEX['mask']['tempo']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['tempo']])\n",
    "\n",
    "                # Sample the new key sign\n",
    "                token_components['key_sign'] = sample_from(current_token_probabilities[INDEX['prob']['key_sign']], \n",
    "                                                           mask_from_current_token[INDEX['mask']['key_sign']],\n",
    "                                                           sampling_settings)\n",
    "                current_settings[\"key_sign\"] = token_components['key_sign']\n",
    "\n",
    "            if token_components['type'] == 5:\n",
    "                mask_from_current_token[INDEX['mask']['key_sign']][current_settings[\"key_sign\"]] = 0 # can only choose the current key_sign\n",
    "                mask_from_current_token[INDEX['mask']['key_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['key_sign']])\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['time_sign']][current_settings[\"time_sign\"]] = 0 # cannot choose the same time_sign as the current\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['tempo']][current_settings[\"tempo\"]] = 0 # can only choose the current tempo\n",
    "                mask_from_current_token[INDEX['mask']['tempo']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['tempo']])\n",
    "\n",
    "                token_components['time_sign'] = sample_from(current_token_probabilities[INDEX['prob']['time_sign']], \n",
    "                                                            mask_from_current_token[INDEX['mask']['time_sign']],\n",
    "                                                            sampling_settings)\n",
    "                current_settings[\"time_sign\"] = token_components['time_sign']\n",
    "\n",
    "            if token_components['type'] == 6:\n",
    "                mask_from_current_token[INDEX['mask']['key_sign']][current_settings[\"key_sign\"]] = 0 # can only choose the current key sign\n",
    "                mask_from_current_token[INDEX['mask']['key_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['key_sign']])\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['time_sign']][current_settings[\"time_sign\"]] = 0 # can only choose the current time sign\n",
    "                mask_from_current_token[INDEX['mask']['time_sign']] = np.bitwise_not(mask_from_current_token[INDEX['mask']['time_sign']])\n",
    "\n",
    "                mask_from_current_token[INDEX['mask']['tempo']][current_settings[\"tempo\"]] = 0 # cannot choose the same tempo as the current\n",
    "\n",
    "                token_components['tempo'] = sample_from(current_token_probabilities[INDEX['prob']['tempo']], \n",
    "                                                        mask_from_current_token[INDEX['mask']['tempo']],\n",
    "                                                        sampling_settings)\n",
    "                current_settings[\"tempo\"] = token_components['tempo']\n",
    "            \n",
    "            current_settings[\"measure\"] = token_components['measure']\n",
    "            current_settings[\"beat\"] = 0\n",
    "            current_settings[\"position\"] = 0\n",
    "\n",
    "        elif token_components['type'] == 7:\n",
    "            mask_from_current_token = deepcopy(conf.default_mask) # only index zero on the other parts of the token\n",
    "\n",
    "    else:\n",
    "        # No masking\n",
    "        mask_from_current_token = [None] * len(conf.default_mask)\n",
    "\n",
    "    # If any of the masks is full of False, we set the type to 7 and the other components to index 0\n",
    "    if any([np.sum(mask_from_current_token[INDEX['mask'][key]]) == 0 \n",
    "            for key in token_components.keys() if key != 'type']):\n",
    "        token_components['type'] = 7\n",
    "        for k in (token_components.keys() - {'type'}):\n",
    "            token_components[k] = 0\n",
    "    else:        \n",
    "        # Sample all values that are still None and concatenate them (except for the velocity)\n",
    "        for key in token_components.keys():\n",
    "            if key == 'velocity':\n",
    "                token_components['velocity'] = int(current_token_probabilities[INDEX['prob']['velocity']] * conf.INPUT_RANGES['velocity'])\n",
    "            elif token_components[key] is None:\n",
    "                token_components[key] = sample_from(current_token_probabilities[INDEX['prob'][key]], \n",
    "                                                    mask_from_current_token[INDEX['mask'][key]],\n",
    "                                                    sampling_settings)\n",
    "\n",
    "    current_token = np.array([\n",
    "        token_components[k] \n",
    "        for k in sorted(INDEX['prob'], key=lambda x: INDEX['prob'][x])], dtype=np.int32)\n",
    "    return current_token, current_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Song generation function\n",
    "def generate_songs(model, style_list:List[str], max_length:int=conf.SEQ_LEN-1, \n",
    "                   terminator_type:int=7, generation_mode:str='standard_sampling', \n",
    "                   temperature:float=1.0, top_k_ratio=0.3, top_p_start:float=0.9, \n",
    "                   top_p_min=0.9, use_masking:bool=True):\n",
    "    \n",
    "    # Check the validity of the parameters\n",
    "    assert temperature > 0, \"Temperature must be greater than 0\"\n",
    "    assert max_length <= conf.SEQ_LEN-1, f\"The maximum length of the generated song must be less than {conf.SEQ_LEN-1}\"\n",
    "    assert generation_mode in ['standard_sampling', 'top_k_sampling', 'top_p_sampling'], \\\n",
    "        f\"Parameter 'generation_mode' must be one of the following: 'standard_sampling', 'top_k_sampling', 'top_p_sampling'\"\n",
    "\n",
    "    # Collect explicitly the number of songs to generate\n",
    "    num_songs = len(style_list)\n",
    "\n",
    "    # Separate preprocessing model, transformer and output layers in order to be able to\n",
    "    # inject the attention masks into the transformer and still use the loaded weights\n",
    "    preprocessing_model = keras.Model(inputs=model.input, outputs=model.get_layer('final_encoding').output)\n",
    "    transformer = model.get_layer('tfgpt2_model')\n",
    "    output_layers = [\n",
    "        model.get_layer('type_scores'), model.get_layer('measure_scores'), model.get_layer('beat_scores'),\n",
    "        model.get_layer('position_scores'), model.get_layer('duration_scores'), model.get_layer('pitch_scores'),\n",
    "        model.get_layer('instrument_scores'), model.get_layer('velocity_values'), model.get_layer('keysign_scores'),\n",
    "        model.get_layer('timesign_scores'), model.get_layer('tempo_scores')\n",
    "    ]\n",
    "    activations = [tf.keras.activations.softmax] * 7 + [tf.keras.activations.relu] + [tf.keras.activations.softmax] * 3\n",
    "    \n",
    "    # Create the empty song array.\n",
    "    # The first token of the songs is always the start token (0,...,0)\n",
    "    # The rest of the tensor is filled with padding of zeroes, which will be masked by the attention masks\n",
    "    generated_songs = np.zeros((num_songs, conf.SEQ_LEN-1, 11), dtype=np.int32)\n",
    "    # Create the current settings for the songs\n",
    "    current_settings = [{\n",
    "        'instruments': [], 'measure': 0, 'beat': 0, 'position': 0, 'key_sign': 0, 'time_sign': 0, 'tempo': 0,\n",
    "    } for _ in range(num_songs)]\n",
    "\n",
    "    # Create the sampling settings dictionary\n",
    "    sampling_settings = {'generation_mode': generation_mode}\n",
    "    if generation_mode == 'top_k_sampling': sampling_settings['top_k_ratio'] = top_k_ratio\n",
    "    elif generation_mode == 'top_p_sampling':\n",
    "        # Compute the dynamic top-p thresholds at each step\n",
    "        top_p_sequence = np.linspace(top_p_start, top_p_min, max_length-1)  # Generate max_length-1 evenly spaced values\n",
    "    \n",
    "    # Generate the one-hot encodings of the genres\n",
    "    styles = encode_styles(style_list)\n",
    "\n",
    "    # Start to generate the songs token by token\n",
    "    for i in trange(1, max_length):\n",
    "\n",
    "        # Create the attention mask (the first 2 tokens are always attended: genre and starting token)\n",
    "        attention_mask = np.ones((num_songs, 1+i), dtype=np.int8)\n",
    "        padding_attention_mask = np.zeros((num_songs, conf.SEQ_LEN-1-i), dtype=np.int8)\n",
    "        attention_mask = np.concatenate([attention_mask, padding_attention_mask], axis=-1)\n",
    "\n",
    "        # Preprocess the songs and pass them through the transformer\n",
    "        preprocessed_tensors = preprocessing_model((generated_songs, styles))\n",
    "        out_transformer      = transformer({'inputs_embeds': preprocessed_tensors},\n",
    "                               attention_mask=attention_mask)['last_hidden_state']\n",
    "        # Use the output layers to generate the probabilities for the next token\n",
    "        # Output from transformer has SEQ_LEN tokens, so we trim it by removing the last one,\n",
    "        # since it's the probability of a token that's out of our bounds.\n",
    "        out_scores           = [output_layers[i](out_transformer)[:,:-1,:]\n",
    "                                for i in range(len(output_layers))]\n",
    "        # Apply temperature to the scores but mind the velocity scores which is a scalar\n",
    "        out_scores_tempered  = [out_scores[i] / temperature for i in range(7)] + \\\n",
    "            [out_scores[7]]  + [out_scores[i] / temperature for i in range(8, 11)]\n",
    "        out_probs            = [np.array(activations[i](out_scores_tempered[i]))\n",
    "                                for i in range(len(activations))]\n",
    "        \n",
    "        if generation_mode == 'top_p_sampling':\n",
    "            sampling_settings['current_top_p_ratio'] = top_p_sequence[i-1]\n",
    "\n",
    "        # Sample the next token, using the requested generation mode\n",
    "        next_tokens = []\n",
    "        for song in range(num_songs):\n",
    "            next_token, current_settings[song] = sample_current_token(song=generated_songs[song], current_token_idx=i, \n",
    "                                                    current_token_probabilities=[out_probs[h][song, i] for h in range(len(out_probs))],\n",
    "                                                    current_settings=current_settings[song], use_masking=use_masking,\n",
    "                                                    sampling_settings=sampling_settings)\n",
    "            next_tokens.append(np.array(next_token, dtype=np.int32))\n",
    "        batch = np.stack(next_tokens, axis=0)\n",
    "\n",
    "        # Add the new tokens to the songs\n",
    "        generated_songs[:, i] = batch\n",
    "\n",
    "    # If a token in a song has type of terminator, simply overwrite the rest of the song with end tokens\n",
    "    for song in range(num_songs):\n",
    "        terminator_indices = np.argwhere(generated_songs[song, :, 0] == terminator_type)\n",
    "        if len(terminator_indices) > 0:\n",
    "            first_terminator_index = terminator_indices[0,0]\n",
    "            generated_songs[song, first_terminator_index:, :] = [7] + [0]*10\n",
    "        \n",
    "    # Internally, the generated song is always SEQ_LEN - 1 long, so we cut it before returning it.\n",
    "    return generated_songs[:, :max_length, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rock songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2046 [00:00<?, ?it/s]2023-05-23 16:20:50.029992: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "100%|██████████| 2046/2046 [06:59<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pop songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:57<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dance songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [07:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating country songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [07:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating metal songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [07:03<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating classical songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:40<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating folk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:37<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating blues songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:37<00:00,  5.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating house songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [07:00<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating indie songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:38<00:00,  5.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating latin songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:46<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating jazz songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:46<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating funk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:46<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rap songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:47<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating punk songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:47<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating r&b songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:46<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating gospel songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [06:45<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating electronic songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2046/2046 [04:34<00:00,  7.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for genre in conf.accepted_subgenres:\n",
    "    print(f\"Generating {genre} songs...\")\n",
    "    out_songs = generate_songs(model, [genre]*4, max_length=2047, temperature=0.9, \n",
    "                            generation_mode='top_p_sampling', top_p_start=0.9, top_p_min=0.6)\n",
    "    song_name = f'songs_{genre}{\"_double_head\" if USE_DOUBLE_HEAD else \"\"}.npy'\n",
    "    np.save(os.path.join(conf.DATA_PATH, 'generated_songs', 'repr', song_name), out_songs, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ed98097e12b2e5cb24acca5eaecb045ae6fa1f3d168a26bde2bb15ec97be77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
