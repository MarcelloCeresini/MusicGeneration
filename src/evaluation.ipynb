{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bf6029-bdb2-4dcc-a429-296ca8191125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import scipy.stats as st\n",
    "\n",
    "# # Workaround for very high loads on GPUs\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# # Or use single GPU\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "from config import Config\n",
    "import utils\n",
    "\n",
    "MODEL_TYPE = 'GPT'\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "conf = Config(\"single_instruments_type\", ROOT_PATH, model_type=MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ce7d7-39be-47e2-9434-08e6521bfd79",
   "metadata": {},
   "source": [
    "# Music Generation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b974aa-2795-4118-a625-5470ad32c06f",
   "metadata": {},
   "source": [
    "We implemented several metrics and statistics that we compare across our sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7bbbcc-5e60-4ed2-b196-afce41caed4d",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e44e0d6-05d1-4aaa-9907-927459bb7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_note(token):\n",
    "    return token[0] == 3 and token[6] < 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb536f86-84ac-47c6-b606-a6fb45d6ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes_in_measures(song, start_measure, end_measure):\n",
    "    # If it's a note with the same measure and its pitch is not drums-related\n",
    "    return [token for token in song \n",
    "            if (is_note(token) and start_measure <= token[1] < end_measure)]\n",
    "\n",
    "def pitch_class_histogram_entropy_metric(song, window_size=1):\n",
    "    # Compute the mean pitch class histogram entropy in a song\n",
    "    # using the specified number of measures (window_size).\n",
    "    # Usually, interesting metrics use window_size 1 and 4\n",
    "    song_measures = np.unique(song[:,1])\n",
    "    if len(song_measures) < window_size:\n",
    "        # print(f\"\\tSong has too few measures for window size {window_size}:\"\n",
    "        #      f\" reverting back to a window size of {len(song_measures)}\")\n",
    "        window_size = len(song_measures)\n",
    "    # Slide the window over the song to compute the entropy of notes in those measures\n",
    "    entropy_for_windows = []\n",
    "    for st_measure in range(0, len(song_measures) - window_size + 1):\n",
    "        end_measure = st_measure + window_size\n",
    "        notes = get_notes_in_measures(song, st_measure, end_measure) \n",
    "        if len(notes) > 0:\n",
    "            notes_pitches = np.array([n[5] for n in notes])\n",
    "            notes_classes = notes_pitches % 12 # {C, C#, ..., Bb, B}\n",
    "            hist, edges = np.histogram(notes_classes, bins=list(range(12)))\n",
    "            hist = hist / np.sum(hist)   # Normalize by total note count in the period\n",
    "            hist = hist + 1e-10 # Avoid log of 0\n",
    "            entropy = -np.sum(hist * (np.log(hist) / np.log(2))) # Fast log2 implementation\n",
    "            entropy_for_windows.append(entropy)\n",
    "        else:\n",
    "            # print(f\"\\tWindow from measures {st_measure} to {end_measure} has no notes.\")\n",
    "            continue\n",
    "    if len(entropy_for_windows) > 0:\n",
    "        return np.mean(entropy_for_windows)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9ca8ef-fcee-4797-80b5-1c5d2cbf6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poliphony_metric(song):\n",
    "    notes_by_start_time = {}\n",
    "    notes_in_song = 0\n",
    "    for token in song:\n",
    "        if is_note(token):   # Notes\n",
    "            notes_in_song += 1\n",
    "            start_time = token[1]*conf.INPUT_RANGES['beat']*conf.INPUT_RANGES['position'] + \\\n",
    "                         token[2]*conf.INPUT_RANGES['position'] + token[3]\n",
    "            if start_time in notes_by_start_time:\n",
    "                notes_by_start_time[start_time].append(token)\n",
    "            else:\n",
    "                notes_by_start_time[start_time] = [token]\n",
    "    return sum([len(notes_list) > 1 for notes_list in notes_by_start_time.values()]) / notes_in_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a57ed78-ade8-4927-a278-6ad268cbbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_span_metric(song):\n",
    "    lowest_pitch = 128\n",
    "    highest_pitch = 0\n",
    "    for token in song:\n",
    "        if is_note(token):  # Notes\n",
    "            if token[5] < lowest_pitch:\n",
    "                lowest_pitch = token[5]\n",
    "            if token[5] > highest_pitch:\n",
    "                highest_pitch = token[5]\n",
    "    return highest_pitch - lowest_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30fd9a3e-5e78-43bc-a004-e6fc21f90410",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tones = {'C':   0,\n",
    "              'C#':  1, \n",
    "              'D':   2,\n",
    "              'D#':  3,\n",
    "              'E':   4,\n",
    "              'F':   5,\n",
    "              'F#':  6,\n",
    "              'G':   7,\n",
    "              'G#':  8,\n",
    "              'A':   9,\n",
    "              'A#': 10,\n",
    "              'B':  11}\n",
    "\n",
    "scale = {}\n",
    "# Most important scales:\n",
    "# Major scale:\n",
    "scale['major'] = [0,2,4,5,7,9,11]\n",
    "#(W-W-H-W-W-W-H)\n",
    "#(2 2 1 2 2 2 1)\n",
    "\n",
    "# Natural minor scale:\n",
    "scale['natural_minor'] = [0,2,3,5,7,8,10]\n",
    "#(W-H-W-W-H-W-W)\n",
    "#(2 1 2 2 1 2 2)\n",
    " \n",
    "# Harmonic minor scale:\n",
    "scale['harmonic_minor'] = [0,2,3,5,7,8,11]\n",
    "#(W-H-W-W-H-WH-H)\n",
    "#(2 1 2 2 1 3 1)\n",
    " \n",
    "def tones_to_scales(tones):\n",
    "    counts = {}\n",
    "    for base_tone in base_tones:\n",
    "        counts[base_tone] = {}\n",
    "        counts[base_tone]['major'] = 0\n",
    "        counts[base_tone]['natural_minor'] = 0\n",
    "        counts[base_tone]['harmonic_minor'] = 0\n",
    "\n",
    "    # If no tones, return 0 for each note in each scale\n",
    "    if not len(tones):\n",
    "        frequencies = {}\n",
    "        for base_tone in base_tones:\n",
    "            frequencies[base_tone] = {}\n",
    "            for scale_label in scale:\n",
    "                frequencies[base_tone][scale_label] = 0.0\n",
    "        return frequencies\n",
    "    \n",
    "    # Otherwise, compute scale consistency and their frequency\n",
    "    for tone in tones:\n",
    "        # For each note...\n",
    "        for base_tone in base_tones:\n",
    "            # For each of the base pitches...\n",
    "            for scale_label in scale:\n",
    "                # For each of the available scales...\n",
    "                if tone%12-base_tones[base_tone] in scale[scale_label]:\n",
    "                    # If the distance between the tone and the base tone is in a scale, \n",
    "                    # add 1 to that scale starting from that base tone\n",
    "                    counts[base_tone][scale_label] += 1\n",
    "    # Transform these counts into frequencies\n",
    "    frequencies = {}\n",
    "    for base_tone in counts:\n",
    "        frequencies[base_tone] = {}\n",
    "        for scale_label in counts[base_tone]:\n",
    "            frequencies[base_tone][scale_label] = float(counts[base_tone][scale_label])/float(len(tones))\n",
    "    return frequencies\n",
    "\n",
    "def max_likelihood_scale(tones):\n",
    "    # Get scale statistics\n",
    "    scale_statistics = tones_to_scales(tones) \n",
    "    stat_list = []\n",
    "    for base_tone in scale_statistics:\n",
    "        for scale_label in scale_statistics[base_tone]:\n",
    "            stat_list.append((base_tone, scale_label, scale_statistics[base_tone][scale_label]))\n",
    "    # Get the most likely scale and its likelihood\n",
    "    stat_list.sort(key=lambda e: e[2], reverse=True)\n",
    "    return (stat_list[0][0]+' '+stat_list[0][1], stat_list[0][2])\n",
    "\n",
    "def scale_consistency_metric(song):\n",
    "    tones = [token[5] for token in song if is_note(token)]\n",
    "    ml = max_likelihood_scale(tones)\n",
    "    stats = {}\n",
    "    stats['scale'] = ml[0] # <-- we ignore it for now but it's cool to see which is the most likely scale for a song\n",
    "    stats['scale_score'] = ml[1]\n",
    "    return stats['scale_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dbb020-fa1e-4fa9-a54a-b2f037175448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER OF NOTES\n",
    "def n_notes_metric(song):\n",
    "    return sum([1 for token in song if is_note(token)])\n",
    "\n",
    "# AVERAGE NOTE DURATION\n",
    "def avg_note_duration_metric(song):\n",
    "    return np.mean([token[4] for token in song if is_note(token)])\n",
    "\n",
    "# MAX SILENCE BETWEEN EVENTS\n",
    "def max_offset_duration_metric(song):\n",
    "    offsets = []\n",
    "    for i in range(len(song)-1):\n",
    "        token = song[i]\n",
    "        if is_note(token):\n",
    "            j = i+1; next_token = song[j]\n",
    "            while not is_note(next_token) and j < len(song)-1:\n",
    "                j += 1; next_token = song[j]\n",
    "            if not is_note(next_token): break\n",
    "            empty_measures = next_token[1] - token[1]\n",
    "            empty_beats = (int(next_token[2]) - int(token[2])) % conf.numerators[token[9] % conf.tot_numerators]\n",
    "            empty_positions = (int(next_token[3]) - int(token[3])) % len(conf.np_positions)\n",
    "            beats_offset = empty_measures * conf.numerators[token[9] % conf.tot_numerators] + empty_beats\n",
    "            offset = beats_offset * len(conf.np_positions) + empty_positions\n",
    "            offsets.append(offset)\n",
    "        elif token[0] == 7:\n",
    "            break\n",
    "    return max(offsets) if len(offsets) > 0 else 0\n",
    "\n",
    "# REPETITIONS IN MEASURES\n",
    "def avg_unique_pitches_in_measure_metric(song):\n",
    "    # Average number of different pitches in a measures\n",
    "    pitches_per_measure = {}\n",
    "    for token in song:\n",
    "        if is_note(token):\n",
    "            measure = token[1]\n",
    "            if measure in pitches_per_measure:\n",
    "                # Add pitch to set\n",
    "                pitches_per_measure[measure].add(token[5])\n",
    "            else:\n",
    "                # Create set\n",
    "                pitches_per_measure[measure] = set([token[5]])\n",
    "    avg_pitches_per_measure = np.mean([len(s) for s in pitches_per_measure.values()])\n",
    "    return avg_pitches_per_measure\n",
    "\n",
    "def repetition_factor_metric(song):\n",
    "    measures = {}\n",
    "    for token in song:\n",
    "        if is_note(token):\n",
    "            measure = token[1]\n",
    "            if measure in measures:\n",
    "                measures[measure].append((token[2], token[3], token[5])) # beat, position, pitch\n",
    "            else:\n",
    "                measures[measure] = [(token[2], token[3], token[5])]\n",
    "    tot_measures = len(measures)\n",
    "    matchings = {}\n",
    "    for measure_1 in measures:\n",
    "        matchings[measure_1] = 0\n",
    "        for measure_2 in measures:\n",
    "            if measure_1 != measure_2 and measures[measure_1] == measures[measure_2]:\n",
    "                matchings[measure_1] += 1\n",
    "        matchings[measure_1] /= tot_measures\n",
    "    return max(matchings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ede0a9-7c45-40ed-9e0a-d996c633e898",
   "metadata": {},
   "source": [
    "## Metrics computation on our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bcdf16-c5b4-4cd8-b9a6-9fc63641b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, _, test_set = utils.get_dataset_splits(conf.dataset_paths['lmd_matched_final_2048_cut'], conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d13f3-2b56-4afd-89eb-9822b218ea3f",
   "metadata": {},
   "source": [
    "Note: for the metric computation we randomly sample 1/5 of the dataset, to make the analysis a little faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0dbdfed-33eb-4b93-ba01-e99e15819b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(dataset, stat, portion=20):\n",
    "    values = []\n",
    "    dataset = dataset.shuffle(len(dataset) // 100 * portion).take(len(dataset) // 100 * portion)\n",
    "    dataset_iter = dataset.as_numpy_iterator()\n",
    "    for X, _ in tqdm(dataset_iter, total=len(dataset)):\n",
    "        for song in X[0]:\n",
    "            if stat == 'entropy_1':\n",
    "                val = pitch_class_histogram_entropy_metric(song, window_size = 1)\n",
    "            elif stat == 'entropy_4':\n",
    "                val = pitch_class_histogram_entropy_metric(song, window_size = 4)\n",
    "            elif stat == 'poliphony':\n",
    "                val = poliphony_metric(song)\n",
    "            elif stat == 'tone_span':\n",
    "                val = tone_span_metric(song)\n",
    "            elif stat == 'scale_consistency':\n",
    "                val = scale_consistency_metric(song)\n",
    "            elif stat == 'n_notes':\n",
    "                val = n_notes_metric(song)\n",
    "            elif stat == 'avg_note_duration':\n",
    "                val = avg_note_duration_metric(song)\n",
    "            elif stat == 'max_offset':\n",
    "                val = max_offset_duration_metric(song)\n",
    "            elif stat == 'unique_pitches_in_measure':\n",
    "                val = avg_unique_pitches_in_measure_metric(song)\n",
    "            elif stat == 'measure_repetition':\n",
    "                val = repetition_factor_metric(song)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        if val is not None:\n",
    "            values.append(val)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4da750-87f1-40cc-ab85-00d2b3d5a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stat(dataset, stat_name, stats, eval_name = 'train'):\n",
    "    print(f\"Computing metric {stat_name}\")\n",
    "    s = time.time()\n",
    "    vals = collect_stats(dataset, stat_name, portion=100)\n",
    "    e = time.time()\n",
    "    stats[stat_name + '_mean'] = float(np.mean(vals))\n",
    "    stats[stat_name + '_std'] = float(np.std(vals))\n",
    "    stats[stat_name + '_interval'] = [float(x) \n",
    "        for x in st.t.interval(\n",
    "            0.95, len(vals)-1, \n",
    "            loc=np.mean(vals), \n",
    "            scale=st.sem(vals)\n",
    "        )]\n",
    "    stats[stat_name + '_time'] = float(e-s)\n",
    "    with open(f'evaluation_stats_{eval_name}.json', 'w') as f:\n",
    "        json.dump(stats, f)\n",
    "\n",
    "def evaluate(dataset, eval_name='train'):\n",
    "    stats = {}\n",
    "    run_stat(dataset, 'entropy_1', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'entropy_4', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'poliphony', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'tone_span', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'scale_consistency', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'n_notes', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'avg_note_duration', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'max_offset', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'unique_pitches_in_measure', stats, eval_name=eval_name)\n",
    "    run_stat(dataset, 'measure_repetition', stats, eval_name=eval_name)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb401e-6499-4600-aca9-5f713485a0de",
   "metadata": {},
   "source": [
    "### Train set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36f0c0-35ea-4f7a-9142-48d272c30e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing metric entropy_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2111/9200 [1:34:25<5:31:52,  2.81s/it]"
     ]
    }
   ],
   "source": [
    "evaluate(train_set, eval_name='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee2e30-b2b0-4eb2-bf2f-70ed9ada4728",
   "metadata": {},
   "source": [
    "### Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c73b78-c7ad-4283-9f99-72d32feaa9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_set, eval_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb47b8-9fda-4820-9aad-0a1e1f78c941",
   "metadata": {},
   "source": [
    "### Generated set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ad32c-91bb-4be9-8b29-8b6d2283537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313399b-84fc-4df4-af84-5a2f6b22199b",
   "metadata": {},
   "source": [
    "## Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ba1c5a-e40e-40af-b1de-f4526e9a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evaluation_stats_train.json', 'r') as f:\n",
    "    train_stats = json.load(f)\n",
    "    \n",
    "with open('evaluation_stats_test.json', 'r') as f:\n",
    "    test_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f33cce18-5045-4364-9f34-dcb08b1f5359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= TRAIN =============\n",
      "entropy_1: 2.33 ± 0.01\n",
      "entropy_4: 2.68 ± 0.00\n",
      "poliphony: 0.21 ± 0.00\n",
      "tone_span: 58.39 ± 0.23\n",
      "scale_consistency: 0.81 ± 0.00\n",
      "n_notes: 1929.77 ± 6.46\n",
      "avg_note_duration: 26.23 ± 0.19\n",
      "max_offset: 796.34 ± 7.22\n",
      "unique_pitches_in_measure: 13.18 ± 0.07\n",
      "measure_repetition: 0.00 ± 0.00\n",
      "============= TEST =============\n",
      "entropy_1: 2.31 ± 0.02\n",
      "entropy_4: 2.68 ± 0.01\n",
      "poliphony: 0.21 ± 0.00\n",
      "tone_span: 58.10 ± 0.66\n",
      "scale_consistency: 0.81 ± 0.01\n",
      "n_notes: 1924.47 ± 18.35\n",
      "avg_note_duration: 26.29 ± 0.59\n",
      "max_offset: 805.82 ± 31.45\n",
      "unique_pitches_in_measure: 12.99 ± 0.21\n",
      "measure_repetition: 0.00 ± 0.00\n"
     ]
    }
   ],
   "source": [
    "metrics = ['entropy_1', 'entropy_4', 'poliphony', 'tone_span',\n",
    "           'scale_consistency', 'n_notes', 'avg_note_duration', \n",
    "           'max_offset', 'unique_pitches_in_measure', \n",
    "           'measure_repetition']\n",
    "\n",
    "stat_sets = {'train': train_stats, 'test': test_stats}\n",
    "\n",
    "for k, v in stat_sets.items():\n",
    "    print(\"============= \" + k.upper() + \" =============\")\n",
    "    for metric in metrics:\n",
    "        m = v[f'{metric}_mean']\n",
    "        m_around =  m - v[f'{metric}_interval'][0]\n",
    "        print(f\"{metric}: {m:.2f} ± {m_around:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
